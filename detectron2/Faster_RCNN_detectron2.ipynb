{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXqRygc57R7O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38fbcc7b-df38-4c73-84ee-37be4b5fbc55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue May  7 18:10:22 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla V100-SXM2-16GB           Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0              24W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acA-SdCFpJ_L",
        "outputId": "d2be916e-3e7e-497d-f299-f15d575ac93c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-h446wvma\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-h446wvma\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit 5c380fdfc62b0124204155d6be3b1016e3dadb2d\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (9.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (3.7.1)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.0.7)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.4.0)\n",
            "Collecting yacs>=0.1.8 (from detectron2==0.6)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.2.1)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (4.66.4)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.15.2)\n",
            "Collecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6)\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6)\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Collecting omegaconf<2.4,>=2.1 (from detectron2==0.6)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hydra-core>=1.1 (from detectron2==0.6)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting black (from detectron2==0.6)\n",
            "  Downloading black-24.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (24.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.25.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.1)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->detectron2==0.6)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2==0.6)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (8.1.7)\n",
            "Collecting mypy-extensions>=0.4.3 (from black->detectron2==0.6)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting pathspec>=0.9.0 (from black->detectron2==0.6)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (4.2.1)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (4.11.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.63.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->detectron2==0.6) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->detectron2==0.6) (3.2.2)\n",
            "Building wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime\n",
            "  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for detectron2: filename=detectron2-0.6-cp310-cp310-linux_x86_64.whl size=6150222 sha256=6adb2d543c513249b00d33c50b108ff7ca41f82094f24137378cd8a537241ebb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bsvwqt7l/wheels/47/e5/15/94c80df2ba85500c5d76599cc307c0a7079d0e221bb6fc4375\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61400 sha256=3c2e9824ca63a163b3e69a3f5486f6db4f9d428a7d331bb589e70e81458c3375\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=067f4c1611de9f0e7f9db64757c009a10455607198b24970cf54bc2d98d0a202\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built detectron2 fvcore antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, yacs, portalocker, pathspec, omegaconf, mypy-extensions, iopath, hydra-core, black, fvcore, detectron2\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 black-24.4.2 detectron2-0.6 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.0.0 omegaconf-2.3.0 pathspec-0.12.1 portalocker-2.8.2 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvtj4PMzqL3Y",
        "outputId": "328dd1e7-fba5-4b3f-ce0d-a44f98a521ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.14.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.2.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Download the file using gdown\n",
        "import gdown\n",
        "\n",
        "# Extract the file ID from the new URL\n",
        "file_id = '1DlHvbeCGbinDxi0SWL5GFeuZuxGltccQ'\n",
        "\n",
        "# Construct the Google Drive download URL\n",
        "download_url = f'https://drive.google.com/uc?id={file_id}'\n",
        "\n",
        "# Download and save the file locally (adjust the output filename if needed)\n",
        "output = 'Faster-RCNN-detectron2.zip'\n",
        "gdown.download(download_url, output, quiet=False)\n",
        "\n",
        "# Unzip the downloaded file\n",
        "!unzip -q Faster-RCNN-detectron2.zip -d ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eaOXpHiqQbx",
        "outputId": "937133e2-4603-422d-c03c-bcaa8469945c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1DlHvbeCGbinDxi0SWL5GFeuZuxGltccQ\n",
            "From (redirected): https://drive.google.com/uc?id=1DlHvbeCGbinDxi0SWL5GFeuZuxGltccQ&confirm=t&uuid=ff833eed-5800-4ef0-a826-3f86305544bd\n",
            "To: /content/Faster-RCNN-detectron2.zip\n",
            "100%|██████████| 319M/319M [00:04<00:00, 73.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nksotrg0qh0Z",
        "outputId": "f3114f37-9ec1-461e-add1-27487af301f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Faster-RCNN-detectron2\tFaster-RCNN-detectron2.zip  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Faster-RCNN-detectron2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDbhWbK1qlRa",
        "outputId": "b9f94120-3480-4500-b432-4a590d843b5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Faster-RCNN-detectron2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwriBviTqohw",
        "outputId": "cf7d8792-af1f-4462-f59e-e85fe02a24cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "annotations  test  train  train_model.py  valid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 train_model.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyfKyjHIqrOa",
        "outputId": "5470d2c7-1917-432c-dd6a-883a5dc0b2ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/07 18:16:21 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "\u001b[32m[05/07 18:16:21 d2.evaluation.coco_evaluation]: \u001b[0mTrying to convert 'intruder_valid' to COCO format ...\n",
            "\u001b[32m[05/07 18:16:21 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'intruder_valid' to COCO format ...)\n",
            "\u001b[32m[05/07 18:16:23 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
            "\u001b[32m[05/07 18:16:23 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 392, #annotations: 510\n",
            "\u001b[32m[05/07 18:16:23 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './output/intruder_valid_coco_format.json' ...\n",
            "\u001b[32m[05/07 18:16:24 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[05/07 18:16:46 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 4118 images left.\n",
            "\u001b[32m[05/07 18:16:46 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
            "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
            "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
            "|    Axe     | 999          |  Handgun   | 1929         |   Knife    | 2446         |\n",
            "|            |              |            |              |            |              |\n",
            "|   total    | 5374         |            |              |            |              |\u001b[0m\n",
            "\u001b[32m[05/07 18:16:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[05/07 18:16:46 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[05/07 18:16:46 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[05/07 18:16:46 d2.data.common]: \u001b[0mSerializing 4118 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/07 18:16:46 d2.data.common]: \u001b[0mSerialized dataset takes 1.16 MiB\n",
            "\u001b[32m[05/07 18:16:46 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=8\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/07 18:16:46 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
            "\u001b[32m[05/07 18:16:46 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl ...\n",
            "model_final_280758.pkl: 167MB [00:00, 168MB/s]               \n",
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
            "Some model parameters or buffers are not found in the checkpoint:\n",
            "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
            "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
            "\u001b[32m[05/07 18:16:47 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3549.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "\u001b[32m[05/07 18:17:03 d2.utils.events]: \u001b[0m eta: 1:29:04  iter: 19  total_loss: 1.517  loss_cls: 1.309  loss_box_reg: 0.1402  loss_rpn_cls: 0.01033  loss_rpn_loc: 0.00973    time: 0.5682  last_time: 0.5051  data_time: 0.0880  last_data_time: 0.0602   lr: 4.9952e-05  max_mem: 5720M\n",
            "2024-05-07 18:17:03.720396: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-05-07 18:17:03.720466: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-05-07 18:17:03.721908: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-05-07 18:17:04.748765: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[32m[05/07 18:17:17 d2.utils.events]: \u001b[0m eta: 1:30:05  iter: 39  total_loss: 0.6459  loss_cls: 0.4386  loss_box_reg: 0.1376  loss_rpn_cls: 0.006399  loss_rpn_loc: 0.01015    time: 0.5742  last_time: 0.5594  data_time: 0.0893  last_data_time: 0.0783   lr: 9.9902e-05  max_mem: 5720M\n",
            "\u001b[32m[05/07 18:17:28 d2.utils.events]: \u001b[0m eta: 1:30:01  iter: 59  total_loss: 0.3978  loss_cls: 0.2086  loss_box_reg: 0.1616  loss_rpn_cls: 0.01276  loss_rpn_loc: 0.01291    time: 0.5748  last_time: 0.5844  data_time: 0.0801  last_data_time: 0.0959   lr: 0.00014985  max_mem: 5720M\n",
            "\u001b[32m[05/07 18:17:40 d2.utils.events]: \u001b[0m eta: 1:29:50  iter: 79  total_loss: 0.3374  loss_cls: 0.1757  loss_box_reg: 0.1452  loss_rpn_cls: 0.00702  loss_rpn_loc: 0.008356    time: 0.5745  last_time: 0.5467  data_time: 0.0808  last_data_time: 0.0616   lr: 0.0001998  max_mem: 5720M\n",
            "\u001b[32m[05/07 18:17:51 d2.utils.events]: \u001b[0m eta: 1:29:35  iter: 99  total_loss: 0.3004  loss_cls: 0.1478  loss_box_reg: 0.1369  loss_rpn_cls: 0.00798  loss_rpn_loc: 0.009926    time: 0.5735  last_time: 0.5432  data_time: 0.0809  last_data_time: 0.0737   lr: 0.00024975  max_mem: 5720M\n",
            "\u001b[32m[05/07 18:18:03 d2.utils.events]: \u001b[0m eta: 1:29:32  iter: 119  total_loss: 0.2948  loss_cls: 0.1387  loss_box_reg: 0.1345  loss_rpn_cls: 0.006562  loss_rpn_loc: 0.009016    time: 0.5752  last_time: 0.5551  data_time: 0.0842  last_data_time: 0.0620   lr: 0.0002997  max_mem: 5720M\n",
            "\u001b[32m[05/07 18:18:15 d2.utils.events]: \u001b[0m eta: 1:29:40  iter: 139  total_loss: 0.2963  loss_cls: 0.1395  loss_box_reg: 0.1377  loss_rpn_cls: 0.005242  loss_rpn_loc: 0.01134    time: 0.5756  last_time: 0.5579  data_time: 0.0860  last_data_time: 0.0674   lr: 0.00034965  max_mem: 5720M\n",
            "\u001b[32m[05/07 18:18:26 d2.utils.events]: \u001b[0m eta: 1:29:36  iter: 159  total_loss: 0.3031  loss_cls: 0.1348  loss_box_reg: 0.152  loss_rpn_cls: 0.009795  loss_rpn_loc: 0.009022    time: 0.5756  last_time: 0.5669  data_time: 0.0790  last_data_time: 0.0778   lr: 0.0003996  max_mem: 5720M\n",
            "\u001b[32m[05/07 18:18:38 d2.utils.events]: \u001b[0m eta: 1:29:17  iter: 179  total_loss: 0.2711  loss_cls: 0.1158  loss_box_reg: 0.1281  loss_rpn_cls: 0.006605  loss_rpn_loc: 0.009177    time: 0.5753  last_time: 0.5556  data_time: 0.0806  last_data_time: 0.0685   lr: 0.00044955  max_mem: 5720M\n",
            "\u001b[32m[05/07 18:18:49 d2.utils.events]: \u001b[0m eta: 1:28:55  iter: 199  total_loss: 0.3082  loss_cls: 0.1329  loss_box_reg: 0.1603  loss_rpn_cls: 0.008638  loss_rpn_loc: 0.008522    time: 0.5752  last_time: 0.6212  data_time: 0.0839  last_data_time: 0.1122   lr: 0.0004995  max_mem: 5720M\n",
            "\u001b[32m[05/07 18:19:00 d2.utils.events]: \u001b[0m eta: 1:28:44  iter: 219  total_loss: 0.2856  loss_cls: 0.116  loss_box_reg: 0.1426  loss_rpn_cls: 0.007673  loss_rpn_loc: 0.009812    time: 0.5745  last_time: 0.6708  data_time: 0.0824  last_data_time: 0.1153   lr: 0.00054945  max_mem: 5720M\n",
            "\u001b[32m[05/07 18:19:12 d2.utils.events]: \u001b[0m eta: 1:28:33  iter: 239  total_loss: 0.3224  loss_cls: 0.128  loss_box_reg: 0.1611  loss_rpn_cls: 0.008251  loss_rpn_loc: 0.01082    time: 0.5740  last_time: 0.5693  data_time: 0.0757  last_data_time: 0.0706   lr: 0.0005994  max_mem: 5720M\n",
            "\u001b[32m[05/07 18:19:23 d2.utils.events]: \u001b[0m eta: 1:28:27  iter: 259  total_loss: 0.2778  loss_cls: 0.1173  loss_box_reg: 0.1392  loss_rpn_cls: 0.00845  loss_rpn_loc: 0.01228    time: 0.5744  last_time: 0.5816  data_time: 0.0782  last_data_time: 0.0964   lr: 0.00064935  max_mem: 5720M\n",
            "\u001b[32m[05/07 18:19:35 d2.utils.events]: \u001b[0m eta: 1:28:21  iter: 279  total_loss: 0.25  loss_cls: 0.1044  loss_box_reg: 0.1276  loss_rpn_cls: 0.005715  loss_rpn_loc: 0.007726    time: 0.5745  last_time: 0.5659  data_time: 0.0835  last_data_time: 0.0830   lr: 0.0006993  max_mem: 5720M\n",
            "\u001b[32m[05/07 18:19:46 d2.utils.events]: \u001b[0m eta: 1:28:14  iter: 299  total_loss: 0.2857  loss_cls: 0.1193  loss_box_reg: 0.149  loss_rpn_cls: 0.007009  loss_rpn_loc: 0.008654    time: 0.5747  last_time: 0.5528  data_time: 0.0849  last_data_time: 0.0581   lr: 0.00074925  max_mem: 5720M\n",
            "\u001b[32m[05/07 18:19:58 d2.utils.events]: \u001b[0m eta: 1:28:05  iter: 319  total_loss: 0.2783  loss_cls: 0.1197  loss_box_reg: 0.1365  loss_rpn_cls: 0.005955  loss_rpn_loc: 0.008264    time: 0.5750  last_time: 0.5240  data_time: 0.0802  last_data_time: 0.0753   lr: 0.0007992  max_mem: 5720M\n",
            "\u001b[32m[05/07 18:20:09 d2.utils.events]: \u001b[0m eta: 1:27:56  iter: 339  total_loss: 0.262  loss_cls: 0.1111  loss_box_reg: 0.1316  loss_rpn_cls: 0.00404  loss_rpn_loc: 0.009426    time: 0.5744  last_time: 0.5123  data_time: 0.0766  last_data_time: 0.0610   lr: 0.00084915  max_mem: 5720M\n",
            "\u001b[32m[05/07 18:20:21 d2.utils.events]: \u001b[0m eta: 1:27:42  iter: 359  total_loss: 0.2499  loss_cls: 0.108  loss_box_reg: 0.1266  loss_rpn_cls: 0.006348  loss_rpn_loc: 0.008746    time: 0.5743  last_time: 0.5479  data_time: 0.0776  last_data_time: 0.0695   lr: 0.0008991  max_mem: 5720M\n",
            "\u001b[32m[05/07 18:20:32 d2.utils.events]: \u001b[0m eta: 1:27:30  iter: 379  total_loss: 0.2218  loss_cls: 0.0963  loss_box_reg: 0.1179  loss_rpn_cls: 0.004322  loss_rpn_loc: 0.00714    time: 0.5745  last_time: 0.5204  data_time: 0.0822  last_data_time: 0.0770   lr: 0.00094905  max_mem: 5720M\n",
            "\u001b[32m[05/07 18:20:44 d2.utils.events]: \u001b[0m eta: 1:27:16  iter: 399  total_loss: 0.2091  loss_cls: 0.08849  loss_box_reg: 0.1049  loss_rpn_cls: 0.006821  loss_rpn_loc: 0.008131    time: 0.5745  last_time: 0.5580  data_time: 0.0854  last_data_time: 0.0675   lr: 0.000999  max_mem: 5720M\n",
            "\u001b[32m[05/07 18:20:55 d2.utils.events]: \u001b[0m eta: 1:27:06  iter: 419  total_loss: 0.211  loss_cls: 0.1015  loss_box_reg: 0.09319  loss_rpn_cls: 0.004848  loss_rpn_loc: 0.008957    time: 0.5745  last_time: 0.6062  data_time: 0.0863  last_data_time: 0.1035   lr: 0.001049  max_mem: 5720M\n",
            "\u001b[32m[05/07 18:21:07 d2.utils.events]: \u001b[0m eta: 1:26:51  iter: 439  total_loss: 0.2308  loss_cls: 0.09988  loss_box_reg: 0.1107  loss_rpn_cls: 0.005915  loss_rpn_loc: 0.01052    time: 0.5738  last_time: 0.6096  data_time: 0.0799  last_data_time: 0.1181   lr: 0.0010989  max_mem: 5720M\n",
            "\u001b[32m[05/07 18:21:18 d2.utils.events]: \u001b[0m eta: 1:26:39  iter: 459  total_loss: 0.1817  loss_cls: 0.08477  loss_box_reg: 0.08378  loss_rpn_cls: 0.006169  loss_rpn_loc: 0.007851    time: 0.5729  last_time: 0.5421  data_time: 0.0784  last_data_time: 0.0693   lr: 0.0011489  max_mem: 5720M\n",
            "\u001b[32m[05/07 18:21:29 d2.utils.events]: \u001b[0m eta: 1:26:24  iter: 479  total_loss: 0.1899  loss_cls: 0.0839  loss_box_reg: 0.09949  loss_rpn_cls: 0.00524  loss_rpn_loc: 0.01091    time: 0.5730  last_time: 0.5457  data_time: 0.0810  last_data_time: 0.0615   lr: 0.0011988  max_mem: 5720M\n",
            "\u001b[32m[05/07 18:21:42 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
            "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
            "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
            "|    Axe     | 94           |  Handgun   | 219          |   Knife    | 197          |\n",
            "|            |              |            |              |            |              |\n",
            "|   total    | 510          |            |              |            |              |\u001b[0m\n",
            "\u001b[32m[05/07 18:21:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[05/07 18:21:42 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[05/07 18:21:42 d2.data.common]: \u001b[0mSerializing 392 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/07 18:21:42 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/07 18:21:42 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "\u001b[32m[05/07 18:21:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 392 batches\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[32m[05/07 18:21:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/392. Dataloading: 0.0048 s/iter. Inference: 0.0548 s/iter. Eval: 0.0005 s/iter. Total: 0.0601 s/iter. ETA=0:00:22\n",
            "\u001b[32m[05/07 18:21:48 d2.evaluation.evaluator]: \u001b[0mInference done 116/392. Dataloading: 0.0042 s/iter. Inference: 0.0439 s/iter. Eval: 0.0004 s/iter. Total: 0.0486 s/iter. ETA=0:00:13\n",
            "\u001b[32m[05/07 18:21:53 d2.evaluation.evaluator]: \u001b[0mInference done 247/392. Dataloading: 0.0031 s/iter. Inference: 0.0395 s/iter. Eval: 0.0003 s/iter. Total: 0.0431 s/iter. ETA=0:00:06\n",
            "\u001b[32m[05/07 18:21:58 d2.evaluation.evaluator]: \u001b[0mInference done 352/392. Dataloading: 0.0034 s/iter. Inference: 0.0408 s/iter. Eval: 0.0004 s/iter. Total: 0.0445 s/iter. ETA=0:00:01\n",
            "\u001b[32m[05/07 18:22:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.141682 (0.044294 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 18:22:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.040430 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 18:22:00 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/07 18:22:00 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
            "\u001b[32m[05/07 18:22:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[05/07 18:22:00 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[05/07 18:22:00 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.32 seconds.\n",
            "\u001b[32m[05/07 18:22:00 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[05/07 18:22:00 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.392\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.663\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.390\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.199\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.406\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.415\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.588\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.610\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.478\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.621\n",
            "\u001b[32m[05/07 18:22:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 39.208 | 66.265 | 38.972 |  nan  | 19.928 | 40.602 |\n",
            "\u001b[32m[05/07 18:22:00 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[05/07 18:22:00 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| Axe        | 22.583 | Handgun    | 46.734 | Knife      | 48.309 |\n",
            "\u001b[32m[05/07 18:22:00 d2.engine.defaults]: \u001b[0mEvaluation results for intruder_valid in csv format:\n",
            "\u001b[32m[05/07 18:22:00 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/07 18:22:00 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/07 18:22:00 d2.evaluation.testing]: \u001b[0mcopypaste: 39.2083,66.2648,38.9724,nan,19.9277,40.6019\n",
            "\u001b[32m[05/07 18:22:00 d2.utils.events]: \u001b[0m eta: 1:26:10  iter: 499  total_loss: 0.1996  loss_cls: 0.09058  loss_box_reg: 0.09921  loss_rpn_cls: 0.004287  loss_rpn_loc: 0.008171    time: 0.5729  last_time: 0.5490  data_time: 0.0851  last_data_time: 0.0744   lr: 0.0012488  max_mem: 5720M\n",
            "\u001b[32m[05/07 18:22:12 d2.utils.events]: \u001b[0m eta: 1:25:55  iter: 519  total_loss: 0.1837  loss_cls: 0.08466  loss_box_reg: 0.08995  loss_rpn_cls: 0.005964  loss_rpn_loc: 0.009614    time: 0.5729  last_time: 0.5532  data_time: 0.0879  last_data_time: 0.0690   lr: 0.0012987  max_mem: 5720M\n",
            "\u001b[32m[05/07 18:22:23 d2.utils.events]: \u001b[0m eta: 1:25:42  iter: 539  total_loss: 0.1524  loss_cls: 0.06366  loss_box_reg: 0.07507  loss_rpn_cls: 0.003874  loss_rpn_loc: 0.008996    time: 0.5725  last_time: 0.7140  data_time: 0.0777  last_data_time: 0.1384   lr: 0.0013487  max_mem: 5720M\n",
            "\u001b[32m[05/07 18:22:34 d2.utils.events]: \u001b[0m eta: 1:25:27  iter: 559  total_loss: 0.1618  loss_cls: 0.06762  loss_box_reg: 0.07917  loss_rpn_cls: 0.003255  loss_rpn_loc: 0.007514    time: 0.5718  last_time: 0.5811  data_time: 0.0779  last_data_time: 0.0709   lr: 0.0013986  max_mem: 5720M\n",
            "\u001b[32m[05/07 18:22:46 d2.utils.events]: \u001b[0m eta: 1:25:13  iter: 579  total_loss: 0.1628  loss_cls: 0.0705  loss_box_reg: 0.07017  loss_rpn_cls: 0.00473  loss_rpn_loc: 0.009296    time: 0.5716  last_time: 0.5842  data_time: 0.0783  last_data_time: 0.0842   lr: 0.0014486  max_mem: 5720M\n",
            "\u001b[32m[05/07 18:22:57 d2.utils.events]: \u001b[0m eta: 1:25:02  iter: 599  total_loss: 0.1994  loss_cls: 0.08465  loss_box_reg: 0.0838  loss_rpn_cls: 0.006026  loss_rpn_loc: 0.008989    time: 0.5717  last_time: 0.5713  data_time: 0.0844  last_data_time: 0.0949   lr: 0.0014985  max_mem: 5720M\n",
            "\u001b[32m[05/07 18:23:09 d2.utils.events]: \u001b[0m eta: 1:24:48  iter: 619  total_loss: 0.1642  loss_cls: 0.07048  loss_box_reg: 0.07467  loss_rpn_cls: 0.004236  loss_rpn_loc: 0.007549    time: 0.5717  last_time: 0.5714  data_time: 0.0901  last_data_time: 0.0872   lr: 0.0015485  max_mem: 5720M\n",
            "\u001b[32m[05/07 18:23:20 d2.utils.events]: \u001b[0m eta: 1:24:35  iter: 639  total_loss: 0.1531  loss_cls: 0.06646  loss_box_reg: 0.0809  loss_rpn_cls: 0.003539  loss_rpn_loc: 0.009837    time: 0.5716  last_time: 0.5480  data_time: 0.0833  last_data_time: 0.0721   lr: 0.0015984  max_mem: 5720M\n",
            "\u001b[32m[05/07 18:23:31 d2.utils.events]: \u001b[0m eta: 1:24:23  iter: 659  total_loss: 0.1808  loss_cls: 0.08603  loss_box_reg: 0.07597  loss_rpn_cls: 0.004227  loss_rpn_loc: 0.008744    time: 0.5717  last_time: 0.5583  data_time: 0.0895  last_data_time: 0.0750   lr: 0.0016484  max_mem: 5720M\n",
            "\u001b[32m[05/07 18:23:43 d2.utils.events]: \u001b[0m eta: 1:24:11  iter: 679  total_loss: 0.1723  loss_cls: 0.07492  loss_box_reg: 0.08849  loss_rpn_cls: 0.004388  loss_rpn_loc: 0.008705    time: 0.5719  last_time: 0.5592  data_time: 0.0852  last_data_time: 0.0765   lr: 0.0016983  max_mem: 5720M\n",
            "\u001b[32m[05/07 18:23:54 d2.utils.events]: \u001b[0m eta: 1:24:00  iter: 699  total_loss: 0.1562  loss_cls: 0.06536  loss_box_reg: 0.07922  loss_rpn_cls: 0.003909  loss_rpn_loc: 0.007626    time: 0.5719  last_time: 0.5304  data_time: 0.0758  last_data_time: 0.0637   lr: 0.0017483  max_mem: 5720M\n",
            "\u001b[32m[05/07 18:24:06 d2.utils.events]: \u001b[0m eta: 1:23:47  iter: 719  total_loss: 0.1547  loss_cls: 0.07136  loss_box_reg: 0.07941  loss_rpn_cls: 0.004472  loss_rpn_loc: 0.009311    time: 0.5717  last_time: 0.5283  data_time: 0.0751  last_data_time: 0.0947   lr: 0.0017982  max_mem: 5720M\n",
            "\u001b[32m[05/07 18:24:17 d2.utils.events]: \u001b[0m eta: 1:23:34  iter: 739  total_loss: 0.146  loss_cls: 0.06527  loss_box_reg: 0.06756  loss_rpn_cls: 0.002432  loss_rpn_loc: 0.007207    time: 0.5714  last_time: 0.6763  data_time: 0.0770  last_data_time: 0.1132   lr: 0.0018482  max_mem: 5720M\n",
            "\u001b[32m[05/07 18:24:28 d2.utils.events]: \u001b[0m eta: 1:23:23  iter: 759  total_loss: 0.166  loss_cls: 0.07018  loss_box_reg: 0.07784  loss_rpn_cls: 0.003153  loss_rpn_loc: 0.009532    time: 0.5713  last_time: 0.6215  data_time: 0.0858  last_data_time: 0.0895   lr: 0.0018981  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:24:40 d2.utils.events]: \u001b[0m eta: 1:23:12  iter: 779  total_loss: 0.1724  loss_cls: 0.07913  loss_box_reg: 0.0757  loss_rpn_cls: 0.003227  loss_rpn_loc: 0.008666    time: 0.5713  last_time: 0.5802  data_time: 0.0838  last_data_time: 0.0974   lr: 0.0019481  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:24:51 d2.utils.events]: \u001b[0m eta: 1:23:00  iter: 799  total_loss: 0.1403  loss_cls: 0.05992  loss_box_reg: 0.07434  loss_rpn_cls: 0.00256  loss_rpn_loc: 0.00795    time: 0.5711  last_time: 0.5566  data_time: 0.0810  last_data_time: 0.0776   lr: 0.001998  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:25:02 d2.utils.events]: \u001b[0m eta: 1:22:49  iter: 819  total_loss: 0.1652  loss_cls: 0.06964  loss_box_reg: 0.09028  loss_rpn_cls: 0.003034  loss_rpn_loc: 0.006891    time: 0.5710  last_time: 0.5580  data_time: 0.0792  last_data_time: 0.0593   lr: 0.002048  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:25:14 d2.utils.events]: \u001b[0m eta: 1:22:37  iter: 839  total_loss: 0.1625  loss_cls: 0.06647  loss_box_reg: 0.07435  loss_rpn_cls: 0.003737  loss_rpn_loc: 0.008894    time: 0.5708  last_time: 0.5110  data_time: 0.0769  last_data_time: 0.0828   lr: 0.0020979  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:25:25 d2.utils.events]: \u001b[0m eta: 1:22:27  iter: 859  total_loss: 0.1515  loss_cls: 0.0632  loss_box_reg: 0.07698  loss_rpn_cls: 0.002586  loss_rpn_loc: 0.007212    time: 0.5710  last_time: 0.5656  data_time: 0.0890  last_data_time: 0.0876   lr: 0.0021479  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:25:37 d2.utils.events]: \u001b[0m eta: 1:22:16  iter: 879  total_loss: 0.1408  loss_cls: 0.05784  loss_box_reg: 0.06595  loss_rpn_cls: 0.003699  loss_rpn_loc: 0.007748    time: 0.5710  last_time: 0.5375  data_time: 0.0724  last_data_time: 0.0709   lr: 0.0021978  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:25:48 d2.utils.events]: \u001b[0m eta: 1:22:04  iter: 899  total_loss: 0.1661  loss_cls: 0.06532  loss_box_reg: 0.07145  loss_rpn_cls: 0.003538  loss_rpn_loc: 0.008441    time: 0.5710  last_time: 0.5663  data_time: 0.0875  last_data_time: 0.0800   lr: 0.0022478  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:26:00 d2.utils.events]: \u001b[0m eta: 1:21:52  iter: 919  total_loss: 0.1685  loss_cls: 0.06609  loss_box_reg: 0.07763  loss_rpn_cls: 0.004287  loss_rpn_loc: 0.009372    time: 0.5709  last_time: 0.5591  data_time: 0.0843  last_data_time: 0.0779   lr: 0.0022977  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:26:11 d2.utils.events]: \u001b[0m eta: 1:21:39  iter: 939  total_loss: 0.1575  loss_cls: 0.05597  loss_box_reg: 0.07784  loss_rpn_cls: 0.004774  loss_rpn_loc: 0.008896    time: 0.5709  last_time: 0.6988  data_time: 0.0838  last_data_time: 0.1110   lr: 0.0023477  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:26:22 d2.utils.events]: \u001b[0m eta: 1:21:26  iter: 959  total_loss: 0.1427  loss_cls: 0.05595  loss_box_reg: 0.06925  loss_rpn_cls: 0.003312  loss_rpn_loc: 0.00938    time: 0.5704  last_time: 0.6072  data_time: 0.0769  last_data_time: 0.0949   lr: 0.0023976  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:26:33 d2.utils.events]: \u001b[0m eta: 1:21:12  iter: 979  total_loss: 0.1542  loss_cls: 0.06122  loss_box_reg: 0.07795  loss_rpn_cls: 0.002745  loss_rpn_loc: 0.006597    time: 0.5703  last_time: 0.5564  data_time: 0.0882  last_data_time: 0.0705   lr: 0.0024476  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:26:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[05/07 18:26:46 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[05/07 18:26:46 d2.data.common]: \u001b[0mSerializing 392 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/07 18:26:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/07 18:26:46 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "\u001b[32m[05/07 18:26:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 392 batches\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[32m[05/07 18:26:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/392. Dataloading: 0.0041 s/iter. Inference: 0.0428 s/iter. Eval: 0.0007 s/iter. Total: 0.0476 s/iter. ETA=0:00:18\n",
            "\u001b[32m[05/07 18:26:52 d2.evaluation.evaluator]: \u001b[0mInference done 114/392. Dataloading: 0.0042 s/iter. Inference: 0.0439 s/iter. Eval: 0.0004 s/iter. Total: 0.0487 s/iter. ETA=0:00:13\n",
            "\u001b[32m[05/07 18:26:57 d2.evaluation.evaluator]: \u001b[0mInference done 245/392. Dataloading: 0.0030 s/iter. Inference: 0.0395 s/iter. Eval: 0.0004 s/iter. Total: 0.0430 s/iter. ETA=0:00:06\n",
            "\u001b[32m[05/07 18:27:02 d2.evaluation.evaluator]: \u001b[0mInference done 353/392. Dataloading: 0.0032 s/iter. Inference: 0.0406 s/iter. Eval: 0.0004 s/iter. Total: 0.0442 s/iter. ETA=0:00:01\n",
            "\u001b[32m[05/07 18:27:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.121478 (0.044242 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 18:27:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.040471 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 18:27:04 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/07 18:27:04 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
            "\u001b[32m[05/07 18:27:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[05/07 18:27:04 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[05/07 18:27:04 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.05 seconds.\n",
            "\u001b[32m[05/07 18:27:04 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[05/07 18:27:04 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.477\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.770\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.527\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.238\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.496\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.471\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.605\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.625\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.442\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.642\n",
            "\u001b[32m[05/07 18:27:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 47.666 | 76.982 | 52.704 |  nan  | 23.812 | 49.560 |\n",
            "\u001b[32m[05/07 18:27:04 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[05/07 18:27:04 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| Axe        | 36.573 | Handgun    | 51.866 | Knife      | 54.560 |\n",
            "\u001b[32m[05/07 18:27:04 d2.engine.defaults]: \u001b[0mEvaluation results for intruder_valid in csv format:\n",
            "\u001b[32m[05/07 18:27:04 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/07 18:27:04 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/07 18:27:04 d2.evaluation.testing]: \u001b[0mcopypaste: 47.6661,76.9822,52.7042,nan,23.8123,49.5597\n",
            "\u001b[32m[05/07 18:27:04 d2.utils.events]: \u001b[0m eta: 1:20:59  iter: 999  total_loss: 0.1408  loss_cls: 0.05707  loss_box_reg: 0.07395  loss_rpn_cls: 0.00366  loss_rpn_loc: 0.009817    time: 0.5701  last_time: 0.5544  data_time: 0.0830  last_data_time: 0.0752   lr: 0.0024975  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:27:15 d2.utils.events]: \u001b[0m eta: 1:20:48  iter: 1019  total_loss: 0.16  loss_cls: 0.06146  loss_box_reg: 0.07668  loss_rpn_cls: 0.003837  loss_rpn_loc: 0.007586    time: 0.5697  last_time: 0.6740  data_time: 0.0699  last_data_time: 0.0957   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:27:26 d2.utils.events]: \u001b[0m eta: 1:20:31  iter: 1039  total_loss: 0.135  loss_cls: 0.05025  loss_box_reg: 0.07245  loss_rpn_cls: 0.002988  loss_rpn_loc: 0.007745    time: 0.5691  last_time: 0.5221  data_time: 0.0743  last_data_time: 0.0662   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:27:37 d2.utils.events]: \u001b[0m eta: 1:20:16  iter: 1059  total_loss: 0.1235  loss_cls: 0.04531  loss_box_reg: 0.06624  loss_rpn_cls: 0.002592  loss_rpn_loc: 0.008315    time: 0.5689  last_time: 0.5260  data_time: 0.0795  last_data_time: 0.0655   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:27:48 d2.utils.events]: \u001b[0m eta: 1:20:05  iter: 1079  total_loss: 0.1303  loss_cls: 0.05286  loss_box_reg: 0.06692  loss_rpn_cls: 0.001981  loss_rpn_loc: 0.006542    time: 0.5688  last_time: 0.4905  data_time: 0.0864  last_data_time: 0.0649   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:28:00 d2.utils.events]: \u001b[0m eta: 1:19:53  iter: 1099  total_loss: 0.1257  loss_cls: 0.0486  loss_box_reg: 0.06613  loss_rpn_cls: 0.003007  loss_rpn_loc: 0.006276    time: 0.5688  last_time: 0.5168  data_time: 0.0814  last_data_time: 0.0744   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:28:11 d2.utils.events]: \u001b[0m eta: 1:19:41  iter: 1119  total_loss: 0.1287  loss_cls: 0.05281  loss_box_reg: 0.0645  loss_rpn_cls: 0.002748  loss_rpn_loc: 0.00732    time: 0.5689  last_time: 0.5655  data_time: 0.0895  last_data_time: 0.0816   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:28:22 d2.utils.events]: \u001b[0m eta: 1:19:26  iter: 1139  total_loss: 0.1499  loss_cls: 0.05882  loss_box_reg: 0.07637  loss_rpn_cls: 0.002308  loss_rpn_loc: 0.007767    time: 0.5687  last_time: 0.5552  data_time: 0.0828  last_data_time: 0.0844   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:28:34 d2.utils.events]: \u001b[0m eta: 1:19:14  iter: 1159  total_loss: 0.1329  loss_cls: 0.05919  loss_box_reg: 0.06457  loss_rpn_cls: 0.002637  loss_rpn_loc: 0.007136    time: 0.5688  last_time: 0.5357  data_time: 0.0867  last_data_time: 0.0676   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:28:45 d2.utils.events]: \u001b[0m eta: 1:19:02  iter: 1179  total_loss: 0.1246  loss_cls: 0.04396  loss_box_reg: 0.07068  loss_rpn_cls: 0.002359  loss_rpn_loc: 0.009315    time: 0.5687  last_time: 0.5652  data_time: 0.0814  last_data_time: 0.0859   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:28:56 d2.utils.events]: \u001b[0m eta: 1:18:50  iter: 1199  total_loss: 0.1331  loss_cls: 0.06278  loss_box_reg: 0.06552  loss_rpn_cls: 0.002849  loss_rpn_loc: 0.00808    time: 0.5688  last_time: 0.5641  data_time: 0.0912  last_data_time: 0.0802   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:29:08 d2.utils.events]: \u001b[0m eta: 1:18:38  iter: 1219  total_loss: 0.12  loss_cls: 0.04957  loss_box_reg: 0.06036  loss_rpn_cls: 0.002114  loss_rpn_loc: 0.006131    time: 0.5687  last_time: 0.6281  data_time: 0.0789  last_data_time: 0.0298   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:29:19 d2.utils.events]: \u001b[0m eta: 1:18:21  iter: 1239  total_loss: 0.125  loss_cls: 0.04767  loss_box_reg: 0.06568  loss_rpn_cls: 0.003069  loss_rpn_loc: 0.008657    time: 0.5683  last_time: 0.5473  data_time: 0.0776  last_data_time: 0.0795   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:29:30 d2.utils.events]: \u001b[0m eta: 1:18:08  iter: 1259  total_loss: 0.1444  loss_cls: 0.05667  loss_box_reg: 0.07506  loss_rpn_cls: 0.004122  loss_rpn_loc: 0.008735    time: 0.5683  last_time: 0.5388  data_time: 0.0824  last_data_time: 0.0671   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:29:41 d2.utils.events]: \u001b[0m eta: 1:17:53  iter: 1279  total_loss: 0.1668  loss_cls: 0.06582  loss_box_reg: 0.08248  loss_rpn_cls: 0.003569  loss_rpn_loc: 0.008967    time: 0.5682  last_time: 0.5565  data_time: 0.0840  last_data_time: 0.0835   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:29:53 d2.utils.events]: \u001b[0m eta: 1:17:39  iter: 1299  total_loss: 0.1171  loss_cls: 0.04738  loss_box_reg: 0.065  loss_rpn_cls: 0.002133  loss_rpn_loc: 0.006602    time: 0.5681  last_time: 0.5453  data_time: 0.0799  last_data_time: 0.0680   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:30:04 d2.utils.events]: \u001b[0m eta: 1:17:24  iter: 1319  total_loss: 0.1322  loss_cls: 0.05091  loss_box_reg: 0.06584  loss_rpn_cls: 0.003384  loss_rpn_loc: 0.007368    time: 0.5680  last_time: 0.5712  data_time: 0.0838  last_data_time: 0.0742   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:30:15 d2.utils.events]: \u001b[0m eta: 1:17:10  iter: 1339  total_loss: 0.1223  loss_cls: 0.04806  loss_box_reg: 0.06265  loss_rpn_cls: 0.002453  loss_rpn_loc: 0.008493    time: 0.5679  last_time: 0.5632  data_time: 0.0804  last_data_time: 0.0831   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:30:26 d2.utils.events]: \u001b[0m eta: 1:16:56  iter: 1359  total_loss: 0.1443  loss_cls: 0.05912  loss_box_reg: 0.0799  loss_rpn_cls: 0.003585  loss_rpn_loc: 0.01088    time: 0.5679  last_time: 0.5111  data_time: 0.0818  last_data_time: 0.0734   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:30:38 d2.utils.events]: \u001b[0m eta: 1:16:43  iter: 1379  total_loss: 0.1335  loss_cls: 0.04886  loss_box_reg: 0.07225  loss_rpn_cls: 0.002755  loss_rpn_loc: 0.009088    time: 0.5677  last_time: 0.5411  data_time: 0.0818  last_data_time: 0.0698   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:30:49 d2.utils.events]: \u001b[0m eta: 1:16:30  iter: 1399  total_loss: 0.1113  loss_cls: 0.04154  loss_box_reg: 0.05503  loss_rpn_cls: 0.002514  loss_rpn_loc: 0.007251    time: 0.5676  last_time: 0.7205  data_time: 0.0761  last_data_time: 0.1052   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:31:00 d2.utils.events]: \u001b[0m eta: 1:16:17  iter: 1419  total_loss: 0.1335  loss_cls: 0.04546  loss_box_reg: 0.07514  loss_rpn_cls: 0.002374  loss_rpn_loc: 0.007834    time: 0.5675  last_time: 0.6202  data_time: 0.0761  last_data_time: 0.0889   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:31:11 d2.utils.events]: \u001b[0m eta: 1:16:06  iter: 1439  total_loss: 0.1507  loss_cls: 0.05907  loss_box_reg: 0.07958  loss_rpn_cls: 0.002078  loss_rpn_loc: 0.008807    time: 0.5674  last_time: 0.5170  data_time: 0.0797  last_data_time: 0.0638   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:31:22 d2.utils.events]: \u001b[0m eta: 1:15:55  iter: 1459  total_loss: 0.1191  loss_cls: 0.04728  loss_box_reg: 0.0609  loss_rpn_cls: 0.003099  loss_rpn_loc: 0.007944    time: 0.5673  last_time: 0.5447  data_time: 0.0829  last_data_time: 0.0755   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:31:34 d2.utils.events]: \u001b[0m eta: 1:15:44  iter: 1479  total_loss: 0.1239  loss_cls: 0.04377  loss_box_reg: 0.06515  loss_rpn_cls: 0.002655  loss_rpn_loc: 0.007051    time: 0.5674  last_time: 0.5731  data_time: 0.0886  last_data_time: 0.0927   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:31:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[05/07 18:31:47 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[05/07 18:31:47 d2.data.common]: \u001b[0mSerializing 392 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/07 18:31:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/07 18:31:47 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "\u001b[32m[05/07 18:31:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 392 batches\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[32m[05/07 18:31:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/392. Dataloading: 0.0014 s/iter. Inference: 0.0352 s/iter. Eval: 0.0004 s/iter. Total: 0.0370 s/iter. ETA=0:00:14\n",
            "\u001b[32m[05/07 18:31:53 d2.evaluation.evaluator]: \u001b[0mInference done 113/392. Dataloading: 0.0040 s/iter. Inference: 0.0440 s/iter. Eval: 0.0004 s/iter. Total: 0.0485 s/iter. ETA=0:00:13\n",
            "\u001b[32m[05/07 18:31:58 d2.evaluation.evaluator]: \u001b[0mInference done 245/392. Dataloading: 0.0029 s/iter. Inference: 0.0394 s/iter. Eval: 0.0004 s/iter. Total: 0.0427 s/iter. ETA=0:00:06\n",
            "\u001b[32m[05/07 18:32:03 d2.evaluation.evaluator]: \u001b[0mInference done 375/392. Dataloading: 0.0026 s/iter. Inference: 0.0382 s/iter. Eval: 0.0004 s/iter. Total: 0.0412 s/iter. ETA=0:00:00\n",
            "\u001b[32m[05/07 18:32:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.120584 (0.041655 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 18:32:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.038380 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 18:32:03 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/07 18:32:03 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
            "\u001b[32m[05/07 18:32:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[05/07 18:32:04 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[05/07 18:32:04 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.07 seconds.\n",
            "\u001b[32m[05/07 18:32:04 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[05/07 18:32:04 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.467\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.788\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.512\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.287\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.481\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.464\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.590\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.604\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.434\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.619\n",
            "\u001b[32m[05/07 18:32:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 46.708 | 78.792 | 51.239 |  nan  | 28.709 | 48.123 |\n",
            "\u001b[32m[05/07 18:32:04 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[05/07 18:32:04 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| Axe        | 36.904 | Handgun    | 51.233 | Knife      | 51.988 |\n",
            "\u001b[32m[05/07 18:32:04 d2.engine.defaults]: \u001b[0mEvaluation results for intruder_valid in csv format:\n",
            "\u001b[32m[05/07 18:32:04 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/07 18:32:04 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/07 18:32:04 d2.evaluation.testing]: \u001b[0mcopypaste: 46.7085,78.7919,51.2389,nan,28.7087,48.1230\n",
            "\u001b[32m[05/07 18:32:04 d2.utils.events]: \u001b[0m eta: 1:15:34  iter: 1499  total_loss: 0.1225  loss_cls: 0.04711  loss_box_reg: 0.0648  loss_rpn_cls: 0.00255  loss_rpn_loc: 0.006953    time: 0.5673  last_time: 0.5136  data_time: 0.0875  last_data_time: 0.0653   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:32:15 d2.utils.events]: \u001b[0m eta: 1:15:22  iter: 1519  total_loss: 0.1131  loss_cls: 0.04137  loss_box_reg: 0.06208  loss_rpn_cls: 0.002728  loss_rpn_loc: 0.006773    time: 0.5671  last_time: 0.5426  data_time: 0.0753  last_data_time: 0.0601   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:32:26 d2.utils.events]: \u001b[0m eta: 1:15:10  iter: 1539  total_loss: 0.1269  loss_cls: 0.04413  loss_box_reg: 0.07061  loss_rpn_cls: 0.001761  loss_rpn_loc: 0.005984    time: 0.5671  last_time: 0.4731  data_time: 0.0845  last_data_time: 0.0623   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:32:37 d2.utils.events]: \u001b[0m eta: 1:14:57  iter: 1559  total_loss: 0.1225  loss_cls: 0.04347  loss_box_reg: 0.06417  loss_rpn_cls: 0.002049  loss_rpn_loc: 0.007848    time: 0.5669  last_time: 0.5433  data_time: 0.0759  last_data_time: 0.0849   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:32:48 d2.utils.events]: \u001b[0m eta: 1:14:43  iter: 1579  total_loss: 0.124  loss_cls: 0.04443  loss_box_reg: 0.06993  loss_rpn_cls: 0.002613  loss_rpn_loc: 0.009584    time: 0.5668  last_time: 0.5397  data_time: 0.0815  last_data_time: 0.0706   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:32:59 d2.utils.events]: \u001b[0m eta: 1:14:31  iter: 1599  total_loss: 0.1049  loss_cls: 0.0373  loss_box_reg: 0.05623  loss_rpn_cls: 0.001848  loss_rpn_loc: 0.007514    time: 0.5666  last_time: 0.5528  data_time: 0.0774  last_data_time: 0.0629   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:33:11 d2.utils.events]: \u001b[0m eta: 1:14:16  iter: 1619  total_loss: 0.105  loss_cls: 0.03765  loss_box_reg: 0.05801  loss_rpn_cls: 0.002081  loss_rpn_loc: 0.006268    time: 0.5665  last_time: 0.5506  data_time: 0.0833  last_data_time: 0.0849   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:33:22 d2.utils.events]: \u001b[0m eta: 1:14:05  iter: 1639  total_loss: 0.101  loss_cls: 0.03458  loss_box_reg: 0.05566  loss_rpn_cls: 0.002405  loss_rpn_loc: 0.005957    time: 0.5665  last_time: 0.5375  data_time: 0.0850  last_data_time: 0.0694   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:33:33 d2.utils.events]: \u001b[0m eta: 1:13:51  iter: 1659  total_loss: 0.1139  loss_cls: 0.0391  loss_box_reg: 0.06233  loss_rpn_cls: 0.002184  loss_rpn_loc: 0.006716    time: 0.5663  last_time: 0.6210  data_time: 0.0831  last_data_time: 0.0981   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:33:44 d2.utils.events]: \u001b[0m eta: 1:13:38  iter: 1679  total_loss: 0.1215  loss_cls: 0.04023  loss_box_reg: 0.07439  loss_rpn_cls: 0.00183  loss_rpn_loc: 0.008731    time: 0.5661  last_time: 0.5924  data_time: 0.0788  last_data_time: 0.0738   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:33:55 d2.utils.events]: \u001b[0m eta: 1:13:25  iter: 1699  total_loss: 0.1037  loss_cls: 0.04086  loss_box_reg: 0.05832  loss_rpn_cls: 0.001947  loss_rpn_loc: 0.006704    time: 0.5659  last_time: 0.5492  data_time: 0.0809  last_data_time: 0.0678   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:34:06 d2.utils.events]: \u001b[0m eta: 1:13:13  iter: 1719  total_loss: 0.1141  loss_cls: 0.03901  loss_box_reg: 0.05739  loss_rpn_cls: 0.001221  loss_rpn_loc: 0.007326    time: 0.5658  last_time: 0.5376  data_time: 0.0794  last_data_time: 0.0682   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:34:17 d2.utils.events]: \u001b[0m eta: 1:13:02  iter: 1739  total_loss: 0.09919  loss_cls: 0.03407  loss_box_reg: 0.0554  loss_rpn_cls: 0.001343  loss_rpn_loc: 0.006805    time: 0.5658  last_time: 0.5102  data_time: 0.0780  last_data_time: 0.0723   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:34:28 d2.utils.events]: \u001b[0m eta: 1:12:48  iter: 1759  total_loss: 0.1161  loss_cls: 0.04271  loss_box_reg: 0.06008  loss_rpn_cls: 0.001999  loss_rpn_loc: 0.007538    time: 0.5656  last_time: 0.5022  data_time: 0.0770  last_data_time: 0.0767   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:34:39 d2.utils.events]: \u001b[0m eta: 1:12:35  iter: 1779  total_loss: 0.09096  loss_cls: 0.03349  loss_box_reg: 0.05209  loss_rpn_cls: 0.0007972  loss_rpn_loc: 0.005259    time: 0.5655  last_time: 0.4888  data_time: 0.0799  last_data_time: 0.0611   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:34:51 d2.utils.events]: \u001b[0m eta: 1:12:24  iter: 1799  total_loss: 0.1039  loss_cls: 0.0369  loss_box_reg: 0.06067  loss_rpn_cls: 0.001545  loss_rpn_loc: 0.00611    time: 0.5654  last_time: 0.5359  data_time: 0.0790  last_data_time: 0.0681   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:35:02 d2.utils.events]: \u001b[0m eta: 1:12:11  iter: 1819  total_loss: 0.09414  loss_cls: 0.03247  loss_box_reg: 0.05489  loss_rpn_cls: 0.001132  loss_rpn_loc: 0.00686    time: 0.5653  last_time: 0.6197  data_time: 0.0863  last_data_time: 0.0951   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:35:13 d2.utils.events]: \u001b[0m eta: 1:11:57  iter: 1839  total_loss: 0.09213  loss_cls: 0.03406  loss_box_reg: 0.05064  loss_rpn_cls: 0.001429  loss_rpn_loc: 0.005831    time: 0.5651  last_time: 0.6449  data_time: 0.0775  last_data_time: 0.1068   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:35:24 d2.utils.events]: \u001b[0m eta: 1:11:42  iter: 1859  total_loss: 0.102  loss_cls: 0.03499  loss_box_reg: 0.05486  loss_rpn_cls: 0.002339  loss_rpn_loc: 0.006622    time: 0.5649  last_time: 0.5463  data_time: 0.0822  last_data_time: 0.0721   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:35:35 d2.utils.events]: \u001b[0m eta: 1:11:31  iter: 1879  total_loss: 0.1066  loss_cls: 0.03709  loss_box_reg: 0.05934  loss_rpn_cls: 0.001618  loss_rpn_loc: 0.005781    time: 0.5649  last_time: 0.5635  data_time: 0.0792  last_data_time: 0.0826   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:35:46 d2.utils.events]: \u001b[0m eta: 1:11:16  iter: 1899  total_loss: 0.1012  loss_cls: 0.0324  loss_box_reg: 0.06002  loss_rpn_cls: 0.002951  loss_rpn_loc: 0.007451    time: 0.5649  last_time: 0.5370  data_time: 0.0896  last_data_time: 0.0751   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:35:57 d2.utils.events]: \u001b[0m eta: 1:11:03  iter: 1919  total_loss: 0.1035  loss_cls: 0.0343  loss_box_reg: 0.05677  loss_rpn_cls: 0.001095  loss_rpn_loc: 0.005852    time: 0.5648  last_time: 0.5455  data_time: 0.0781  last_data_time: 0.0751   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:36:08 d2.utils.events]: \u001b[0m eta: 1:10:51  iter: 1939  total_loss: 0.113  loss_cls: 0.03856  loss_box_reg: 0.06063  loss_rpn_cls: 0.001392  loss_rpn_loc: 0.009394    time: 0.5647  last_time: 0.5346  data_time: 0.0793  last_data_time: 0.0659   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:36:20 d2.utils.events]: \u001b[0m eta: 1:10:41  iter: 1959  total_loss: 0.1232  loss_cls: 0.04251  loss_box_reg: 0.07185  loss_rpn_cls: 0.001428  loss_rpn_loc: 0.006092    time: 0.5647  last_time: 0.5193  data_time: 0.0885  last_data_time: 0.0789   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:36:31 d2.utils.events]: \u001b[0m eta: 1:10:28  iter: 1979  total_loss: 0.1188  loss_cls: 0.0409  loss_box_reg: 0.06632  loss_rpn_cls: 0.001949  loss_rpn_loc: 0.007926    time: 0.5646  last_time: 0.5472  data_time: 0.0773  last_data_time: 0.0668   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:36:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[05/07 18:36:44 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[05/07 18:36:44 d2.data.common]: \u001b[0mSerializing 392 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/07 18:36:44 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/07 18:36:44 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "\u001b[32m[05/07 18:36:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 392 batches\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[32m[05/07 18:36:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/392. Dataloading: 0.0018 s/iter. Inference: 0.0352 s/iter. Eval: 0.0004 s/iter. Total: 0.0374 s/iter. ETA=0:00:14\n",
            "\u001b[32m[05/07 18:36:50 d2.evaluation.evaluator]: \u001b[0mInference done 143/392. Dataloading: 0.0021 s/iter. Inference: 0.0354 s/iter. Eval: 0.0003 s/iter. Total: 0.0379 s/iter. ETA=0:00:09\n",
            "\u001b[32m[05/07 18:36:55 d2.evaluation.evaluator]: \u001b[0mInference done 253/392. Dataloading: 0.0029 s/iter. Inference: 0.0380 s/iter. Eval: 0.0004 s/iter. Total: 0.0413 s/iter. ETA=0:00:05\n",
            "\u001b[32m[05/07 18:37:00 d2.evaluation.evaluator]: \u001b[0mInference done 379/392. Dataloading: 0.0027 s/iter. Inference: 0.0377 s/iter. Eval: 0.0004 s/iter. Total: 0.0408 s/iter. ETA=0:00:00\n",
            "\u001b[32m[05/07 18:37:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.802092 (0.040832 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 18:37:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.037523 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 18:37:00 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/07 18:37:00 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
            "\u001b[32m[05/07 18:37:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[05/07 18:37:00 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[05/07 18:37:00 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.04 seconds.\n",
            "\u001b[32m[05/07 18:37:00 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[05/07 18:37:00 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.509\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.786\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.583\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.309\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.524\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.482\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.607\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.624\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.489\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.636\n",
            "\u001b[32m[05/07 18:37:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 50.946 | 78.641 | 58.297 |  nan  | 30.933 | 52.393 |\n",
            "\u001b[32m[05/07 18:37:00 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[05/07 18:37:00 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| Axe        | 40.785 | Handgun    | 53.695 | Knife      | 58.358 |\n",
            "\u001b[32m[05/07 18:37:00 d2.engine.defaults]: \u001b[0mEvaluation results for intruder_valid in csv format:\n",
            "\u001b[32m[05/07 18:37:00 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/07 18:37:00 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/07 18:37:00 d2.evaluation.testing]: \u001b[0mcopypaste: 50.9459,78.6411,58.2974,nan,30.9334,52.3934\n",
            "\u001b[32m[05/07 18:37:00 d2.utils.events]: \u001b[0m eta: 1:10:16  iter: 1999  total_loss: 0.1137  loss_cls: 0.03845  loss_box_reg: 0.06313  loss_rpn_cls: 0.001766  loss_rpn_loc: 0.007697    time: 0.5644  last_time: 0.7021  data_time: 0.0756  last_data_time: 0.1455   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:37:12 d2.utils.events]: \u001b[0m eta: 1:10:07  iter: 2019  total_loss: 0.1022  loss_cls: 0.03934  loss_box_reg: 0.05236  loss_rpn_cls: 0.002418  loss_rpn_loc: 0.007147    time: 0.5644  last_time: 0.5514  data_time: 0.0851  last_data_time: 0.0884   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:37:23 d2.utils.events]: \u001b[0m eta: 1:09:59  iter: 2039  total_loss: 0.1336  loss_cls: 0.04734  loss_box_reg: 0.07282  loss_rpn_cls: 0.00276  loss_rpn_loc: 0.008662    time: 0.5644  last_time: 0.5494  data_time: 0.0836  last_data_time: 0.0781   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:37:34 d2.utils.events]: \u001b[0m eta: 1:09:48  iter: 2059  total_loss: 0.1157  loss_cls: 0.04209  loss_box_reg: 0.0679  loss_rpn_cls: 0.0009657  loss_rpn_loc: 0.006602    time: 0.5643  last_time: 0.5429  data_time: 0.0772  last_data_time: 0.0719   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:37:45 d2.utils.events]: \u001b[0m eta: 1:09:36  iter: 2079  total_loss: 0.09741  loss_cls: 0.0336  loss_box_reg: 0.0558  loss_rpn_cls: 0.001541  loss_rpn_loc: 0.006752    time: 0.5643  last_time: 0.6475  data_time: 0.0801  last_data_time: 0.1087   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:37:56 d2.utils.events]: \u001b[0m eta: 1:09:24  iter: 2099  total_loss: 0.09427  loss_cls: 0.03261  loss_box_reg: 0.05321  loss_rpn_cls: 0.001763  loss_rpn_loc: 0.006848    time: 0.5641  last_time: 0.6014  data_time: 0.0786  last_data_time: 0.0884   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:38:07 d2.utils.events]: \u001b[0m eta: 1:09:11  iter: 2119  total_loss: 0.1044  loss_cls: 0.03277  loss_box_reg: 0.05917  loss_rpn_cls: 0.001204  loss_rpn_loc: 0.006243    time: 0.5640  last_time: 0.5356  data_time: 0.0842  last_data_time: 0.0678   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:38:18 d2.utils.events]: \u001b[0m eta: 1:09:00  iter: 2139  total_loss: 0.1023  loss_cls: 0.03318  loss_box_reg: 0.05858  loss_rpn_cls: 0.001041  loss_rpn_loc: 0.007092    time: 0.5639  last_time: 0.5409  data_time: 0.0830  last_data_time: 0.0745   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:38:29 d2.utils.events]: \u001b[0m eta: 1:08:48  iter: 2159  total_loss: 0.1159  loss_cls: 0.03863  loss_box_reg: 0.06622  loss_rpn_cls: 0.001109  loss_rpn_loc: 0.00646    time: 0.5639  last_time: 0.5103  data_time: 0.0894  last_data_time: 0.0792   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:38:41 d2.utils.events]: \u001b[0m eta: 1:08:37  iter: 2179  total_loss: 0.09292  loss_cls: 0.02976  loss_box_reg: 0.05377  loss_rpn_cls: 0.001605  loss_rpn_loc: 0.006216    time: 0.5638  last_time: 0.5627  data_time: 0.0808  last_data_time: 0.0660   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:38:52 d2.utils.events]: \u001b[0m eta: 1:08:25  iter: 2199  total_loss: 0.0953  loss_cls: 0.03354  loss_box_reg: 0.05201  loss_rpn_cls: 0.001123  loss_rpn_loc: 0.00653    time: 0.5637  last_time: 0.5138  data_time: 0.0828  last_data_time: 0.0838   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:39:03 d2.utils.events]: \u001b[0m eta: 1:08:14  iter: 2219  total_loss: 0.09635  loss_cls: 0.03434  loss_box_reg: 0.05559  loss_rpn_cls: 0.0008426  loss_rpn_loc: 0.00525    time: 0.5636  last_time: 0.5495  data_time: 0.0878  last_data_time: 0.0823   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:39:14 d2.utils.events]: \u001b[0m eta: 1:08:03  iter: 2239  total_loss: 0.1157  loss_cls: 0.04021  loss_box_reg: 0.06511  loss_rpn_cls: 0.001795  loss_rpn_loc: 0.009327    time: 0.5635  last_time: 0.6609  data_time: 0.0773  last_data_time: 0.0977   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:39:25 d2.utils.events]: \u001b[0m eta: 1:07:52  iter: 2259  total_loss: 0.09902  loss_cls: 0.03497  loss_box_reg: 0.05508  loss_rpn_cls: 0.002302  loss_rpn_loc: 0.006567    time: 0.5634  last_time: 0.6957  data_time: 0.0803  last_data_time: 0.1272   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:39:36 d2.utils.events]: \u001b[0m eta: 1:07:40  iter: 2279  total_loss: 0.1008  loss_cls: 0.03292  loss_box_reg: 0.05886  loss_rpn_cls: 0.0008698  loss_rpn_loc: 0.007265    time: 0.5634  last_time: 0.5778  data_time: 0.0841  last_data_time: 0.1063   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:39:47 d2.utils.events]: \u001b[0m eta: 1:07:30  iter: 2299  total_loss: 0.09634  loss_cls: 0.03219  loss_box_reg: 0.05541  loss_rpn_cls: 0.0006633  loss_rpn_loc: 0.005431    time: 0.5634  last_time: 0.5596  data_time: 0.0841  last_data_time: 0.0862   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:39:58 d2.utils.events]: \u001b[0m eta: 1:07:18  iter: 2319  total_loss: 0.1131  loss_cls: 0.03643  loss_box_reg: 0.06325  loss_rpn_cls: 0.001137  loss_rpn_loc: 0.006548    time: 0.5633  last_time: 0.5391  data_time: 0.0805  last_data_time: 0.0649   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:40:10 d2.utils.events]: \u001b[0m eta: 1:07:06  iter: 2339  total_loss: 0.09679  loss_cls: 0.03095  loss_box_reg: 0.05316  loss_rpn_cls: 0.00152  loss_rpn_loc: 0.007185    time: 0.5632  last_time: 0.5932  data_time: 0.0853  last_data_time: 0.1015   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:40:21 d2.utils.events]: \u001b[0m eta: 1:06:53  iter: 2359  total_loss: 0.1025  loss_cls: 0.03395  loss_box_reg: 0.06196  loss_rpn_cls: 0.001449  loss_rpn_loc: 0.006179    time: 0.5632  last_time: 0.5176  data_time: 0.0812  last_data_time: 0.0816   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:40:32 d2.utils.events]: \u001b[0m eta: 1:06:42  iter: 2379  total_loss: 0.1067  loss_cls: 0.03649  loss_box_reg: 0.05632  loss_rpn_cls: 0.001699  loss_rpn_loc: 0.00718    time: 0.5632  last_time: 0.5227  data_time: 0.0747  last_data_time: 0.0761   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:40:43 d2.utils.events]: \u001b[0m eta: 1:06:33  iter: 2399  total_loss: 0.09718  loss_cls: 0.03301  loss_box_reg: 0.05613  loss_rpn_cls: 0.001201  loss_rpn_loc: 0.006928    time: 0.5632  last_time: 0.5436  data_time: 0.0774  last_data_time: 0.0794   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:40:55 d2.utils.events]: \u001b[0m eta: 1:06:20  iter: 2419  total_loss: 0.1128  loss_cls: 0.04089  loss_box_reg: 0.06266  loss_rpn_cls: 0.0018  loss_rpn_loc: 0.006816    time: 0.5632  last_time: 0.6414  data_time: 0.0737  last_data_time: 0.0991   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:41:05 d2.utils.events]: \u001b[0m eta: 1:06:08  iter: 2439  total_loss: 0.09426  loss_cls: 0.03361  loss_box_reg: 0.05269  loss_rpn_cls: 0.001925  loss_rpn_loc: 0.006001    time: 0.5629  last_time: 0.6419  data_time: 0.0720  last_data_time: 0.0814   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:41:16 d2.utils.events]: \u001b[0m eta: 1:05:55  iter: 2459  total_loss: 0.1109  loss_cls: 0.03748  loss_box_reg: 0.06122  loss_rpn_cls: 0.0018  loss_rpn_loc: 0.00605    time: 0.5629  last_time: 0.5328  data_time: 0.0780  last_data_time: 0.0647   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:41:28 d2.utils.events]: \u001b[0m eta: 1:05:43  iter: 2479  total_loss: 0.09903  loss_cls: 0.03288  loss_box_reg: 0.05708  loss_rpn_cls: 0.0008108  loss_rpn_loc: 0.006077    time: 0.5628  last_time: 0.5340  data_time: 0.0827  last_data_time: 0.0560   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:41:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[05/07 18:41:41 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[05/07 18:41:41 d2.data.common]: \u001b[0mSerializing 392 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/07 18:41:41 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/07 18:41:41 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "\u001b[32m[05/07 18:41:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 392 batches\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[32m[05/07 18:41:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/392. Dataloading: 0.0015 s/iter. Inference: 0.0359 s/iter. Eval: 0.0003 s/iter. Total: 0.0378 s/iter. ETA=0:00:14\n",
            "\u001b[32m[05/07 18:41:46 d2.evaluation.evaluator]: \u001b[0mInference done 111/392. Dataloading: 0.0045 s/iter. Inference: 0.0445 s/iter. Eval: 0.0004 s/iter. Total: 0.0495 s/iter. ETA=0:00:13\n",
            "\u001b[32m[05/07 18:41:51 d2.evaluation.evaluator]: \u001b[0mInference done 244/392. Dataloading: 0.0030 s/iter. Inference: 0.0395 s/iter. Eval: 0.0004 s/iter. Total: 0.0429 s/iter. ETA=0:00:06\n",
            "\u001b[32m[05/07 18:41:56 d2.evaluation.evaluator]: \u001b[0mInference done 360/392. Dataloading: 0.0031 s/iter. Inference: 0.0395 s/iter. Eval: 0.0003 s/iter. Total: 0.0430 s/iter. ETA=0:00:01\n",
            "\u001b[32m[05/07 18:41:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.079936 (0.044134 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 18:41:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.040294 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 18:41:58 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/07 18:41:58 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
            "\u001b[32m[05/07 18:41:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[05/07 18:41:58 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[05/07 18:41:58 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.04 seconds.\n",
            "\u001b[32m[05/07 18:41:58 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[05/07 18:41:58 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.495\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.796\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.556\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.278\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.508\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.474\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.587\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.600\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.400\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.613\n",
            "\u001b[32m[05/07 18:41:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 49.476 | 79.618 | 55.636 |  nan  | 27.845 | 50.781 |\n",
            "\u001b[32m[05/07 18:41:58 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[05/07 18:41:58 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| Axe        | 42.333 | Handgun    | 49.438 | Knife      | 56.656 |\n",
            "\u001b[32m[05/07 18:41:58 d2.engine.defaults]: \u001b[0mEvaluation results for intruder_valid in csv format:\n",
            "\u001b[32m[05/07 18:41:58 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/07 18:41:58 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/07 18:41:58 d2.evaluation.testing]: \u001b[0mcopypaste: 49.4755,79.6182,55.6364,nan,27.8447,50.7814\n",
            "\u001b[32m[05/07 18:41:58 d2.utils.events]: \u001b[0m eta: 1:05:32  iter: 2499  total_loss: 0.1031  loss_cls: 0.0337  loss_box_reg: 0.0582  loss_rpn_cls: 0.001278  loss_rpn_loc: 0.006901    time: 0.5628  last_time: 0.5519  data_time: 0.0810  last_data_time: 0.0740   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:42:09 d2.utils.events]: \u001b[0m eta: 1:05:21  iter: 2519  total_loss: 0.08574  loss_cls: 0.02901  loss_box_reg: 0.04843  loss_rpn_cls: 0.001254  loss_rpn_loc: 0.006145    time: 0.5627  last_time: 0.6792  data_time: 0.0724  last_data_time: 0.1426   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:42:20 d2.utils.events]: \u001b[0m eta: 1:05:08  iter: 2539  total_loss: 0.08685  loss_cls: 0.02971  loss_box_reg: 0.05322  loss_rpn_cls: 0.0006195  loss_rpn_loc: 0.006319    time: 0.5626  last_time: 0.5483  data_time: 0.0838  last_data_time: 0.0654   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:42:31 d2.utils.events]: \u001b[0m eta: 1:04:59  iter: 2559  total_loss: 0.1068  loss_cls: 0.03473  loss_box_reg: 0.06372  loss_rpn_cls: 0.0008585  loss_rpn_loc: 0.006317    time: 0.5626  last_time: 0.5590  data_time: 0.0801  last_data_time: 0.0855   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:42:43 d2.utils.events]: \u001b[0m eta: 1:04:48  iter: 2579  total_loss: 0.09907  loss_cls: 0.03397  loss_box_reg: 0.0559  loss_rpn_cls: 0.001204  loss_rpn_loc: 0.006725    time: 0.5625  last_time: 0.5231  data_time: 0.0810  last_data_time: 0.0483   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:42:54 d2.utils.events]: \u001b[0m eta: 1:04:36  iter: 2599  total_loss: 0.1072  loss_cls: 0.03426  loss_box_reg: 0.06513  loss_rpn_cls: 0.001194  loss_rpn_loc: 0.007585    time: 0.5624  last_time: 0.4944  data_time: 0.0835  last_data_time: 0.0649   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:43:05 d2.utils.events]: \u001b[0m eta: 1:04:25  iter: 2619  total_loss: 0.087  loss_cls: 0.03081  loss_box_reg: 0.04834  loss_rpn_cls: 0.001162  loss_rpn_loc: 0.006725    time: 0.5624  last_time: 0.5373  data_time: 0.0717  last_data_time: 0.0771   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:43:16 d2.utils.events]: \u001b[0m eta: 1:04:16  iter: 2639  total_loss: 0.09251  loss_cls: 0.0316  loss_box_reg: 0.04676  loss_rpn_cls: 0.0008619  loss_rpn_loc: 0.005855    time: 0.5624  last_time: 0.5487  data_time: 0.0837  last_data_time: 0.0856   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:43:27 d2.utils.events]: \u001b[0m eta: 1:04:06  iter: 2659  total_loss: 0.09829  loss_cls: 0.03294  loss_box_reg: 0.05947  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007074    time: 0.5624  last_time: 0.5395  data_time: 0.0817  last_data_time: 0.0602   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:43:38 d2.utils.events]: \u001b[0m eta: 1:03:54  iter: 2679  total_loss: 0.09771  loss_cls: 0.03269  loss_box_reg: 0.05365  loss_rpn_cls: 0.001109  loss_rpn_loc: 0.006569    time: 0.5624  last_time: 0.6209  data_time: 0.0784  last_data_time: 0.1329   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:43:49 d2.utils.events]: \u001b[0m eta: 1:03:45  iter: 2699  total_loss: 0.09259  loss_cls: 0.03071  loss_box_reg: 0.05608  loss_rpn_cls: 0.0005889  loss_rpn_loc: 0.005908    time: 0.5623  last_time: 0.6387  data_time: 0.0773  last_data_time: 0.1045   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:44:01 d2.utils.events]: \u001b[0m eta: 1:03:35  iter: 2719  total_loss: 0.0834  loss_cls: 0.02849  loss_box_reg: 0.04694  loss_rpn_cls: 0.001009  loss_rpn_loc: 0.006292    time: 0.5622  last_time: 0.5339  data_time: 0.0772  last_data_time: 0.0561   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:44:12 d2.utils.events]: \u001b[0m eta: 1:03:24  iter: 2739  total_loss: 0.1022  loss_cls: 0.0298  loss_box_reg: 0.061  loss_rpn_cls: 0.001408  loss_rpn_loc: 0.005805    time: 0.5623  last_time: 0.5046  data_time: 0.0781  last_data_time: 0.0618   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:44:23 d2.utils.events]: \u001b[0m eta: 1:03:14  iter: 2759  total_loss: 0.1074  loss_cls: 0.03733  loss_box_reg: 0.05923  loss_rpn_cls: 0.001163  loss_rpn_loc: 0.004869    time: 0.5623  last_time: 0.4980  data_time: 0.0798  last_data_time: 0.0735   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:44:34 d2.utils.events]: \u001b[0m eta: 1:03:02  iter: 2779  total_loss: 0.08284  loss_cls: 0.02644  loss_box_reg: 0.04748  loss_rpn_cls: 0.0007143  loss_rpn_loc: 0.007369    time: 0.5623  last_time: 0.5066  data_time: 0.0867  last_data_time: 0.0757   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:44:45 d2.utils.events]: \u001b[0m eta: 1:02:52  iter: 2799  total_loss: 0.08929  loss_cls: 0.02925  loss_box_reg: 0.05206  loss_rpn_cls: 0.001342  loss_rpn_loc: 0.006329    time: 0.5622  last_time: 0.5522  data_time: 0.0802  last_data_time: 0.0945   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:44:57 d2.utils.events]: \u001b[0m eta: 1:02:42  iter: 2819  total_loss: 0.08859  loss_cls: 0.02916  loss_box_reg: 0.05226  loss_rpn_cls: 0.0008782  loss_rpn_loc: 0.006446    time: 0.5622  last_time: 0.5513  data_time: 0.0810  last_data_time: 0.0736   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:45:08 d2.utils.events]: \u001b[0m eta: 1:02:30  iter: 2839  total_loss: 0.08927  loss_cls: 0.02959  loss_box_reg: 0.05266  loss_rpn_cls: 0.001226  loss_rpn_loc: 0.005675    time: 0.5621  last_time: 0.5012  data_time: 0.0783  last_data_time: 0.0666   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:45:19 d2.utils.events]: \u001b[0m eta: 1:02:21  iter: 2859  total_loss: 0.07927  loss_cls: 0.02389  loss_box_reg: 0.04591  loss_rpn_cls: 0.0007561  loss_rpn_loc: 0.006201    time: 0.5620  last_time: 0.7080  data_time: 0.0781  last_data_time: 0.1193   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:45:30 d2.utils.events]: \u001b[0m eta: 1:02:07  iter: 2879  total_loss: 0.09605  loss_cls: 0.03234  loss_box_reg: 0.05393  loss_rpn_cls: 0.001296  loss_rpn_loc: 0.00541    time: 0.5620  last_time: 0.5736  data_time: 0.0773  last_data_time: 0.1066   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:45:41 d2.utils.events]: \u001b[0m eta: 1:01:57  iter: 2899  total_loss: 0.1198  loss_cls: 0.03341  loss_box_reg: 0.06926  loss_rpn_cls: 0.001014  loss_rpn_loc: 0.006622    time: 0.5620  last_time: 0.5762  data_time: 0.0851  last_data_time: 0.0747   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:45:53 d2.utils.events]: \u001b[0m eta: 1:01:47  iter: 2919  total_loss: 0.08577  loss_cls: 0.0304  loss_box_reg: 0.04998  loss_rpn_cls: 0.001027  loss_rpn_loc: 0.006724    time: 0.5620  last_time: 0.5512  data_time: 0.0927  last_data_time: 0.0672   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:46:04 d2.utils.events]: \u001b[0m eta: 1:01:37  iter: 2939  total_loss: 0.08536  loss_cls: 0.02604  loss_box_reg: 0.05165  loss_rpn_cls: 0.001151  loss_rpn_loc: 0.006316    time: 0.5620  last_time: 0.5659  data_time: 0.0822  last_data_time: 0.0832   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:46:15 d2.utils.events]: \u001b[0m eta: 1:01:26  iter: 2959  total_loss: 0.08604  loss_cls: 0.02568  loss_box_reg: 0.05385  loss_rpn_cls: 0.0009662  loss_rpn_loc: 0.00614    time: 0.5620  last_time: 0.5514  data_time: 0.0807  last_data_time: 0.0754   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:46:26 d2.utils.events]: \u001b[0m eta: 1:01:17  iter: 2979  total_loss: 0.09672  loss_cls: 0.03205  loss_box_reg: 0.0544  loss_rpn_cls: 0.000693  loss_rpn_loc: 0.006064    time: 0.5620  last_time: 0.5405  data_time: 0.0822  last_data_time: 0.0669   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:46:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[05/07 18:46:39 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[05/07 18:46:39 d2.data.common]: \u001b[0mSerializing 392 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/07 18:46:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/07 18:46:39 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "\u001b[32m[05/07 18:46:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 392 batches\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[32m[05/07 18:46:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/392. Dataloading: 0.0013 s/iter. Inference: 0.0367 s/iter. Eval: 0.0003 s/iter. Total: 0.0382 s/iter. ETA=0:00:14\n",
            "\u001b[32m[05/07 18:46:45 d2.evaluation.evaluator]: \u001b[0mInference done 140/392. Dataloading: 0.0022 s/iter. Inference: 0.0361 s/iter. Eval: 0.0003 s/iter. Total: 0.0387 s/iter. ETA=0:00:09\n",
            "\u001b[32m[05/07 18:46:50 d2.evaluation.evaluator]: \u001b[0mInference done 238/392. Dataloading: 0.0031 s/iter. Inference: 0.0405 s/iter. Eval: 0.0003 s/iter. Total: 0.0440 s/iter. ETA=0:00:06\n",
            "\u001b[32m[05/07 18:46:55 d2.evaluation.evaluator]: \u001b[0mInference done 370/392. Dataloading: 0.0027 s/iter. Inference: 0.0388 s/iter. Eval: 0.0003 s/iter. Total: 0.0418 s/iter. ETA=0:00:00\n",
            "\u001b[32m[05/07 18:46:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.137440 (0.041699 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 18:46:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.038508 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 18:46:56 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/07 18:46:56 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
            "\u001b[32m[05/07 18:46:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[05/07 18:46:56 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[05/07 18:46:56 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.04 seconds.\n",
            "\u001b[32m[05/07 18:46:56 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[05/07 18:46:56 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.483\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.788\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.511\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.276\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.496\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.471\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.585\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.599\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.393\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.613\n",
            "\u001b[32m[05/07 18:46:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 48.349 | 78.797 | 51.141 |  nan  | 27.617 | 49.620 |\n",
            "\u001b[32m[05/07 18:46:56 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[05/07 18:46:56 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| Axe        | 42.442 | Handgun    | 46.983 | Knife      | 55.621 |\n",
            "\u001b[32m[05/07 18:46:56 d2.engine.defaults]: \u001b[0mEvaluation results for intruder_valid in csv format:\n",
            "\u001b[32m[05/07 18:46:56 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/07 18:46:56 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/07 18:46:56 d2.evaluation.testing]: \u001b[0mcopypaste: 48.3490,78.7966,51.1410,nan,27.6169,49.6204\n",
            "\u001b[32m[05/07 18:46:56 d2.utils.events]: \u001b[0m eta: 1:01:08  iter: 2999  total_loss: 0.08444  loss_cls: 0.02855  loss_box_reg: 0.05102  loss_rpn_cls: 0.001405  loss_rpn_loc: 0.006416    time: 0.5619  last_time: 0.5074  data_time: 0.0798  last_data_time: 0.0378   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:47:07 d2.utils.events]: \u001b[0m eta: 1:00:57  iter: 3019  total_loss: 0.08912  loss_cls: 0.03049  loss_box_reg: 0.05382  loss_rpn_cls: 0.0009493  loss_rpn_loc: 0.00692    time: 0.5619  last_time: 0.5455  data_time: 0.0855  last_data_time: 0.0720   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:47:18 d2.utils.events]: \u001b[0m eta: 1:00:46  iter: 3039  total_loss: 0.08957  loss_cls: 0.02695  loss_box_reg: 0.05086  loss_rpn_cls: 0.001218  loss_rpn_loc: 0.009128    time: 0.5619  last_time: 0.5210  data_time: 0.0802  last_data_time: 0.0796   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:47:29 d2.utils.events]: \u001b[0m eta: 1:00:36  iter: 3059  total_loss: 0.08717  loss_cls: 0.02825  loss_box_reg: 0.05136  loss_rpn_cls: 0.0008347  loss_rpn_loc: 0.005333    time: 0.5619  last_time: 0.5056  data_time: 0.0809  last_data_time: 0.0790   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:47:40 d2.utils.events]: \u001b[0m eta: 1:00:24  iter: 3079  total_loss: 0.08529  loss_cls: 0.02709  loss_box_reg: 0.04943  loss_rpn_cls: 0.001177  loss_rpn_loc: 0.005891    time: 0.5618  last_time: 0.5138  data_time: 0.0766  last_data_time: 0.0701   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:47:52 d2.utils.events]: \u001b[0m eta: 1:00:13  iter: 3099  total_loss: 0.0899  loss_cls: 0.02885  loss_box_reg: 0.05301  loss_rpn_cls: 0.0005929  loss_rpn_loc: 0.005904    time: 0.5618  last_time: 0.6780  data_time: 0.0812  last_data_time: 0.0997   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:48:03 d2.utils.events]: \u001b[0m eta: 1:00:03  iter: 3119  total_loss: 0.07601  loss_cls: 0.02389  loss_box_reg: 0.04328  loss_rpn_cls: 0.0005985  loss_rpn_loc: 0.006051    time: 0.5617  last_time: 0.7391  data_time: 0.0785  last_data_time: 0.2045   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:48:14 d2.utils.events]: \u001b[0m eta: 0:59:52  iter: 3139  total_loss: 0.08713  loss_cls: 0.0254  loss_box_reg: 0.05188  loss_rpn_cls: 0.0007045  loss_rpn_loc: 0.00659    time: 0.5617  last_time: 0.5574  data_time: 0.0829  last_data_time: 0.0786   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:48:25 d2.utils.events]: \u001b[0m eta: 0:59:41  iter: 3159  total_loss: 0.09439  loss_cls: 0.02912  loss_box_reg: 0.05594  loss_rpn_cls: 0.0007203  loss_rpn_loc: 0.00595    time: 0.5617  last_time: 0.5267  data_time: 0.0742  last_data_time: 0.0397   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:48:36 d2.utils.events]: \u001b[0m eta: 0:59:31  iter: 3179  total_loss: 0.07723  loss_cls: 0.02519  loss_box_reg: 0.04624  loss_rpn_cls: 0.0007224  loss_rpn_loc: 0.006244    time: 0.5617  last_time: 0.5562  data_time: 0.0796  last_data_time: 0.0882   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:48:47 d2.utils.events]: \u001b[0m eta: 0:59:21  iter: 3199  total_loss: 0.09229  loss_cls: 0.02732  loss_box_reg: 0.05178  loss_rpn_cls: 0.001211  loss_rpn_loc: 0.008375    time: 0.5617  last_time: 0.5656  data_time: 0.0794  last_data_time: 0.0851   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:48:59 d2.utils.events]: \u001b[0m eta: 0:59:10  iter: 3219  total_loss: 0.08034  loss_cls: 0.0307  loss_box_reg: 0.04394  loss_rpn_cls: 0.0009519  loss_rpn_loc: 0.005534    time: 0.5617  last_time: 0.5380  data_time: 0.0778  last_data_time: 0.0704   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:49:10 d2.utils.events]: \u001b[0m eta: 0:58:59  iter: 3239  total_loss: 0.07938  loss_cls: 0.02465  loss_box_reg: 0.04957  loss_rpn_cls: 0.0009116  loss_rpn_loc: 0.006681    time: 0.5617  last_time: 0.5465  data_time: 0.0835  last_data_time: 0.0745   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:49:21 d2.utils.events]: \u001b[0m eta: 0:58:48  iter: 3259  total_loss: 0.08035  loss_cls: 0.02718  loss_box_reg: 0.04927  loss_rpn_cls: 0.0009956  loss_rpn_loc: 0.005636    time: 0.5617  last_time: 0.5559  data_time: 0.0827  last_data_time: 0.0839   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:49:33 d2.utils.events]: \u001b[0m eta: 0:58:39  iter: 3279  total_loss: 0.09316  loss_cls: 0.03246  loss_box_reg: 0.05524  loss_rpn_cls: 0.0009616  loss_rpn_loc: 0.00643    time: 0.5617  last_time: 0.5432  data_time: 0.0853  last_data_time: 0.0770   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:49:44 d2.utils.events]: \u001b[0m eta: 0:58:27  iter: 3299  total_loss: 0.08729  loss_cls: 0.02708  loss_box_reg: 0.05094  loss_rpn_cls: 0.0005638  loss_rpn_loc: 0.00551    time: 0.5617  last_time: 0.7301  data_time: 0.0801  last_data_time: 0.0943   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:49:55 d2.utils.events]: \u001b[0m eta: 0:58:18  iter: 3319  total_loss: 0.09771  loss_cls: 0.03244  loss_box_reg: 0.058  loss_rpn_cls: 0.001175  loss_rpn_loc: 0.006476    time: 0.5617  last_time: 0.5203  data_time: 0.0821  last_data_time: 0.0606   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:50:06 d2.utils.events]: \u001b[0m eta: 0:58:07  iter: 3339  total_loss: 0.07942  loss_cls: 0.0272  loss_box_reg: 0.04904  loss_rpn_cls: 0.0006705  loss_rpn_loc: 0.00565    time: 0.5616  last_time: 0.5555  data_time: 0.0732  last_data_time: 0.0915   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:50:17 d2.utils.events]: \u001b[0m eta: 0:57:57  iter: 3359  total_loss: 0.09078  loss_cls: 0.02875  loss_box_reg: 0.05657  loss_rpn_cls: 0.001208  loss_rpn_loc: 0.005895    time: 0.5616  last_time: 0.5071  data_time: 0.0792  last_data_time: 0.0688   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:50:29 d2.utils.events]: \u001b[0m eta: 0:57:46  iter: 3379  total_loss: 0.09793  loss_cls: 0.02768  loss_box_reg: 0.05367  loss_rpn_cls: 0.001133  loss_rpn_loc: 0.007926    time: 0.5616  last_time: 0.5690  data_time: 0.0868  last_data_time: 0.0899   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:50:40 d2.utils.events]: \u001b[0m eta: 0:57:34  iter: 3399  total_loss: 0.0695  loss_cls: 0.02404  loss_box_reg: 0.04308  loss_rpn_cls: 0.001087  loss_rpn_loc: 0.005466    time: 0.5616  last_time: 0.5616  data_time: 0.0813  last_data_time: 0.0907   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:50:51 d2.utils.events]: \u001b[0m eta: 0:57:24  iter: 3419  total_loss: 0.08838  loss_cls: 0.0273  loss_box_reg: 0.05082  loss_rpn_cls: 0.0008818  loss_rpn_loc: 0.006825    time: 0.5617  last_time: 0.5136  data_time: 0.0765  last_data_time: 0.0326   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:51:02 d2.utils.events]: \u001b[0m eta: 0:57:13  iter: 3439  total_loss: 0.08365  loss_cls: 0.02509  loss_box_reg: 0.0543  loss_rpn_cls: 0.001058  loss_rpn_loc: 0.007668    time: 0.5616  last_time: 0.5543  data_time: 0.0836  last_data_time: 0.0890   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:51:14 d2.utils.events]: \u001b[0m eta: 0:57:03  iter: 3459  total_loss: 0.07998  loss_cls: 0.02172  loss_box_reg: 0.04533  loss_rpn_cls: 0.001071  loss_rpn_loc: 0.006594    time: 0.5616  last_time: 0.5545  data_time: 0.0813  last_data_time: 0.0834   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:51:24 d2.utils.events]: \u001b[0m eta: 0:56:53  iter: 3479  total_loss: 0.09914  loss_cls: 0.03128  loss_box_reg: 0.05913  loss_rpn_cls: 0.001142  loss_rpn_loc: 0.00531    time: 0.5616  last_time: 0.6537  data_time: 0.0813  last_data_time: 0.1228   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:51:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[05/07 18:51:38 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[05/07 18:51:38 d2.data.common]: \u001b[0mSerializing 392 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/07 18:51:38 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/07 18:51:38 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "\u001b[32m[05/07 18:51:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 392 batches\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[32m[05/07 18:51:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/392. Dataloading: 0.0011 s/iter. Inference: 0.0357 s/iter. Eval: 0.0003 s/iter. Total: 0.0370 s/iter. ETA=0:00:14\n",
            "\u001b[32m[05/07 18:51:44 d2.evaluation.evaluator]: \u001b[0mInference done 142/392. Dataloading: 0.0020 s/iter. Inference: 0.0360 s/iter. Eval: 0.0003 s/iter. Total: 0.0384 s/iter. ETA=0:00:09\n",
            "\u001b[32m[05/07 18:51:49 d2.evaluation.evaluator]: \u001b[0mInference done 259/392. Dataloading: 0.0024 s/iter. Inference: 0.0378 s/iter. Eval: 0.0004 s/iter. Total: 0.0406 s/iter. ETA=0:00:05\n",
            "\u001b[32m[05/07 18:51:54 d2.evaluation.evaluator]: \u001b[0mInference done 371/392. Dataloading: 0.0026 s/iter. Inference: 0.0389 s/iter. Eval: 0.0003 s/iter. Total: 0.0419 s/iter. ETA=0:00:00\n",
            "\u001b[32m[05/07 18:51:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.180651 (0.041810 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 18:51:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.038669 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 18:51:55 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/07 18:51:55 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
            "\u001b[32m[05/07 18:51:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[05/07 18:51:55 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[05/07 18:51:55 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.04 seconds.\n",
            "\u001b[32m[05/07 18:51:55 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[05/07 18:51:55 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.489\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.782\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.552\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.235\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.505\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.472\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.577\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.592\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.377\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.606\n",
            "\u001b[32m[05/07 18:51:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 48.942 | 78.156 | 55.185 |  nan  | 23.520 | 50.517 |\n",
            "\u001b[32m[05/07 18:51:55 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[05/07 18:51:55 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| Axe        | 42.701 | Handgun    | 48.770 | Knife      | 55.355 |\n",
            "\u001b[32m[05/07 18:51:55 d2.engine.defaults]: \u001b[0mEvaluation results for intruder_valid in csv format:\n",
            "\u001b[32m[05/07 18:51:55 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/07 18:51:55 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/07 18:51:55 d2.evaluation.testing]: \u001b[0mcopypaste: 48.9420,78.1560,55.1851,nan,23.5201,50.5166\n",
            "\u001b[32m[05/07 18:51:55 d2.utils.events]: \u001b[0m eta: 0:56:39  iter: 3499  total_loss: 0.08814  loss_cls: 0.02601  loss_box_reg: 0.05112  loss_rpn_cls: 0.0005502  loss_rpn_loc: 0.005361    time: 0.5615  last_time: 0.5541  data_time: 0.0788  last_data_time: 0.0718   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:52:06 d2.utils.events]: \u001b[0m eta: 0:56:31  iter: 3519  total_loss: 0.07677  loss_cls: 0.02463  loss_box_reg: 0.04364  loss_rpn_cls: 0.000946  loss_rpn_loc: 0.00641    time: 0.5615  last_time: 0.5609  data_time: 0.0825  last_data_time: 0.0786   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:52:18 d2.utils.events]: \u001b[0m eta: 0:56:21  iter: 3539  total_loss: 0.08366  loss_cls: 0.02697  loss_box_reg: 0.05159  loss_rpn_cls: 0.000826  loss_rpn_loc: 0.005237    time: 0.5615  last_time: 0.5042  data_time: 0.0802  last_data_time: 0.0792   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:52:29 d2.utils.events]: \u001b[0m eta: 0:56:10  iter: 3559  total_loss: 0.08624  loss_cls: 0.0301  loss_box_reg: 0.04733  loss_rpn_cls: 0.001316  loss_rpn_loc: 0.006221    time: 0.5615  last_time: 0.6724  data_time: 0.0853  last_data_time: 0.1485   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:52:40 d2.utils.events]: \u001b[0m eta: 0:55:59  iter: 3579  total_loss: 0.0826  loss_cls: 0.02569  loss_box_reg: 0.04415  loss_rpn_cls: 0.001165  loss_rpn_loc: 0.006774    time: 0.5614  last_time: 0.6495  data_time: 0.0780  last_data_time: 0.1237   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:52:51 d2.utils.events]: \u001b[0m eta: 0:55:48  iter: 3599  total_loss: 0.09158  loss_cls: 0.02754  loss_box_reg: 0.05364  loss_rpn_cls: 0.0008526  loss_rpn_loc: 0.004947    time: 0.5614  last_time: 0.5474  data_time: 0.0819  last_data_time: 0.0720   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:53:02 d2.utils.events]: \u001b[0m eta: 0:55:38  iter: 3619  total_loss: 0.07272  loss_cls: 0.02211  loss_box_reg: 0.04187  loss_rpn_cls: 0.0004643  loss_rpn_loc: 0.004761    time: 0.5615  last_time: 0.5414  data_time: 0.0930  last_data_time: 0.0609   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:53:14 d2.utils.events]: \u001b[0m eta: 0:55:27  iter: 3639  total_loss: 0.09355  loss_cls: 0.02836  loss_box_reg: 0.05042  loss_rpn_cls: 0.001016  loss_rpn_loc: 0.008378    time: 0.5615  last_time: 0.4914  data_time: 0.0780  last_data_time: 0.0306   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:53:25 d2.utils.events]: \u001b[0m eta: 0:55:16  iter: 3659  total_loss: 0.07637  loss_cls: 0.02472  loss_box_reg: 0.04271  loss_rpn_cls: 0.001038  loss_rpn_loc: 0.007197    time: 0.5615  last_time: 0.5432  data_time: 0.0837  last_data_time: 0.0635   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:53:36 d2.utils.events]: \u001b[0m eta: 0:55:06  iter: 3679  total_loss: 0.07608  loss_cls: 0.02428  loss_box_reg: 0.04657  loss_rpn_cls: 0.000978  loss_rpn_loc: 0.005651    time: 0.5615  last_time: 0.5666  data_time: 0.0818  last_data_time: 0.0998   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:53:47 d2.utils.events]: \u001b[0m eta: 0:54:55  iter: 3699  total_loss: 0.08021  loss_cls: 0.02542  loss_box_reg: 0.0473  loss_rpn_cls: 0.0007779  loss_rpn_loc: 0.006954    time: 0.5615  last_time: 0.5473  data_time: 0.0815  last_data_time: 0.0725   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:53:59 d2.utils.events]: \u001b[0m eta: 0:54:46  iter: 3719  total_loss: 0.07889  loss_cls: 0.02719  loss_box_reg: 0.04387  loss_rpn_cls: 0.0007554  loss_rpn_loc: 0.006469    time: 0.5615  last_time: 0.5003  data_time: 0.0797  last_data_time: 0.0778   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:54:10 d2.utils.events]: \u001b[0m eta: 0:54:33  iter: 3739  total_loss: 0.071  loss_cls: 0.02388  loss_box_reg: 0.04185  loss_rpn_cls: 0.0007569  loss_rpn_loc: 0.004835    time: 0.5616  last_time: 0.5455  data_time: 0.0788  last_data_time: 0.0764   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:54:21 d2.utils.events]: \u001b[0m eta: 0:54:23  iter: 3759  total_loss: 0.0887  loss_cls: 0.02755  loss_box_reg: 0.05329  loss_rpn_cls: 0.0008486  loss_rpn_loc: 0.006226    time: 0.5616  last_time: 0.7235  data_time: 0.0815  last_data_time: 0.1706   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:54:33 d2.utils.events]: \u001b[0m eta: 0:54:15  iter: 3779  total_loss: 0.07963  loss_cls: 0.02531  loss_box_reg: 0.04678  loss_rpn_cls: 0.001115  loss_rpn_loc: 0.007521    time: 0.5615  last_time: 0.5613  data_time: 0.0806  last_data_time: 0.0770   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:54:44 d2.utils.events]: \u001b[0m eta: 0:54:04  iter: 3799  total_loss: 0.08853  loss_cls: 0.03047  loss_box_reg: 0.05138  loss_rpn_cls: 0.0005866  loss_rpn_loc: 0.005883    time: 0.5616  last_time: 0.5448  data_time: 0.0810  last_data_time: 0.0711   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:54:55 d2.utils.events]: \u001b[0m eta: 0:53:53  iter: 3819  total_loss: 0.09185  loss_cls: 0.02688  loss_box_reg: 0.05672  loss_rpn_cls: 0.001192  loss_rpn_loc: 0.006121    time: 0.5616  last_time: 0.5829  data_time: 0.0824  last_data_time: 0.0912   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:55:07 d2.utils.events]: \u001b[0m eta: 0:53:43  iter: 3839  total_loss: 0.07681  loss_cls: 0.0254  loss_box_reg: 0.0471  loss_rpn_cls: 0.001161  loss_rpn_loc: 0.006408    time: 0.5617  last_time: 0.5537  data_time: 0.0844  last_data_time: 0.0760   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:55:18 d2.utils.events]: \u001b[0m eta: 0:53:33  iter: 3859  total_loss: 0.08084  loss_cls: 0.02403  loss_box_reg: 0.04998  loss_rpn_cls: 0.0006927  loss_rpn_loc: 0.005361    time: 0.5617  last_time: 0.5635  data_time: 0.0805  last_data_time: 0.0722   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:55:29 d2.utils.events]: \u001b[0m eta: 0:53:24  iter: 3879  total_loss: 0.08221  loss_cls: 0.0231  loss_box_reg: 0.05247  loss_rpn_cls: 0.001452  loss_rpn_loc: 0.005955    time: 0.5617  last_time: 0.5582  data_time: 0.0814  last_data_time: 0.0764   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:55:41 d2.utils.events]: \u001b[0m eta: 0:53:13  iter: 3899  total_loss: 0.09457  loss_cls: 0.03267  loss_box_reg: 0.05371  loss_rpn_cls: 0.0015  loss_rpn_loc: 0.006441    time: 0.5617  last_time: 0.5698  data_time: 0.0793  last_data_time: 0.0809   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:55:52 d2.utils.events]: \u001b[0m eta: 0:53:02  iter: 3919  total_loss: 0.07391  loss_cls: 0.0254  loss_box_reg: 0.04248  loss_rpn_cls: 0.0004533  loss_rpn_loc: 0.005655    time: 0.5617  last_time: 0.5483  data_time: 0.0873  last_data_time: 0.0718   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:56:03 d2.utils.events]: \u001b[0m eta: 0:52:50  iter: 3939  total_loss: 0.08641  loss_cls: 0.02819  loss_box_reg: 0.04903  loss_rpn_cls: 0.0009871  loss_rpn_loc: 0.006865    time: 0.5617  last_time: 0.7356  data_time: 0.0810  last_data_time: 0.1431   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:56:14 d2.utils.events]: \u001b[0m eta: 0:52:40  iter: 3959  total_loss: 0.08308  loss_cls: 0.02638  loss_box_reg: 0.04946  loss_rpn_cls: 0.001032  loss_rpn_loc: 0.005919    time: 0.5617  last_time: 0.5686  data_time: 0.0793  last_data_time: 0.0780   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:56:26 d2.utils.events]: \u001b[0m eta: 0:52:28  iter: 3979  total_loss: 0.1059  loss_cls: 0.03301  loss_box_reg: 0.06466  loss_rpn_cls: 0.0009138  loss_rpn_loc: 0.006243    time: 0.5617  last_time: 0.5370  data_time: 0.0866  last_data_time: 0.0645   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:56:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[05/07 18:56:39 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[05/07 18:56:39 d2.data.common]: \u001b[0mSerializing 392 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/07 18:56:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/07 18:56:39 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "\u001b[32m[05/07 18:56:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 392 batches\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[32m[05/07 18:56:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/392. Dataloading: 0.0037 s/iter. Inference: 0.0533 s/iter. Eval: 0.0004 s/iter. Total: 0.0573 s/iter. ETA=0:00:21\n",
            "\u001b[32m[05/07 18:56:45 d2.evaluation.evaluator]: \u001b[0mInference done 115/392. Dataloading: 0.0037 s/iter. Inference: 0.0446 s/iter. Eval: 0.0004 s/iter. Total: 0.0488 s/iter. ETA=0:00:13\n",
            "\u001b[32m[05/07 18:56:50 d2.evaluation.evaluator]: \u001b[0mInference done 243/392. Dataloading: 0.0028 s/iter. Inference: 0.0403 s/iter. Eval: 0.0004 s/iter. Total: 0.0436 s/iter. ETA=0:00:06\n",
            "\u001b[32m[05/07 18:56:55 d2.evaluation.evaluator]: \u001b[0mInference done 346/392. Dataloading: 0.0032 s/iter. Inference: 0.0417 s/iter. Eval: 0.0004 s/iter. Total: 0.0453 s/iter. ETA=0:00:02\n",
            "\u001b[32m[05/07 18:56:57 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.348292 (0.044828 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 18:56:57 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.041163 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 18:56:57 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/07 18:56:57 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
            "\u001b[32m[05/07 18:56:57 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[05/07 18:56:57 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[05/07 18:56:57 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.04 seconds.\n",
            "\u001b[32m[05/07 18:56:57 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[05/07 18:56:57 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.462\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.771\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.487\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.273\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.476\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.454\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.564\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.579\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.370\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.594\n",
            "\u001b[32m[05/07 18:56:57 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 46.235 | 77.133 | 48.650 |  nan  | 27.275 | 47.570 |\n",
            "\u001b[32m[05/07 18:56:57 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[05/07 18:56:57 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| Axe        | 38.281 | Handgun    | 51.286 | Knife      | 49.139 |\n",
            "\u001b[32m[05/07 18:56:57 d2.engine.defaults]: \u001b[0mEvaluation results for intruder_valid in csv format:\n",
            "\u001b[32m[05/07 18:56:57 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/07 18:56:57 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/07 18:56:57 d2.evaluation.testing]: \u001b[0mcopypaste: 46.2354,77.1334,48.6504,nan,27.2750,47.5698\n",
            "\u001b[32m[05/07 18:56:57 d2.utils.events]: \u001b[0m eta: 0:52:18  iter: 3999  total_loss: 0.07746  loss_cls: 0.02485  loss_box_reg: 0.04785  loss_rpn_cls: 0.001177  loss_rpn_loc: 0.005708    time: 0.5617  last_time: 0.5392  data_time: 0.0779  last_data_time: 0.0648   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:57:08 d2.utils.events]: \u001b[0m eta: 0:52:07  iter: 4019  total_loss: 0.07312  loss_cls: 0.02637  loss_box_reg: 0.03971  loss_rpn_cls: 0.0007974  loss_rpn_loc: 0.00578    time: 0.5617  last_time: 0.5494  data_time: 0.0812  last_data_time: 0.0731   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:57:19 d2.utils.events]: \u001b[0m eta: 0:51:55  iter: 4039  total_loss: 0.07657  loss_cls: 0.02603  loss_box_reg: 0.04252  loss_rpn_cls: 0.0007639  loss_rpn_loc: 0.006953    time: 0.5617  last_time: 0.6930  data_time: 0.0792  last_data_time: 0.1406   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:57:31 d2.utils.events]: \u001b[0m eta: 0:51:44  iter: 4059  total_loss: 0.07737  loss_cls: 0.02379  loss_box_reg: 0.0448  loss_rpn_cls: 0.0007695  loss_rpn_loc: 0.005161    time: 0.5617  last_time: 0.5703  data_time: 0.0773  last_data_time: 0.0649   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:57:42 d2.utils.events]: \u001b[0m eta: 0:51:34  iter: 4079  total_loss: 0.07622  loss_cls: 0.02429  loss_box_reg: 0.04076  loss_rpn_cls: 0.0007349  loss_rpn_loc: 0.005953    time: 0.5617  last_time: 0.5436  data_time: 0.0826  last_data_time: 0.0636   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:57:53 d2.utils.events]: \u001b[0m eta: 0:51:24  iter: 4099  total_loss: 0.08336  loss_cls: 0.02537  loss_box_reg: 0.04951  loss_rpn_cls: 0.0005949  loss_rpn_loc: 0.006457    time: 0.5617  last_time: 0.5745  data_time: 0.0823  last_data_time: 0.0854   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:58:05 d2.utils.events]: \u001b[0m eta: 0:51:14  iter: 4119  total_loss: 0.08569  loss_cls: 0.02745  loss_box_reg: 0.05501  loss_rpn_cls: 0.0008359  loss_rpn_loc: 0.007259    time: 0.5618  last_time: 0.5533  data_time: 0.0835  last_data_time: 0.0714   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:58:16 d2.utils.events]: \u001b[0m eta: 0:51:04  iter: 4139  total_loss: 0.08925  loss_cls: 0.02778  loss_box_reg: 0.05182  loss_rpn_cls: 0.0006775  loss_rpn_loc: 0.005734    time: 0.5618  last_time: 0.5699  data_time: 0.0950  last_data_time: 0.0998   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:58:27 d2.utils.events]: \u001b[0m eta: 0:50:55  iter: 4159  total_loss: 0.07512  loss_cls: 0.02613  loss_box_reg: 0.04593  loss_rpn_cls: 0.0004195  loss_rpn_loc: 0.00638    time: 0.5619  last_time: 0.5665  data_time: 0.0848  last_data_time: 0.0892   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:58:39 d2.utils.events]: \u001b[0m eta: 0:50:46  iter: 4179  total_loss: 0.06792  loss_cls: 0.02024  loss_box_reg: 0.04198  loss_rpn_cls: 0.0005899  loss_rpn_loc: 0.005765    time: 0.5619  last_time: 0.5204  data_time: 0.0818  last_data_time: 0.0792   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:58:50 d2.utils.events]: \u001b[0m eta: 0:50:37  iter: 4199  total_loss: 0.0712  loss_cls: 0.02227  loss_box_reg: 0.04271  loss_rpn_cls: 0.0007044  loss_rpn_loc: 0.00609    time: 0.5619  last_time: 0.5379  data_time: 0.0821  last_data_time: 0.0610   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:59:02 d2.utils.events]: \u001b[0m eta: 0:50:28  iter: 4219  total_loss: 0.08648  loss_cls: 0.0266  loss_box_reg: 0.05585  loss_rpn_cls: 0.0006331  loss_rpn_loc: 0.006572    time: 0.5620  last_time: 0.5514  data_time: 0.0893  last_data_time: 0.0735   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:59:13 d2.utils.events]: \u001b[0m eta: 0:50:17  iter: 4239  total_loss: 0.08277  loss_cls: 0.025  loss_box_reg: 0.04669  loss_rpn_cls: 0.0006802  loss_rpn_loc: 0.00591    time: 0.5620  last_time: 0.7009  data_time: 0.0816  last_data_time: 0.2016   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:59:24 d2.utils.events]: \u001b[0m eta: 0:50:06  iter: 4259  total_loss: 0.08252  loss_cls: 0.0271  loss_box_reg: 0.05068  loss_rpn_cls: 0.0007148  loss_rpn_loc: 0.005739    time: 0.5619  last_time: 0.5493  data_time: 0.0766  last_data_time: 0.0727   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:59:35 d2.utils.events]: \u001b[0m eta: 0:49:55  iter: 4279  total_loss: 0.07349  loss_cls: 0.02336  loss_box_reg: 0.04181  loss_rpn_cls: 0.0005867  loss_rpn_loc: 0.005987    time: 0.5619  last_time: 0.5052  data_time: 0.0776  last_data_time: 0.0707   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:59:46 d2.utils.events]: \u001b[0m eta: 0:49:44  iter: 4299  total_loss: 0.07006  loss_cls: 0.0226  loss_box_reg: 0.0413  loss_rpn_cls: 0.0006021  loss_rpn_loc: 0.005663    time: 0.5619  last_time: 0.5555  data_time: 0.0836  last_data_time: 0.0824   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 18:59:58 d2.utils.events]: \u001b[0m eta: 0:49:33  iter: 4319  total_loss: 0.07263  loss_cls: 0.02237  loss_box_reg: 0.04154  loss_rpn_cls: 0.0003327  loss_rpn_loc: 0.006964    time: 0.5619  last_time: 0.4857  data_time: 0.0852  last_data_time: 0.0605   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 19:00:09 d2.utils.events]: \u001b[0m eta: 0:49:22  iter: 4339  total_loss: 0.07819  loss_cls: 0.02366  loss_box_reg: 0.04428  loss_rpn_cls: 0.0008035  loss_rpn_loc: 0.005178    time: 0.5619  last_time: 0.5617  data_time: 0.0850  last_data_time: 0.0908   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 19:00:20 d2.utils.events]: \u001b[0m eta: 0:49:11  iter: 4359  total_loss: 0.08592  loss_cls: 0.02562  loss_box_reg: 0.04638  loss_rpn_cls: 0.001103  loss_rpn_loc: 0.006632    time: 0.5620  last_time: 0.5748  data_time: 0.0835  last_data_time: 0.0974   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 19:00:32 d2.utils.events]: \u001b[0m eta: 0:49:00  iter: 4379  total_loss: 0.08243  loss_cls: 0.02458  loss_box_reg: 0.05211  loss_rpn_cls: 0.0007123  loss_rpn_loc: 0.006235    time: 0.5620  last_time: 0.5221  data_time: 0.0817  last_data_time: 0.0855   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 19:00:43 d2.utils.events]: \u001b[0m eta: 0:48:48  iter: 4399  total_loss: 0.07936  loss_cls: 0.02367  loss_box_reg: 0.0493  loss_rpn_cls: 0.0004011  loss_rpn_loc: 0.005677    time: 0.5619  last_time: 0.5383  data_time: 0.0745  last_data_time: 0.0632   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 19:00:54 d2.utils.events]: \u001b[0m eta: 0:48:36  iter: 4419  total_loss: 0.08893  loss_cls: 0.02694  loss_box_reg: 0.0526  loss_rpn_cls: 0.0009942  loss_rpn_loc: 0.00583    time: 0.5619  last_time: 0.6768  data_time: 0.0782  last_data_time: 0.1210   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 19:01:05 d2.utils.events]: \u001b[0m eta: 0:48:25  iter: 4439  total_loss: 0.08278  loss_cls: 0.02593  loss_box_reg: 0.0513  loss_rpn_cls: 0.0005347  loss_rpn_loc: 0.004971    time: 0.5618  last_time: 0.5671  data_time: 0.0802  last_data_time: 0.0893   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 19:01:16 d2.utils.events]: \u001b[0m eta: 0:48:14  iter: 4459  total_loss: 0.07933  loss_cls: 0.02348  loss_box_reg: 0.05056  loss_rpn_cls: 0.0004838  loss_rpn_loc: 0.005389    time: 0.5619  last_time: 0.5595  data_time: 0.0796  last_data_time: 0.0824   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 19:01:27 d2.utils.events]: \u001b[0m eta: 0:48:03  iter: 4479  total_loss: 0.085  loss_cls: 0.02708  loss_box_reg: 0.05209  loss_rpn_cls: 0.0005169  loss_rpn_loc: 0.005192    time: 0.5619  last_time: 0.5423  data_time: 0.0819  last_data_time: 0.0618   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 19:01:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[05/07 19:01:40 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[05/07 19:01:40 d2.data.common]: \u001b[0mSerializing 392 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/07 19:01:40 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/07 19:01:40 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "\u001b[32m[05/07 19:01:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 392 batches\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[32m[05/07 19:01:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/392. Dataloading: 0.0013 s/iter. Inference: 0.0350 s/iter. Eval: 0.0003 s/iter. Total: 0.0366 s/iter. ETA=0:00:13\n",
            "\u001b[32m[05/07 19:01:46 d2.evaluation.evaluator]: \u001b[0mInference done 111/392. Dataloading: 0.0037 s/iter. Inference: 0.0453 s/iter. Eval: 0.0004 s/iter. Total: 0.0495 s/iter. ETA=0:00:13\n",
            "\u001b[32m[05/07 19:01:51 d2.evaluation.evaluator]: \u001b[0mInference done 243/392. Dataloading: 0.0027 s/iter. Inference: 0.0401 s/iter. Eval: 0.0003 s/iter. Total: 0.0432 s/iter. ETA=0:00:06\n",
            "\u001b[32m[05/07 19:01:56 d2.evaluation.evaluator]: \u001b[0mInference done 364/392. Dataloading: 0.0026 s/iter. Inference: 0.0396 s/iter. Eval: 0.0003 s/iter. Total: 0.0426 s/iter. ETA=0:00:01\n",
            "\u001b[32m[05/07 19:01:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.157448 (0.044334 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 19:01:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.040806 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 19:01:58 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/07 19:01:58 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
            "\u001b[32m[05/07 19:01:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[05/07 19:01:58 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[05/07 19:01:58 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.04 seconds.\n",
            "\u001b[32m[05/07 19:01:58 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[05/07 19:01:58 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.510\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.780\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.569\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.263\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.529\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.486\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.606\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.617\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.372\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.633\n",
            "\u001b[32m[05/07 19:01:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 51.032 | 77.978 | 56.885 |  nan  | 26.289 | 52.857 |\n",
            "\u001b[32m[05/07 19:01:58 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[05/07 19:01:58 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| Axe        | 44.567 | Handgun    | 49.740 | Knife      | 58.789 |\n",
            "\u001b[32m[05/07 19:01:58 d2.engine.defaults]: \u001b[0mEvaluation results for intruder_valid in csv format:\n",
            "\u001b[32m[05/07 19:01:58 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/07 19:01:58 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/07 19:01:58 d2.evaluation.testing]: \u001b[0mcopypaste: 51.0322,77.9780,56.8854,nan,26.2891,52.8571\n",
            "\u001b[32m[05/07 19:01:58 d2.utils.events]: \u001b[0m eta: 0:47:52  iter: 4499  total_loss: 0.0759  loss_cls: 0.02378  loss_box_reg: 0.04453  loss_rpn_cls: 0.0005726  loss_rpn_loc: 0.0059    time: 0.5619  last_time: 0.5423  data_time: 0.0769  last_data_time: 0.0748   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 19:02:09 d2.utils.events]: \u001b[0m eta: 0:47:39  iter: 4519  total_loss: 0.07672  loss_cls: 0.02403  loss_box_reg: 0.04705  loss_rpn_cls: 0.0003487  loss_rpn_loc: 0.00611    time: 0.5617  last_time: 0.6371  data_time: 0.0704  last_data_time: 0.0797   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 19:02:20 d2.utils.events]: \u001b[0m eta: 0:47:30  iter: 4539  total_loss: 0.07817  loss_cls: 0.02438  loss_box_reg: 0.04839  loss_rpn_cls: 0.000546  loss_rpn_loc: 0.006668    time: 0.5617  last_time: 0.5443  data_time: 0.0846  last_data_time: 0.0762   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 19:02:31 d2.utils.events]: \u001b[0m eta: 0:47:18  iter: 4559  total_loss: 0.07252  loss_cls: 0.02062  loss_box_reg: 0.04288  loss_rpn_cls: 0.0006502  loss_rpn_loc: 0.00699    time: 0.5617  last_time: 0.5154  data_time: 0.0842  last_data_time: 0.0700   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 19:02:42 d2.utils.events]: \u001b[0m eta: 0:47:07  iter: 4579  total_loss: 0.07655  loss_cls: 0.02456  loss_box_reg: 0.04617  loss_rpn_cls: 0.0006676  loss_rpn_loc: 0.005832    time: 0.5617  last_time: 0.5491  data_time: 0.0841  last_data_time: 0.0686   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 19:02:54 d2.utils.events]: \u001b[0m eta: 0:46:56  iter: 4599  total_loss: 0.0801  loss_cls: 0.02606  loss_box_reg: 0.04825  loss_rpn_cls: 0.0006674  loss_rpn_loc: 0.005453    time: 0.5617  last_time: 0.5169  data_time: 0.0779  last_data_time: 0.0825   lr: 0.0025  max_mem: 5721M\n",
            "\u001b[32m[05/07 19:03:05 d2.utils.events]: \u001b[0m eta: 0:46:44  iter: 4619  total_loss: 0.07808  loss_cls: 0.02435  loss_box_reg: 0.04619  loss_rpn_cls: 0.0005029  loss_rpn_loc: 0.005102    time: 0.5618  last_time: 0.5469  data_time: 0.0802  last_data_time: 0.0656   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:03:16 d2.utils.events]: \u001b[0m eta: 0:46:34  iter: 4639  total_loss: 0.07317  loss_cls: 0.02455  loss_box_reg: 0.04326  loss_rpn_cls: 0.0004113  loss_rpn_loc: 0.005209    time: 0.5617  last_time: 0.5439  data_time: 0.0828  last_data_time: 0.0693   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:03:28 d2.utils.events]: \u001b[0m eta: 0:46:23  iter: 4659  total_loss: 0.07794  loss_cls: 0.02619  loss_box_reg: 0.04502  loss_rpn_cls: 0.0008073  loss_rpn_loc: 0.005755    time: 0.5618  last_time: 0.5433  data_time: 0.0830  last_data_time: 0.0659   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:03:39 d2.utils.events]: \u001b[0m eta: 0:46:11  iter: 4679  total_loss: 0.09073  loss_cls: 0.02853  loss_box_reg: 0.0566  loss_rpn_cls: 0.0006494  loss_rpn_loc: 0.006102    time: 0.5617  last_time: 0.5821  data_time: 0.0752  last_data_time: 0.0566   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:03:50 d2.utils.events]: \u001b[0m eta: 0:46:00  iter: 4699  total_loss: 0.06573  loss_cls: 0.0213  loss_box_reg: 0.03758  loss_rpn_cls: 0.0007659  loss_rpn_loc: 0.005562    time: 0.5617  last_time: 0.6578  data_time: 0.0738  last_data_time: 0.1211   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:04:01 d2.utils.events]: \u001b[0m eta: 0:45:49  iter: 4719  total_loss: 0.06807  loss_cls: 0.0213  loss_box_reg: 0.03974  loss_rpn_cls: 0.0005966  loss_rpn_loc: 0.007159    time: 0.5617  last_time: 0.5676  data_time: 0.0871  last_data_time: 0.0806   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:04:13 d2.utils.events]: \u001b[0m eta: 0:45:38  iter: 4739  total_loss: 0.08463  loss_cls: 0.02259  loss_box_reg: 0.0526  loss_rpn_cls: 0.0006477  loss_rpn_loc: 0.006695    time: 0.5617  last_time: 0.5175  data_time: 0.0788  last_data_time: 0.0794   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:04:24 d2.utils.events]: \u001b[0m eta: 0:45:27  iter: 4759  total_loss: 0.07123  loss_cls: 0.02058  loss_box_reg: 0.04332  loss_rpn_cls: 0.0003554  loss_rpn_loc: 0.006375    time: 0.5618  last_time: 0.5664  data_time: 0.0822  last_data_time: 0.0811   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:04:35 d2.utils.events]: \u001b[0m eta: 0:45:14  iter: 4779  total_loss: 0.06929  loss_cls: 0.02122  loss_box_reg: 0.04208  loss_rpn_cls: 0.0004265  loss_rpn_loc: 0.005342    time: 0.5617  last_time: 0.5173  data_time: 0.0709  last_data_time: 0.0804   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:04:46 d2.utils.events]: \u001b[0m eta: 0:45:03  iter: 4799  total_loss: 0.06747  loss_cls: 0.02366  loss_box_reg: 0.03903  loss_rpn_cls: 0.0003999  loss_rpn_loc: 0.004179    time: 0.5617  last_time: 0.5301  data_time: 0.0832  last_data_time: 0.0657   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:04:58 d2.utils.events]: \u001b[0m eta: 0:44:52  iter: 4819  total_loss: 0.08148  loss_cls: 0.02542  loss_box_reg: 0.04796  loss_rpn_cls: 0.0009676  loss_rpn_loc: 0.005516    time: 0.5617  last_time: 0.5684  data_time: 0.0784  last_data_time: 0.0981   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:05:09 d2.utils.events]: \u001b[0m eta: 0:44:39  iter: 4839  total_loss: 0.06447  loss_cls: 0.02018  loss_box_reg: 0.04068  loss_rpn_cls: 0.0006294  loss_rpn_loc: 0.005165    time: 0.5618  last_time: 0.5590  data_time: 0.0815  last_data_time: 0.0851   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:05:20 d2.utils.events]: \u001b[0m eta: 0:44:29  iter: 4859  total_loss: 0.06851  loss_cls: 0.02043  loss_box_reg: 0.04324  loss_rpn_cls: 0.0003178  loss_rpn_loc: 0.005037    time: 0.5618  last_time: 0.6056  data_time: 0.0820  last_data_time: 0.0951   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:05:31 d2.utils.events]: \u001b[0m eta: 0:44:16  iter: 4879  total_loss: 0.06924  loss_cls: 0.02096  loss_box_reg: 0.04009  loss_rpn_cls: 0.0007025  loss_rpn_loc: 0.005267    time: 0.5618  last_time: 0.6182  data_time: 0.0821  last_data_time: 0.1048   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:05:43 d2.utils.events]: \u001b[0m eta: 0:44:06  iter: 4899  total_loss: 0.07923  loss_cls: 0.0244  loss_box_reg: 0.04684  loss_rpn_cls: 0.0006681  loss_rpn_loc: 0.0063    time: 0.5618  last_time: 0.5531  data_time: 0.0787  last_data_time: 0.0641   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:05:54 d2.utils.events]: \u001b[0m eta: 0:43:57  iter: 4919  total_loss: 0.07111  loss_cls: 0.02057  loss_box_reg: 0.04253  loss_rpn_cls: 0.0006672  loss_rpn_loc: 0.005119    time: 0.5618  last_time: 0.5653  data_time: 0.0815  last_data_time: 0.0828   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:06:05 d2.utils.events]: \u001b[0m eta: 0:43:46  iter: 4939  total_loss: 0.0757  loss_cls: 0.0214  loss_box_reg: 0.04709  loss_rpn_cls: 0.0007062  loss_rpn_loc: 0.005277    time: 0.5618  last_time: 0.5569  data_time: 0.0735  last_data_time: 0.0632   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:06:17 d2.utils.events]: \u001b[0m eta: 0:43:35  iter: 4959  total_loss: 0.07743  loss_cls: 0.02587  loss_box_reg: 0.04956  loss_rpn_cls: 0.0006179  loss_rpn_loc: 0.00534    time: 0.5618  last_time: 0.5399  data_time: 0.0770  last_data_time: 0.0624   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:06:28 d2.utils.events]: \u001b[0m eta: 0:43:23  iter: 4979  total_loss: 0.08063  loss_cls: 0.02323  loss_box_reg: 0.04671  loss_rpn_cls: 0.0004632  loss_rpn_loc: 0.005065    time: 0.5618  last_time: 0.5519  data_time: 0.0804  last_data_time: 0.0629   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:06:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[05/07 19:06:42 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[05/07 19:06:42 d2.data.common]: \u001b[0mSerializing 392 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/07 19:06:42 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/07 19:06:42 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "\u001b[32m[05/07 19:06:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 392 batches\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[32m[05/07 19:06:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/392. Dataloading: 0.0010 s/iter. Inference: 0.0387 s/iter. Eval: 0.0004 s/iter. Total: 0.0401 s/iter. ETA=0:00:15\n",
            "\u001b[32m[05/07 19:06:48 d2.evaluation.evaluator]: \u001b[0mInference done 125/392. Dataloading: 0.0032 s/iter. Inference: 0.0404 s/iter. Eval: 0.0004 s/iter. Total: 0.0440 s/iter. ETA=0:00:11\n",
            "\u001b[32m[05/07 19:06:53 d2.evaluation.evaluator]: \u001b[0mInference done 243/392. Dataloading: 0.0031 s/iter. Inference: 0.0398 s/iter. Eval: 0.0004 s/iter. Total: 0.0433 s/iter. ETA=0:00:06\n",
            "\u001b[32m[05/07 19:06:58 d2.evaluation.evaluator]: \u001b[0mInference done 375/392. Dataloading: 0.0027 s/iter. Inference: 0.0384 s/iter. Eval: 0.0003 s/iter. Total: 0.0415 s/iter. ETA=0:00:00\n",
            "\u001b[32m[05/07 19:06:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.123543 (0.041663 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 19:06:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.038375 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 19:06:58 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/07 19:06:58 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
            "\u001b[32m[05/07 19:06:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[05/07 19:06:58 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[05/07 19:06:58 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.04 seconds.\n",
            "\u001b[32m[05/07 19:06:58 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[05/07 19:06:58 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.478\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.783\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.532\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.250\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.493\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.467\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.575\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.588\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.354\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.605\n",
            "\u001b[32m[05/07 19:06:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 47.793 | 78.268 | 53.209 |  nan  | 24.992 | 49.264 |\n",
            "\u001b[32m[05/07 19:06:58 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[05/07 19:06:58 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| Axe        | 39.421 | Handgun    | 50.307 | Knife      | 53.653 |\n",
            "\u001b[32m[05/07 19:06:58 d2.engine.defaults]: \u001b[0mEvaluation results for intruder_valid in csv format:\n",
            "\u001b[32m[05/07 19:06:58 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/07 19:06:58 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/07 19:06:58 d2.evaluation.testing]: \u001b[0mcopypaste: 47.7934,78.2679,53.2093,nan,24.9920,49.2643\n",
            "\u001b[32m[05/07 19:06:58 d2.utils.events]: \u001b[0m eta: 0:43:12  iter: 4999  total_loss: 0.073  loss_cls: 0.02323  loss_box_reg: 0.04501  loss_rpn_cls: 0.0009085  loss_rpn_loc: 0.006752    time: 0.5618  last_time: 0.5525  data_time: 0.0849  last_data_time: 0.0672   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:07:10 d2.utils.events]: \u001b[0m eta: 0:43:01  iter: 5019  total_loss: 0.0738  loss_cls: 0.02264  loss_box_reg: 0.04661  loss_rpn_cls: 0.0003147  loss_rpn_loc: 0.005674    time: 0.5618  last_time: 0.5339  data_time: 0.0754  last_data_time: 0.0633   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:07:21 d2.utils.events]: \u001b[0m eta: 0:42:52  iter: 5039  total_loss: 0.0808  loss_cls: 0.02433  loss_box_reg: 0.04811  loss_rpn_cls: 0.0007592  loss_rpn_loc: 0.006018    time: 0.5618  last_time: 0.5540  data_time: 0.0787  last_data_time: 0.0795   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:07:32 d2.utils.events]: \u001b[0m eta: 0:42:41  iter: 5059  total_loss: 0.0698  loss_cls: 0.02129  loss_box_reg: 0.03973  loss_rpn_cls: 0.0004637  loss_rpn_loc: 0.005941    time: 0.5619  last_time: 0.5556  data_time: 0.0817  last_data_time: 0.0808   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:07:44 d2.utils.events]: \u001b[0m eta: 0:42:30  iter: 5079  total_loss: 0.08532  loss_cls: 0.02336  loss_box_reg: 0.04656  loss_rpn_cls: 0.0006428  loss_rpn_loc: 0.006157    time: 0.5619  last_time: 0.5842  data_time: 0.0846  last_data_time: 0.1041   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:07:55 d2.utils.events]: \u001b[0m eta: 0:42:20  iter: 5099  total_loss: 0.08477  loss_cls: 0.02426  loss_box_reg: 0.05097  loss_rpn_cls: 0.001305  loss_rpn_loc: 0.007376    time: 0.5619  last_time: 0.5755  data_time: 0.0826  last_data_time: 0.1053   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:08:07 d2.utils.events]: \u001b[0m eta: 0:42:10  iter: 5119  total_loss: 0.09428  loss_cls: 0.02791  loss_box_reg: 0.05199  loss_rpn_cls: 0.0005722  loss_rpn_loc: 0.005904    time: 0.5620  last_time: 0.5662  data_time: 0.0893  last_data_time: 0.0944   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:08:18 d2.utils.events]: \u001b[0m eta: 0:41:59  iter: 5139  total_loss: 0.06876  loss_cls: 0.02155  loss_box_reg: 0.03881  loss_rpn_cls: 0.0004993  loss_rpn_loc: 0.005975    time: 0.5621  last_time: 0.5551  data_time: 0.0877  last_data_time: 0.0800   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:08:30 d2.utils.events]: \u001b[0m eta: 0:41:48  iter: 5159  total_loss: 0.06729  loss_cls: 0.02111  loss_box_reg: 0.04247  loss_rpn_cls: 0.0004007  loss_rpn_loc: 0.005344    time: 0.5621  last_time: 0.6790  data_time: 0.0892  last_data_time: 0.1380   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:08:41 d2.utils.events]: \u001b[0m eta: 0:41:34  iter: 5179  total_loss: 0.0658  loss_cls: 0.01957  loss_box_reg: 0.04163  loss_rpn_cls: 0.0003846  loss_rpn_loc: 0.006191    time: 0.5621  last_time: 0.6219  data_time: 0.0786  last_data_time: 0.1102   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:08:52 d2.utils.events]: \u001b[0m eta: 0:41:23  iter: 5199  total_loss: 0.0714  loss_cls: 0.0207  loss_box_reg: 0.04559  loss_rpn_cls: 0.0006132  loss_rpn_loc: 0.005869    time: 0.5621  last_time: 0.5402  data_time: 0.0765  last_data_time: 0.0668   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:09:03 d2.utils.events]: \u001b[0m eta: 0:41:10  iter: 5219  total_loss: 0.0587  loss_cls: 0.01933  loss_box_reg: 0.03531  loss_rpn_cls: 0.0006035  loss_rpn_loc: 0.005581    time: 0.5621  last_time: 0.5423  data_time: 0.0838  last_data_time: 0.0686   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:09:15 d2.utils.events]: \u001b[0m eta: 0:41:00  iter: 5239  total_loss: 0.0725  loss_cls: 0.02248  loss_box_reg: 0.04238  loss_rpn_cls: 0.0003579  loss_rpn_loc: 0.004823    time: 0.5621  last_time: 0.5735  data_time: 0.0865  last_data_time: 0.0885   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:09:26 d2.utils.events]: \u001b[0m eta: 0:40:49  iter: 5259  total_loss: 0.06736  loss_cls: 0.02028  loss_box_reg: 0.03798  loss_rpn_cls: 0.0002618  loss_rpn_loc: 0.006831    time: 0.5621  last_time: 0.4980  data_time: 0.0809  last_data_time: 0.0665   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:09:37 d2.utils.events]: \u001b[0m eta: 0:40:37  iter: 5279  total_loss: 0.08761  loss_cls: 0.02573  loss_box_reg: 0.05171  loss_rpn_cls: 0.0008887  loss_rpn_loc: 0.005644    time: 0.5621  last_time: 0.5674  data_time: 0.0890  last_data_time: 0.0706   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:09:48 d2.utils.events]: \u001b[0m eta: 0:40:26  iter: 5299  total_loss: 0.06465  loss_cls: 0.0204  loss_box_reg: 0.03997  loss_rpn_cls: 0.0004504  loss_rpn_loc: 0.004912    time: 0.5620  last_time: 0.5330  data_time: 0.0691  last_data_time: 0.0646   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:10:00 d2.utils.events]: \u001b[0m eta: 0:40:14  iter: 5319  total_loss: 0.07825  loss_cls: 0.02411  loss_box_reg: 0.04907  loss_rpn_cls: 0.0005252  loss_rpn_loc: 0.00524    time: 0.5620  last_time: 0.5500  data_time: 0.0818  last_data_time: 0.0754   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:10:11 d2.utils.events]: \u001b[0m eta: 0:40:03  iter: 5339  total_loss: 0.08745  loss_cls: 0.02437  loss_box_reg: 0.05347  loss_rpn_cls: 0.0007685  loss_rpn_loc: 0.00673    time: 0.5621  last_time: 0.6702  data_time: 0.0830  last_data_time: 0.1136   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:10:22 d2.utils.events]: \u001b[0m eta: 0:39:53  iter: 5359  total_loss: 0.07294  loss_cls: 0.02043  loss_box_reg: 0.04373  loss_rpn_cls: 0.0008542  loss_rpn_loc: 0.006051    time: 0.5620  last_time: 0.6679  data_time: 0.0827  last_data_time: 0.1435   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:10:33 d2.utils.events]: \u001b[0m eta: 0:39:41  iter: 5379  total_loss: 0.07329  loss_cls: 0.02338  loss_box_reg: 0.0471  loss_rpn_cls: 0.0007122  loss_rpn_loc: 0.005377    time: 0.5620  last_time: 0.5411  data_time: 0.0781  last_data_time: 0.0667   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:10:44 d2.utils.events]: \u001b[0m eta: 0:39:31  iter: 5399  total_loss: 0.06418  loss_cls: 0.02235  loss_box_reg: 0.03652  loss_rpn_cls: 0.0004729  loss_rpn_loc: 0.004962    time: 0.5620  last_time: 0.5645  data_time: 0.0815  last_data_time: 0.0848   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:10:56 d2.utils.events]: \u001b[0m eta: 0:39:21  iter: 5419  total_loss: 0.06703  loss_cls: 0.01981  loss_box_reg: 0.04031  loss_rpn_cls: 0.0009748  loss_rpn_loc: 0.005548    time: 0.5620  last_time: 0.5500  data_time: 0.0820  last_data_time: 0.0681   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:11:07 d2.utils.events]: \u001b[0m eta: 0:39:11  iter: 5439  total_loss: 0.08157  loss_cls: 0.02413  loss_box_reg: 0.04902  loss_rpn_cls: 0.001241  loss_rpn_loc: 0.006462    time: 0.5620  last_time: 0.5486  data_time: 0.0793  last_data_time: 0.0678   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:11:18 d2.utils.events]: \u001b[0m eta: 0:38:59  iter: 5459  total_loss: 0.06491  loss_cls: 0.02198  loss_box_reg: 0.03572  loss_rpn_cls: 0.0004704  loss_rpn_loc: 0.006106    time: 0.5621  last_time: 0.5452  data_time: 0.0838  last_data_time: 0.0753   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:11:30 d2.utils.events]: \u001b[0m eta: 0:38:49  iter: 5479  total_loss: 0.07086  loss_cls: 0.02156  loss_box_reg: 0.04474  loss_rpn_cls: 0.0005191  loss_rpn_loc: 0.00561    time: 0.5621  last_time: 0.5570  data_time: 0.0889  last_data_time: 0.0702   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:11:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[05/07 19:11:43 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[05/07 19:11:43 d2.data.common]: \u001b[0mSerializing 392 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/07 19:11:43 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/07 19:11:43 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "\u001b[32m[05/07 19:11:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 392 batches\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[32m[05/07 19:11:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/392. Dataloading: 0.0012 s/iter. Inference: 0.0359 s/iter. Eval: 0.0003 s/iter. Total: 0.0374 s/iter. ETA=0:00:14\n",
            "\u001b[32m[05/07 19:11:49 d2.evaluation.evaluator]: \u001b[0mInference done 142/392. Dataloading: 0.0021 s/iter. Inference: 0.0358 s/iter. Eval: 0.0003 s/iter. Total: 0.0382 s/iter. ETA=0:00:09\n",
            "\u001b[32m[05/07 19:11:54 d2.evaluation.evaluator]: \u001b[0mInference done 240/392. Dataloading: 0.0028 s/iter. Inference: 0.0403 s/iter. Eval: 0.0003 s/iter. Total: 0.0436 s/iter. ETA=0:00:06\n",
            "\u001b[32m[05/07 19:11:59 d2.evaluation.evaluator]: \u001b[0mInference done 372/392. Dataloading: 0.0025 s/iter. Inference: 0.0387 s/iter. Eval: 0.0003 s/iter. Total: 0.0416 s/iter. ETA=0:00:00\n",
            "\u001b[32m[05/07 19:12:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.057603 (0.041493 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 19:12:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.038472 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 19:12:00 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/07 19:12:00 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
            "\u001b[32m[05/07 19:12:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[05/07 19:12:00 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[05/07 19:12:00 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.04 seconds.\n",
            "\u001b[32m[05/07 19:12:00 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[05/07 19:12:00 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.500\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.770\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.546\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.247\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.516\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.490\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.591\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.603\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.403\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.615\n",
            "\u001b[32m[05/07 19:12:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 49.996 | 77.022 | 54.598 |  nan  | 24.700 | 51.607 |\n",
            "\u001b[32m[05/07 19:12:00 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[05/07 19:12:00 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| Axe        | 41.874 | Handgun    | 51.715 | Knife      | 56.399 |\n",
            "\u001b[32m[05/07 19:12:00 d2.engine.defaults]: \u001b[0mEvaluation results for intruder_valid in csv format:\n",
            "\u001b[32m[05/07 19:12:00 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/07 19:12:00 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/07 19:12:00 d2.evaluation.testing]: \u001b[0mcopypaste: 49.9958,77.0224,54.5976,nan,24.7002,51.6072\n",
            "\u001b[32m[05/07 19:12:00 d2.utils.events]: \u001b[0m eta: 0:38:40  iter: 5499  total_loss: 0.07305  loss_cls: 0.02158  loss_box_reg: 0.04384  loss_rpn_cls: 0.0004671  loss_rpn_loc: 0.00468    time: 0.5621  last_time: 0.5198  data_time: 0.0813  last_data_time: 0.0878   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:12:11 d2.utils.events]: \u001b[0m eta: 0:38:30  iter: 5519  total_loss: 0.06206  loss_cls: 0.01981  loss_box_reg: 0.03631  loss_rpn_cls: 0.0002861  loss_rpn_loc: 0.005026    time: 0.5621  last_time: 0.5578  data_time: 0.0868  last_data_time: 0.0866   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:12:22 d2.utils.events]: \u001b[0m eta: 0:38:18  iter: 5539  total_loss: 0.07382  loss_cls: 0.02299  loss_box_reg: 0.04452  loss_rpn_cls: 0.0006336  loss_rpn_loc: 0.005789    time: 0.5621  last_time: 0.5531  data_time: 0.0842  last_data_time: 0.0828   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:12:34 d2.utils.events]: \u001b[0m eta: 0:38:07  iter: 5559  total_loss: 0.07152  loss_cls: 0.01985  loss_box_reg: 0.04153  loss_rpn_cls: 0.001057  loss_rpn_loc: 0.006631    time: 0.5621  last_time: 0.5494  data_time: 0.0816  last_data_time: 0.0705   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:12:45 d2.utils.events]: \u001b[0m eta: 0:37:56  iter: 5579  total_loss: 0.0831  loss_cls: 0.02511  loss_box_reg: 0.04904  loss_rpn_cls: 0.0004934  loss_rpn_loc: 0.006213    time: 0.5621  last_time: 0.5441  data_time: 0.0807  last_data_time: 0.0739   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:12:56 d2.utils.events]: \u001b[0m eta: 0:37:45  iter: 5599  total_loss: 0.06637  loss_cls: 0.01958  loss_box_reg: 0.03952  loss_rpn_cls: 0.0003933  loss_rpn_loc: 0.005249    time: 0.5621  last_time: 0.5520  data_time: 0.0794  last_data_time: 0.0770   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:13:07 d2.utils.events]: \u001b[0m eta: 0:37:34  iter: 5619  total_loss: 0.06249  loss_cls: 0.02016  loss_box_reg: 0.03739  loss_rpn_cls: 0.0002669  loss_rpn_loc: 0.004186    time: 0.5621  last_time: 0.6516  data_time: 0.0788  last_data_time: 0.1102   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:13:18 d2.utils.events]: \u001b[0m eta: 0:37:22  iter: 5639  total_loss: 0.09595  loss_cls: 0.02792  loss_box_reg: 0.0552  loss_rpn_cls: 0.0006706  loss_rpn_loc: 0.006513    time: 0.5621  last_time: 0.5762  data_time: 0.0723  last_data_time: 0.0763   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:13:30 d2.utils.events]: \u001b[0m eta: 0:37:11  iter: 5659  total_loss: 0.0653  loss_cls: 0.02004  loss_box_reg: 0.04026  loss_rpn_cls: 0.000442  loss_rpn_loc: 0.005143    time: 0.5621  last_time: 0.5608  data_time: 0.0800  last_data_time: 0.0778   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:13:41 d2.utils.events]: \u001b[0m eta: 0:37:00  iter: 5679  total_loss: 0.06514  loss_cls: 0.0188  loss_box_reg: 0.03934  loss_rpn_cls: 0.0005193  loss_rpn_loc: 0.005116    time: 0.5621  last_time: 0.5452  data_time: 0.0776  last_data_time: 0.0629   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:13:52 d2.utils.events]: \u001b[0m eta: 0:36:49  iter: 5699  total_loss: 0.07212  loss_cls: 0.02058  loss_box_reg: 0.04477  loss_rpn_cls: 0.0003411  loss_rpn_loc: 0.00529    time: 0.5621  last_time: 0.5291  data_time: 0.0845  last_data_time: 0.0653   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:14:03 d2.utils.events]: \u001b[0m eta: 0:36:38  iter: 5719  total_loss: 0.06644  loss_cls: 0.01848  loss_box_reg: 0.04033  loss_rpn_cls: 0.0004264  loss_rpn_loc: 0.00609    time: 0.5621  last_time: 0.5647  data_time: 0.0864  last_data_time: 0.0916   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:14:15 d2.utils.events]: \u001b[0m eta: 0:36:27  iter: 5739  total_loss: 0.07205  loss_cls: 0.02245  loss_box_reg: 0.03917  loss_rpn_cls: 0.0009774  loss_rpn_loc: 0.006089    time: 0.5621  last_time: 0.5804  data_time: 0.0850  last_data_time: 0.0962   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:14:26 d2.utils.events]: \u001b[0m eta: 0:36:16  iter: 5759  total_loss: 0.06479  loss_cls: 0.01978  loss_box_reg: 0.03768  loss_rpn_cls: 0.0002953  loss_rpn_loc: 0.005021    time: 0.5621  last_time: 0.5280  data_time: 0.0819  last_data_time: 0.0913   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:14:37 d2.utils.events]: \u001b[0m eta: 0:36:05  iter: 5779  total_loss: 0.06434  loss_cls: 0.01998  loss_box_reg: 0.03776  loss_rpn_cls: 0.00104  loss_rpn_loc: 0.004853    time: 0.5621  last_time: 0.5489  data_time: 0.0809  last_data_time: 0.0773   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:14:48 d2.utils.events]: \u001b[0m eta: 0:35:54  iter: 5799  total_loss: 0.07358  loss_cls: 0.02086  loss_box_reg: 0.0416  loss_rpn_cls: 0.0005118  loss_rpn_loc: 0.005157    time: 0.5621  last_time: 0.6403  data_time: 0.0757  last_data_time: 0.1042   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:14:59 d2.utils.events]: \u001b[0m eta: 0:35:43  iter: 5819  total_loss: 0.06878  loss_cls: 0.0197  loss_box_reg: 0.0434  loss_rpn_cls: 0.0006433  loss_rpn_loc: 0.005617    time: 0.5620  last_time: 0.6050  data_time: 0.0744  last_data_time: 0.0785   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:15:11 d2.utils.events]: \u001b[0m eta: 0:35:32  iter: 5839  total_loss: 0.06672  loss_cls: 0.01987  loss_box_reg: 0.04212  loss_rpn_cls: 0.0005617  loss_rpn_loc: 0.004866    time: 0.5621  last_time: 0.5633  data_time: 0.0825  last_data_time: 0.0867   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:15:22 d2.utils.events]: \u001b[0m eta: 0:35:21  iter: 5859  total_loss: 0.0623  loss_cls: 0.02014  loss_box_reg: 0.03709  loss_rpn_cls: 0.0006009  loss_rpn_loc: 0.005594    time: 0.5621  last_time: 0.5506  data_time: 0.0855  last_data_time: 0.0772   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:15:33 d2.utils.events]: \u001b[0m eta: 0:35:10  iter: 5879  total_loss: 0.06176  loss_cls: 0.01966  loss_box_reg: 0.03886  loss_rpn_cls: 0.0006235  loss_rpn_loc: 0.004589    time: 0.5621  last_time: 0.5404  data_time: 0.0810  last_data_time: 0.0694   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:15:45 d2.utils.events]: \u001b[0m eta: 0:34:59  iter: 5899  total_loss: 0.07131  loss_cls: 0.02157  loss_box_reg: 0.04397  loss_rpn_cls: 0.0002954  loss_rpn_loc: 0.003955    time: 0.5621  last_time: 0.5453  data_time: 0.0815  last_data_time: 0.0758   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:15:56 d2.utils.events]: \u001b[0m eta: 0:34:48  iter: 5919  total_loss: 0.07557  loss_cls: 0.02127  loss_box_reg: 0.04607  loss_rpn_cls: 0.0003195  loss_rpn_loc: 0.005248    time: 0.5621  last_time: 0.5393  data_time: 0.0775  last_data_time: 0.0812   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:16:07 d2.utils.events]: \u001b[0m eta: 0:34:37  iter: 5939  total_loss: 0.07114  loss_cls: 0.02227  loss_box_reg: 0.0442  loss_rpn_cls: 0.000401  loss_rpn_loc: 0.004517    time: 0.5621  last_time: 0.5053  data_time: 0.0839  last_data_time: 0.0751   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:16:19 d2.utils.events]: \u001b[0m eta: 0:34:26  iter: 5959  total_loss: 0.06664  loss_cls: 0.0193  loss_box_reg: 0.04292  loss_rpn_cls: 0.0002466  loss_rpn_loc: 0.004547    time: 0.5621  last_time: 0.5640  data_time: 0.0752  last_data_time: 0.0813   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:16:30 d2.utils.events]: \u001b[0m eta: 0:34:15  iter: 5979  total_loss: 0.07506  loss_cls: 0.02299  loss_box_reg: 0.04438  loss_rpn_cls: 0.0005386  loss_rpn_loc: 0.006795    time: 0.5621  last_time: 0.6030  data_time: 0.0789  last_data_time: 0.0905   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:16:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[05/07 19:16:43 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[05/07 19:16:43 d2.data.common]: \u001b[0mSerializing 392 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/07 19:16:43 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/07 19:16:43 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "\u001b[32m[05/07 19:16:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 392 batches\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[32m[05/07 19:16:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/392. Dataloading: 0.0017 s/iter. Inference: 0.0364 s/iter. Eval: 0.0003 s/iter. Total: 0.0384 s/iter. ETA=0:00:14\n",
            "\u001b[32m[05/07 19:16:49 d2.evaluation.evaluator]: \u001b[0mInference done 143/392. Dataloading: 0.0020 s/iter. Inference: 0.0357 s/iter. Eval: 0.0003 s/iter. Total: 0.0380 s/iter. ETA=0:00:09\n",
            "\u001b[32m[05/07 19:16:54 d2.evaluation.evaluator]: \u001b[0mInference done 260/392. Dataloading: 0.0024 s/iter. Inference: 0.0376 s/iter. Eval: 0.0003 s/iter. Total: 0.0404 s/iter. ETA=0:00:05\n",
            "\u001b[32m[05/07 19:16:59 d2.evaluation.evaluator]: \u001b[0mInference done 377/392. Dataloading: 0.0025 s/iter. Inference: 0.0383 s/iter. Eval: 0.0003 s/iter. Total: 0.0412 s/iter. ETA=0:00:00\n",
            "\u001b[32m[05/07 19:17:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.933980 (0.041173 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 19:17:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.038099 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 19:17:00 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/07 19:17:00 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
            "\u001b[32m[05/07 19:17:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.24s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[05/07 19:17:00 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[05/07 19:17:00 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.04 seconds.\n",
            "\u001b[32m[05/07 19:17:00 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[05/07 19:17:00 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.501\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.762\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.558\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.257\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.517\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.485\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.597\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.612\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.379\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.627\n",
            "\u001b[32m[05/07 19:17:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 50.097 | 76.158 | 55.819 |  nan  | 25.672 | 51.713 |\n",
            "\u001b[32m[05/07 19:17:00 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[05/07 19:17:00 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| Axe        | 41.258 | Handgun    | 51.467 | Knife      | 57.567 |\n",
            "\u001b[32m[05/07 19:17:00 d2.engine.defaults]: \u001b[0mEvaluation results for intruder_valid in csv format:\n",
            "\u001b[32m[05/07 19:17:00 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/07 19:17:00 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/07 19:17:00 d2.evaluation.testing]: \u001b[0mcopypaste: 50.0973,76.1583,55.8189,nan,25.6716,51.7126\n",
            "\u001b[32m[05/07 19:17:00 d2.utils.events]: \u001b[0m eta: 0:34:03  iter: 5999  total_loss: 0.0691  loss_cls: 0.02214  loss_box_reg: 0.04147  loss_rpn_cls: 0.0003923  loss_rpn_loc: 0.005519    time: 0.5620  last_time: 0.5810  data_time: 0.0758  last_data_time: 0.0389   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:17:11 d2.utils.events]: \u001b[0m eta: 0:33:52  iter: 6019  total_loss: 0.07395  loss_cls: 0.02115  loss_box_reg: 0.04702  loss_rpn_cls: 0.0004305  loss_rpn_loc: 0.005019    time: 0.5621  last_time: 0.5484  data_time: 0.0797  last_data_time: 0.0774   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:17:23 d2.utils.events]: \u001b[0m eta: 0:33:40  iter: 6039  total_loss: 0.0745  loss_cls: 0.02202  loss_box_reg: 0.04308  loss_rpn_cls: 0.000518  loss_rpn_loc: 0.005539    time: 0.5621  last_time: 0.5540  data_time: 0.0857  last_data_time: 0.0824   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:17:34 d2.utils.events]: \u001b[0m eta: 0:33:29  iter: 6059  total_loss: 0.06132  loss_cls: 0.02124  loss_box_reg: 0.03896  loss_rpn_cls: 0.0009123  loss_rpn_loc: 0.005943    time: 0.5621  last_time: 0.5222  data_time: 0.0786  last_data_time: 0.0760   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:17:45 d2.utils.events]: \u001b[0m eta: 0:33:18  iter: 6079  total_loss: 0.06178  loss_cls: 0.01835  loss_box_reg: 0.03896  loss_rpn_cls: 0.0006991  loss_rpn_loc: 0.004441    time: 0.5620  last_time: 0.6716  data_time: 0.0748  last_data_time: 0.1175   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:17:56 d2.utils.events]: \u001b[0m eta: 0:33:06  iter: 6099  total_loss: 0.07449  loss_cls: 0.02298  loss_box_reg: 0.0436  loss_rpn_cls: 0.0006284  loss_rpn_loc: 0.005062    time: 0.5620  last_time: 0.5624  data_time: 0.0804  last_data_time: 0.0856   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:18:07 d2.utils.events]: \u001b[0m eta: 0:32:54  iter: 6119  total_loss: 0.06716  loss_cls: 0.02163  loss_box_reg: 0.04087  loss_rpn_cls: 0.0004963  loss_rpn_loc: 0.005222    time: 0.5620  last_time: 0.5705  data_time: 0.0813  last_data_time: 0.0888   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:18:19 d2.utils.events]: \u001b[0m eta: 0:32:43  iter: 6139  total_loss: 0.07523  loss_cls: 0.02294  loss_box_reg: 0.04458  loss_rpn_cls: 0.0004539  loss_rpn_loc: 0.006368    time: 0.5620  last_time: 0.5592  data_time: 0.0777  last_data_time: 0.0803   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:18:30 d2.utils.events]: \u001b[0m eta: 0:32:32  iter: 6159  total_loss: 0.08282  loss_cls: 0.02146  loss_box_reg: 0.05413  loss_rpn_cls: 0.0005581  loss_rpn_loc: 0.006126    time: 0.5620  last_time: 0.5576  data_time: 0.0838  last_data_time: 0.0805   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:18:41 d2.utils.events]: \u001b[0m eta: 0:32:20  iter: 6179  total_loss: 0.0619  loss_cls: 0.01799  loss_box_reg: 0.03761  loss_rpn_cls: 0.0006416  loss_rpn_loc: 0.004634    time: 0.5620  last_time: 0.5370  data_time: 0.0811  last_data_time: 0.0620   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:18:53 d2.utils.events]: \u001b[0m eta: 0:32:10  iter: 6199  total_loss: 0.05649  loss_cls: 0.01612  loss_box_reg: 0.03412  loss_rpn_cls: 0.0004324  loss_rpn_loc: 0.004556    time: 0.5621  last_time: 0.5580  data_time: 0.0891  last_data_time: 0.0893   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:19:04 d2.utils.events]: \u001b[0m eta: 0:31:59  iter: 6219  total_loss: 0.06362  loss_cls: 0.01922  loss_box_reg: 0.04222  loss_rpn_cls: 0.0004161  loss_rpn_loc: 0.006811    time: 0.5621  last_time: 0.5170  data_time: 0.0904  last_data_time: 0.0851   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:19:15 d2.utils.events]: \u001b[0m eta: 0:31:47  iter: 6239  total_loss: 0.07371  loss_cls: 0.0212  loss_box_reg: 0.04364  loss_rpn_cls: 0.0003766  loss_rpn_loc: 0.005382    time: 0.5621  last_time: 0.5167  data_time: 0.0763  last_data_time: 0.0360   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:19:26 d2.utils.events]: \u001b[0m eta: 0:31:36  iter: 6259  total_loss: 0.06194  loss_cls: 0.01895  loss_box_reg: 0.03831  loss_rpn_cls: 0.0006353  loss_rpn_loc: 0.004508    time: 0.5621  last_time: 0.6641  data_time: 0.0787  last_data_time: 0.1051   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:19:37 d2.utils.events]: \u001b[0m eta: 0:31:24  iter: 6279  total_loss: 0.0659  loss_cls: 0.01894  loss_box_reg: 0.03872  loss_rpn_cls: 0.0006245  loss_rpn_loc: 0.005794    time: 0.5620  last_time: 0.5462  data_time: 0.0770  last_data_time: 0.0627   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:19:49 d2.utils.events]: \u001b[0m eta: 0:31:15  iter: 6299  total_loss: 0.06035  loss_cls: 0.0182  loss_box_reg: 0.0364  loss_rpn_cls: 0.0002709  loss_rpn_loc: 0.005296    time: 0.5620  last_time: 0.5486  data_time: 0.0820  last_data_time: 0.0676   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:20:00 d2.utils.events]: \u001b[0m eta: 0:31:04  iter: 6319  total_loss: 0.05678  loss_cls: 0.01695  loss_box_reg: 0.03149  loss_rpn_cls: 0.0003434  loss_rpn_loc: 0.005571    time: 0.5621  last_time: 0.5375  data_time: 0.0849  last_data_time: 0.0655   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:20:11 d2.utils.events]: \u001b[0m eta: 0:30:52  iter: 6339  total_loss: 0.0688  loss_cls: 0.02025  loss_box_reg: 0.04144  loss_rpn_cls: 0.0004469  loss_rpn_loc: 0.005479    time: 0.5621  last_time: 0.5058  data_time: 0.0810  last_data_time: 0.0625   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:20:23 d2.utils.events]: \u001b[0m eta: 0:30:40  iter: 6359  total_loss: 0.06668  loss_cls: 0.0207  loss_box_reg: 0.04335  loss_rpn_cls: 0.0008351  loss_rpn_loc: 0.00531    time: 0.5621  last_time: 0.5024  data_time: 0.0840  last_data_time: 0.0700   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:20:34 d2.utils.events]: \u001b[0m eta: 0:30:31  iter: 6379  total_loss: 0.05913  loss_cls: 0.01781  loss_box_reg: 0.03619  loss_rpn_cls: 0.0007193  loss_rpn_loc: 0.006755    time: 0.5621  last_time: 0.5379  data_time: 0.0795  last_data_time: 0.0618   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:20:45 d2.utils.events]: \u001b[0m eta: 0:30:19  iter: 6399  total_loss: 0.07676  loss_cls: 0.02367  loss_box_reg: 0.04297  loss_rpn_cls: 0.00068  loss_rpn_loc: 0.007188    time: 0.5621  last_time: 0.5452  data_time: 0.0849  last_data_time: 0.0609   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:20:57 d2.utils.events]: \u001b[0m eta: 0:30:07  iter: 6419  total_loss: 0.06328  loss_cls: 0.02093  loss_box_reg: 0.03975  loss_rpn_cls: 0.0002919  loss_rpn_loc: 0.004999    time: 0.5621  last_time: 0.5400  data_time: 0.0844  last_data_time: 0.0746   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:21:08 d2.utils.events]: \u001b[0m eta: 0:29:57  iter: 6439  total_loss: 0.06334  loss_cls: 0.01904  loss_box_reg: 0.03848  loss_rpn_cls: 0.0004381  loss_rpn_loc: 0.004721    time: 0.5621  last_time: 0.7039  data_time: 0.0854  last_data_time: 0.1012   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:21:19 d2.utils.events]: \u001b[0m eta: 0:29:46  iter: 6459  total_loss: 0.05567  loss_cls: 0.017  loss_box_reg: 0.03355  loss_rpn_cls: 0.0004453  loss_rpn_loc: 0.005491    time: 0.5621  last_time: 0.5889  data_time: 0.0782  last_data_time: 0.0919   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:21:30 d2.utils.events]: \u001b[0m eta: 0:29:34  iter: 6479  total_loss: 0.07502  loss_cls: 0.02285  loss_box_reg: 0.04596  loss_rpn_cls: 0.0005076  loss_rpn_loc: 0.006174    time: 0.5621  last_time: 0.5539  data_time: 0.0798  last_data_time: 0.0782   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:21:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[05/07 19:21:44 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[05/07 19:21:44 d2.data.common]: \u001b[0mSerializing 392 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/07 19:21:44 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/07 19:21:44 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "\u001b[32m[05/07 19:21:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 392 batches\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[32m[05/07 19:21:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/392. Dataloading: 0.0078 s/iter. Inference: 0.0634 s/iter. Eval: 0.0003 s/iter. Total: 0.0716 s/iter. ETA=0:00:27\n",
            "\u001b[32m[05/07 19:21:50 d2.evaluation.evaluator]: \u001b[0mInference done 128/392. Dataloading: 0.0032 s/iter. Inference: 0.0407 s/iter. Eval: 0.0003 s/iter. Total: 0.0443 s/iter. ETA=0:00:11\n",
            "\u001b[32m[05/07 19:21:55 d2.evaluation.evaluator]: \u001b[0mInference done 258/392. Dataloading: 0.0027 s/iter. Inference: 0.0382 s/iter. Eval: 0.0003 s/iter. Total: 0.0413 s/iter. ETA=0:00:05\n",
            "\u001b[32m[05/07 19:22:00 d2.evaluation.evaluator]: \u001b[0mInference done 357/392. Dataloading: 0.0031 s/iter. Inference: 0.0405 s/iter. Eval: 0.0003 s/iter. Total: 0.0440 s/iter. ETA=0:00:01\n",
            "\u001b[32m[05/07 19:22:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.991358 (0.043905 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 19:22:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.040260 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 19:22:01 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/07 19:22:01 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
            "\u001b[32m[05/07 19:22:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[05/07 19:22:02 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[05/07 19:22:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.06 seconds.\n",
            "\u001b[32m[05/07 19:22:02 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[05/07 19:22:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.475\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.773\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.491\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.250\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.489\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.459\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.567\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.580\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.341\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.595\n",
            "\u001b[32m[05/07 19:22:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 47.456 | 77.325 | 49.053 |  nan  | 24.979 | 48.901 |\n",
            "\u001b[32m[05/07 19:22:02 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[05/07 19:22:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| Axe        | 36.359 | Handgun    | 51.901 | Knife      | 54.109 |\n",
            "\u001b[32m[05/07 19:22:02 d2.engine.defaults]: \u001b[0mEvaluation results for intruder_valid in csv format:\n",
            "\u001b[32m[05/07 19:22:02 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/07 19:22:02 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/07 19:22:02 d2.evaluation.testing]: \u001b[0mcopypaste: 47.4561,77.3253,49.0527,nan,24.9795,48.9012\n",
            "\u001b[32m[05/07 19:22:02 d2.utils.events]: \u001b[0m eta: 0:29:23  iter: 6499  total_loss: 0.06687  loss_cls: 0.01876  loss_box_reg: 0.04169  loss_rpn_cls: 0.001431  loss_rpn_loc: 0.00511    time: 0.5621  last_time: 0.5571  data_time: 0.0889  last_data_time: 0.0853   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:22:13 d2.utils.events]: \u001b[0m eta: 0:29:14  iter: 6519  total_loss: 0.05951  loss_cls: 0.01955  loss_box_reg: 0.03621  loss_rpn_cls: 0.000542  loss_rpn_loc: 0.00512    time: 0.5622  last_time: 0.5908  data_time: 0.0881  last_data_time: 0.0843   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:22:25 d2.utils.events]: \u001b[0m eta: 0:29:04  iter: 6539  total_loss: 0.06218  loss_cls: 0.01843  loss_box_reg: 0.03886  loss_rpn_cls: 0.0003354  loss_rpn_loc: 0.004426    time: 0.5622  last_time: 0.6433  data_time: 0.0893  last_data_time: 0.1620   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:22:36 d2.utils.events]: \u001b[0m eta: 0:28:53  iter: 6559  total_loss: 0.07148  loss_cls: 0.02264  loss_box_reg: 0.04281  loss_rpn_cls: 0.000429  loss_rpn_loc: 0.005765    time: 0.5622  last_time: 0.6557  data_time: 0.0807  last_data_time: 0.1248   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:22:47 d2.utils.events]: \u001b[0m eta: 0:28:42  iter: 6579  total_loss: 0.07014  loss_cls: 0.02181  loss_box_reg: 0.04109  loss_rpn_cls: 0.0003989  loss_rpn_loc: 0.004792    time: 0.5622  last_time: 0.5197  data_time: 0.0839  last_data_time: 0.0723   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:22:59 d2.utils.events]: \u001b[0m eta: 0:28:33  iter: 6599  total_loss: 0.06608  loss_cls: 0.0213  loss_box_reg: 0.04025  loss_rpn_cls: 0.0004897  loss_rpn_loc: 0.005479    time: 0.5623  last_time: 0.5882  data_time: 0.0854  last_data_time: 0.0953   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:23:10 d2.utils.events]: \u001b[0m eta: 0:28:22  iter: 6619  total_loss: 0.06254  loss_cls: 0.01969  loss_box_reg: 0.03807  loss_rpn_cls: 0.0004223  loss_rpn_loc: 0.004333    time: 0.5623  last_time: 0.5517  data_time: 0.0795  last_data_time: 0.0656   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:23:22 d2.utils.events]: \u001b[0m eta: 0:28:13  iter: 6639  total_loss: 0.06469  loss_cls: 0.02016  loss_box_reg: 0.04003  loss_rpn_cls: 0.0002499  loss_rpn_loc: 0.004605    time: 0.5623  last_time: 0.5677  data_time: 0.0823  last_data_time: 0.0972   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:23:33 d2.utils.events]: \u001b[0m eta: 0:28:02  iter: 6659  total_loss: 0.06998  loss_cls: 0.02141  loss_box_reg: 0.04446  loss_rpn_cls: 0.000634  loss_rpn_loc: 0.005338    time: 0.5624  last_time: 0.5739  data_time: 0.0752  last_data_time: 0.0956   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:23:45 d2.utils.events]: \u001b[0m eta: 0:27:52  iter: 6679  total_loss: 0.06984  loss_cls: 0.02062  loss_box_reg: 0.04399  loss_rpn_cls: 0.0004149  loss_rpn_loc: 0.004658    time: 0.5624  last_time: 0.5579  data_time: 0.0903  last_data_time: 0.0746   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:23:57 d2.utils.events]: \u001b[0m eta: 0:27:41  iter: 6699  total_loss: 0.06254  loss_cls: 0.01755  loss_box_reg: 0.03763  loss_rpn_cls: 0.0004629  loss_rpn_loc: 0.006134    time: 0.5625  last_time: 0.5734  data_time: 0.0838  last_data_time: 0.0973   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:24:08 d2.utils.events]: \u001b[0m eta: 0:27:30  iter: 6719  total_loss: 0.06798  loss_cls: 0.01867  loss_box_reg: 0.03962  loss_rpn_cls: 0.0002975  loss_rpn_loc: 0.005127    time: 0.5625  last_time: 0.5640  data_time: 0.0854  last_data_time: 0.0802   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:24:19 d2.utils.events]: \u001b[0m eta: 0:27:19  iter: 6739  total_loss: 0.0589  loss_cls: 0.01774  loss_box_reg: 0.03658  loss_rpn_cls: 0.0002149  loss_rpn_loc: 0.00527    time: 0.5625  last_time: 0.5663  data_time: 0.0850  last_data_time: 0.0907   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:24:30 d2.utils.events]: \u001b[0m eta: 0:27:08  iter: 6759  total_loss: 0.06599  loss_cls: 0.01848  loss_box_reg: 0.04083  loss_rpn_cls: 0.000372  loss_rpn_loc: 0.005897    time: 0.5625  last_time: 0.6262  data_time: 0.0824  last_data_time: 0.0967   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:24:42 d2.utils.events]: \u001b[0m eta: 0:26:57  iter: 6779  total_loss: 0.06354  loss_cls: 0.01921  loss_box_reg: 0.03857  loss_rpn_cls: 0.0002466  loss_rpn_loc: 0.00489    time: 0.5625  last_time: 0.5826  data_time: 0.0820  last_data_time: 0.1046   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:24:53 d2.utils.events]: \u001b[0m eta: 0:26:47  iter: 6799  total_loss: 0.07405  loss_cls: 0.02391  loss_box_reg: 0.04582  loss_rpn_cls: 0.0006796  loss_rpn_loc: 0.004742    time: 0.5625  last_time: 0.5751  data_time: 0.0843  last_data_time: 0.0881   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:25:05 d2.utils.events]: \u001b[0m eta: 0:26:36  iter: 6819  total_loss: 0.06233  loss_cls: 0.01832  loss_box_reg: 0.03901  loss_rpn_cls: 0.000277  loss_rpn_loc: 0.005158    time: 0.5626  last_time: 0.5464  data_time: 0.0875  last_data_time: 0.0702   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:25:16 d2.utils.events]: \u001b[0m eta: 0:26:26  iter: 6839  total_loss: 0.06984  loss_cls: 0.02017  loss_box_reg: 0.04058  loss_rpn_cls: 0.0006056  loss_rpn_loc: 0.005219    time: 0.5626  last_time: 0.5799  data_time: 0.0875  last_data_time: 0.0994   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:25:28 d2.utils.events]: \u001b[0m eta: 0:26:15  iter: 6859  total_loss: 0.06241  loss_cls: 0.0176  loss_box_reg: 0.03856  loss_rpn_cls: 0.0002945  loss_rpn_loc: 0.004743    time: 0.5627  last_time: 0.5567  data_time: 0.0826  last_data_time: 0.0791   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:25:39 d2.utils.events]: \u001b[0m eta: 0:26:05  iter: 6879  total_loss: 0.07066  loss_cls: 0.02029  loss_box_reg: 0.0438  loss_rpn_cls: 0.0004857  loss_rpn_loc: 0.005939    time: 0.5627  last_time: 0.5097  data_time: 0.0860  last_data_time: 0.0608   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:25:51 d2.utils.events]: \u001b[0m eta: 0:25:54  iter: 6899  total_loss: 0.06311  loss_cls: 0.01955  loss_box_reg: 0.038  loss_rpn_cls: 0.0005082  loss_rpn_loc: 0.004462    time: 0.5627  last_time: 0.5759  data_time: 0.0921  last_data_time: 0.0956   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:26:03 d2.utils.events]: \u001b[0m eta: 0:25:43  iter: 6919  total_loss: 0.05584  loss_cls: 0.01673  loss_box_reg: 0.03399  loss_rpn_cls: 0.000349  loss_rpn_loc: 0.00543    time: 0.5628  last_time: 0.5564  data_time: 0.0789  last_data_time: 0.0818   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:26:14 d2.utils.events]: \u001b[0m eta: 0:25:32  iter: 6939  total_loss: 0.06425  loss_cls: 0.01839  loss_box_reg: 0.04066  loss_rpn_cls: 0.0005352  loss_rpn_loc: 0.005105    time: 0.5628  last_time: 0.6754  data_time: 0.0868  last_data_time: 0.1596   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:26:25 d2.utils.events]: \u001b[0m eta: 0:25:21  iter: 6959  total_loss: 0.05333  loss_cls: 0.0173  loss_box_reg: 0.03227  loss_rpn_cls: 0.000437  loss_rpn_loc: 0.004256    time: 0.5628  last_time: 0.6161  data_time: 0.0803  last_data_time: 0.0593   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:26:37 d2.utils.events]: \u001b[0m eta: 0:25:12  iter: 6979  total_loss: 0.06178  loss_cls: 0.02029  loss_box_reg: 0.03735  loss_rpn_cls: 0.0007759  loss_rpn_loc: 0.005643    time: 0.5629  last_time: 0.5302  data_time: 0.0841  last_data_time: 0.0572   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:26:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[05/07 19:26:50 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[05/07 19:26:50 d2.data.common]: \u001b[0mSerializing 392 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/07 19:26:50 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/07 19:26:50 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "\u001b[32m[05/07 19:26:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 392 batches\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[32m[05/07 19:26:51 d2.evaluation.evaluator]: \u001b[0mInference done 11/392. Dataloading: 0.0083 s/iter. Inference: 0.0622 s/iter. Eval: 0.0003 s/iter. Total: 0.0707 s/iter. ETA=0:00:26\n",
            "\u001b[32m[05/07 19:26:56 d2.evaluation.evaluator]: \u001b[0mInference done 119/392. Dataloading: 0.0038 s/iter. Inference: 0.0434 s/iter. Eval: 0.0003 s/iter. Total: 0.0476 s/iter. ETA=0:00:13\n",
            "\u001b[32m[05/07 19:27:01 d2.evaluation.evaluator]: \u001b[0mInference done 250/392. Dataloading: 0.0030 s/iter. Inference: 0.0393 s/iter. Eval: 0.0003 s/iter. Total: 0.0427 s/iter. ETA=0:00:06\n",
            "\u001b[32m[05/07 19:27:06 d2.evaluation.evaluator]: \u001b[0mInference done 351/392. Dataloading: 0.0033 s/iter. Inference: 0.0410 s/iter. Eval: 0.0004 s/iter. Total: 0.0448 s/iter. ETA=0:00:01\n",
            "\u001b[32m[05/07 19:27:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.096747 (0.044178 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 19:27:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.040354 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 19:27:08 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/07 19:27:08 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
            "\u001b[32m[05/07 19:27:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[05/07 19:27:08 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[05/07 19:27:08 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.04 seconds.\n",
            "\u001b[32m[05/07 19:27:08 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[05/07 19:27:08 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.465\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.758\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.476\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.266\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.480\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.459\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.556\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.570\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.371\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.582\n",
            "\u001b[32m[05/07 19:27:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 46.466 | 75.767 | 47.565 |  nan  | 26.589 | 47.950 |\n",
            "\u001b[32m[05/07 19:27:08 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[05/07 19:27:08 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| Axe        | 38.754 | Handgun    | 46.147 | Knife      | 54.499 |\n",
            "\u001b[32m[05/07 19:27:08 d2.engine.defaults]: \u001b[0mEvaluation results for intruder_valid in csv format:\n",
            "\u001b[32m[05/07 19:27:08 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/07 19:27:08 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/07 19:27:08 d2.evaluation.testing]: \u001b[0mcopypaste: 46.4665,75.7666,47.5648,nan,26.5888,47.9505\n",
            "\u001b[32m[05/07 19:27:08 d2.utils.events]: \u001b[0m eta: 0:25:01  iter: 6999  total_loss: 0.07161  loss_cls: 0.01935  loss_box_reg: 0.04252  loss_rpn_cls: 0.0006396  loss_rpn_loc: 0.005223    time: 0.5629  last_time: 0.5666  data_time: 0.0847  last_data_time: 0.0878   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:27:20 d2.utils.events]: \u001b[0m eta: 0:24:51  iter: 7019  total_loss: 0.06732  loss_cls: 0.01962  loss_box_reg: 0.04024  loss_rpn_cls: 0.0003488  loss_rpn_loc: 0.005662    time: 0.5629  last_time: 0.5715  data_time: 0.0861  last_data_time: 0.0946   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:27:31 d2.utils.events]: \u001b[0m eta: 0:24:40  iter: 7039  total_loss: 0.06054  loss_cls: 0.01784  loss_box_reg: 0.03594  loss_rpn_cls: 0.0006111  loss_rpn_loc: 0.005618    time: 0.5629  last_time: 0.6322  data_time: 0.0751  last_data_time: 0.1472   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:27:42 d2.utils.events]: \u001b[0m eta: 0:24:29  iter: 7059  total_loss: 0.07366  loss_cls: 0.02028  loss_box_reg: 0.04777  loss_rpn_cls: 0.000278  loss_rpn_loc: 0.00464    time: 0.5629  last_time: 0.5619  data_time: 0.0780  last_data_time: 0.0772   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:27:54 d2.utils.events]: \u001b[0m eta: 0:24:19  iter: 7079  total_loss: 0.06336  loss_cls: 0.0195  loss_box_reg: 0.03889  loss_rpn_cls: 0.0006276  loss_rpn_loc: 0.006262    time: 0.5630  last_time: 0.5656  data_time: 0.0835  last_data_time: 0.0773   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:28:05 d2.utils.events]: \u001b[0m eta: 0:24:08  iter: 7099  total_loss: 0.06293  loss_cls: 0.01983  loss_box_reg: 0.03946  loss_rpn_cls: 0.0004515  loss_rpn_loc: 0.004945    time: 0.5630  last_time: 0.5437  data_time: 0.0845  last_data_time: 0.0897   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:28:17 d2.utils.events]: \u001b[0m eta: 0:23:57  iter: 7119  total_loss: 0.06334  loss_cls: 0.01799  loss_box_reg: 0.04018  loss_rpn_cls: 0.0002557  loss_rpn_loc: 0.004628    time: 0.5631  last_time: 0.5757  data_time: 0.0841  last_data_time: 0.1102   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:28:29 d2.utils.events]: \u001b[0m eta: 0:23:47  iter: 7139  total_loss: 0.05813  loss_cls: 0.01798  loss_box_reg: 0.03557  loss_rpn_cls: 0.0004033  loss_rpn_loc: 0.004614    time: 0.5631  last_time: 0.5598  data_time: 0.0900  last_data_time: 0.0760   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:28:40 d2.utils.events]: \u001b[0m eta: 0:23:36  iter: 7159  total_loss: 0.07114  loss_cls: 0.01983  loss_box_reg: 0.043  loss_rpn_cls: 0.0002862  loss_rpn_loc: 0.005749    time: 0.5631  last_time: 0.5716  data_time: 0.0901  last_data_time: 0.0957   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:28:51 d2.utils.events]: \u001b[0m eta: 0:23:25  iter: 7179  total_loss: 0.06671  loss_cls: 0.02109  loss_box_reg: 0.03839  loss_rpn_cls: 0.0003749  loss_rpn_loc: 0.005686    time: 0.5632  last_time: 0.5408  data_time: 0.0854  last_data_time: 0.0762   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:29:03 d2.utils.events]: \u001b[0m eta: 0:23:15  iter: 7199  total_loss: 0.07979  loss_cls: 0.02256  loss_box_reg: 0.05028  loss_rpn_cls: 0.0003671  loss_rpn_loc: 0.005427    time: 0.5632  last_time: 0.5648  data_time: 0.0907  last_data_time: 0.0811   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:29:14 d2.utils.events]: \u001b[0m eta: 0:23:04  iter: 7219  total_loss: 0.07491  loss_cls: 0.02017  loss_box_reg: 0.04684  loss_rpn_cls: 0.0006843  loss_rpn_loc: 0.005907    time: 0.5632  last_time: 0.5872  data_time: 0.0810  last_data_time: 0.0964   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:29:25 d2.utils.events]: \u001b[0m eta: 0:22:52  iter: 7239  total_loss: 0.06252  loss_cls: 0.01743  loss_box_reg: 0.03722  loss_rpn_cls: 0.000388  loss_rpn_loc: 0.004823    time: 0.5632  last_time: 0.6743  data_time: 0.0753  last_data_time: 0.1040   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:29:37 d2.utils.events]: \u001b[0m eta: 0:22:42  iter: 7259  total_loss: 0.06342  loss_cls: 0.01767  loss_box_reg: 0.03813  loss_rpn_cls: 0.0002727  loss_rpn_loc: 0.004725    time: 0.5632  last_time: 0.5629  data_time: 0.0862  last_data_time: 0.1002   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:29:48 d2.utils.events]: \u001b[0m eta: 0:22:31  iter: 7279  total_loss: 0.05674  loss_cls: 0.01629  loss_box_reg: 0.03549  loss_rpn_cls: 0.000323  loss_rpn_loc: 0.00448    time: 0.5632  last_time: 0.5418  data_time: 0.0814  last_data_time: 0.0642   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:30:00 d2.utils.events]: \u001b[0m eta: 0:22:20  iter: 7299  total_loss: 0.05752  loss_cls: 0.01769  loss_box_reg: 0.03602  loss_rpn_cls: 0.0004047  loss_rpn_loc: 0.004439    time: 0.5632  last_time: 0.5451  data_time: 0.0804  last_data_time: 0.0693   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:30:11 d2.utils.events]: \u001b[0m eta: 0:22:09  iter: 7319  total_loss: 0.06415  loss_cls: 0.01863  loss_box_reg: 0.0403  loss_rpn_cls: 0.0004855  loss_rpn_loc: 0.005844    time: 0.5633  last_time: 0.5808  data_time: 0.0905  last_data_time: 0.0879   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:30:23 d2.utils.events]: \u001b[0m eta: 0:21:58  iter: 7339  total_loss: 0.06727  loss_cls: 0.02055  loss_box_reg: 0.04116  loss_rpn_cls: 0.0004194  loss_rpn_loc: 0.004891    time: 0.5633  last_time: 0.5654  data_time: 0.0902  last_data_time: 0.0596   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:30:34 d2.utils.events]: \u001b[0m eta: 0:21:47  iter: 7359  total_loss: 0.06534  loss_cls: 0.02115  loss_box_reg: 0.04025  loss_rpn_cls: 0.0002858  loss_rpn_loc: 0.005012    time: 0.5633  last_time: 0.5462  data_time: 0.0800  last_data_time: 0.0695   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:30:46 d2.utils.events]: \u001b[0m eta: 0:21:37  iter: 7379  total_loss: 0.0651  loss_cls: 0.01944  loss_box_reg: 0.03918  loss_rpn_cls: 0.0006618  loss_rpn_loc: 0.006193    time: 0.5633  last_time: 0.5592  data_time: 0.0822  last_data_time: 0.0698   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:30:57 d2.utils.events]: \u001b[0m eta: 0:21:26  iter: 7399  total_loss: 0.06439  loss_cls: 0.01695  loss_box_reg: 0.0402  loss_rpn_cls: 0.0008534  loss_rpn_loc: 0.004856    time: 0.5634  last_time: 0.5403  data_time: 0.0895  last_data_time: 0.0577   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:31:09 d2.utils.events]: \u001b[0m eta: 0:21:15  iter: 7419  total_loss: 0.0588  loss_cls: 0.0178  loss_box_reg: 0.03687  loss_rpn_cls: 0.0004091  loss_rpn_loc: 0.005091    time: 0.5634  last_time: 0.6839  data_time: 0.0860  last_data_time: 0.1217   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:31:20 d2.utils.events]: \u001b[0m eta: 0:21:04  iter: 7439  total_loss: 0.06074  loss_cls: 0.01771  loss_box_reg: 0.03639  loss_rpn_cls: 0.0003892  loss_rpn_loc: 0.005665    time: 0.5634  last_time: 0.5738  data_time: 0.0780  last_data_time: 0.0723   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:31:31 d2.utils.events]: \u001b[0m eta: 0:20:53  iter: 7459  total_loss: 0.06692  loss_cls: 0.01966  loss_box_reg: 0.04242  loss_rpn_cls: 0.0003872  loss_rpn_loc: 0.005339    time: 0.5634  last_time: 0.5703  data_time: 0.0927  last_data_time: 0.0965   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:31:43 d2.utils.events]: \u001b[0m eta: 0:20:42  iter: 7479  total_loss: 0.05906  loss_cls: 0.01728  loss_box_reg: 0.03504  loss_rpn_cls: 0.000197  loss_rpn_loc: 0.005345    time: 0.5634  last_time: 0.5374  data_time: 0.0883  last_data_time: 0.0983   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:31:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[05/07 19:31:56 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[05/07 19:31:56 d2.data.common]: \u001b[0mSerializing 392 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/07 19:31:56 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/07 19:31:56 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "\u001b[32m[05/07 19:31:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 392 batches\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[32m[05/07 19:31:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/392. Dataloading: 0.0032 s/iter. Inference: 0.0376 s/iter. Eval: 0.0003 s/iter. Total: 0.0411 s/iter. ETA=0:00:15\n",
            "\u001b[32m[05/07 19:32:02 d2.evaluation.evaluator]: \u001b[0mInference done 104/392. Dataloading: 0.0049 s/iter. Inference: 0.0477 s/iter. Eval: 0.0004 s/iter. Total: 0.0531 s/iter. ETA=0:00:15\n",
            "\u001b[32m[05/07 19:32:07 d2.evaluation.evaluator]: \u001b[0mInference done 227/392. Dataloading: 0.0036 s/iter. Inference: 0.0422 s/iter. Eval: 0.0004 s/iter. Total: 0.0463 s/iter. ETA=0:00:07\n",
            "\u001b[32m[05/07 19:32:12 d2.evaluation.evaluator]: \u001b[0mInference done 345/392. Dataloading: 0.0035 s/iter. Inference: 0.0411 s/iter. Eval: 0.0004 s/iter. Total: 0.0450 s/iter. ETA=0:00:02\n",
            "\u001b[32m[05/07 19:32:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.072642 (0.046699 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 19:32:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.042322 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 19:32:15 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/07 19:32:15 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
            "\u001b[32m[05/07 19:32:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[05/07 19:32:15 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[05/07 19:32:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.03 seconds.\n",
            "\u001b[32m[05/07 19:32:15 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[05/07 19:32:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.472\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.747\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.501\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.282\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.486\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.470\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.563\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.578\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.339\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.592\n",
            "\u001b[32m[05/07 19:32:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 47.179 | 74.718 | 50.105 |  nan  | 28.170 | 48.593 |\n",
            "\u001b[32m[05/07 19:32:15 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[05/07 19:32:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| Axe        | 36.829 | Handgun    | 50.594 | Knife      | 54.114 |\n",
            "\u001b[32m[05/07 19:32:15 d2.engine.defaults]: \u001b[0mEvaluation results for intruder_valid in csv format:\n",
            "\u001b[32m[05/07 19:32:15 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/07 19:32:15 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/07 19:32:15 d2.evaluation.testing]: \u001b[0mcopypaste: 47.1793,74.7181,50.1053,nan,28.1703,48.5931\n",
            "\u001b[32m[05/07 19:32:15 d2.utils.events]: \u001b[0m eta: 0:20:30  iter: 7499  total_loss: 0.07377  loss_cls: 0.01934  loss_box_reg: 0.04611  loss_rpn_cls: 0.0003171  loss_rpn_loc: 0.006199    time: 0.5635  last_time: 0.5545  data_time: 0.0931  last_data_time: 0.0708   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:32:26 d2.utils.events]: \u001b[0m eta: 0:20:19  iter: 7519  total_loss: 0.0655  loss_cls: 0.01879  loss_box_reg: 0.04135  loss_rpn_cls: 0.0004904  loss_rpn_loc: 0.006236    time: 0.5635  last_time: 0.6545  data_time: 0.0845  last_data_time: 0.0985   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:32:38 d2.utils.events]: \u001b[0m eta: 0:20:08  iter: 7539  total_loss: 0.06343  loss_cls: 0.0185  loss_box_reg: 0.03915  loss_rpn_cls: 0.0005418  loss_rpn_loc: 0.005468    time: 0.5635  last_time: 0.6595  data_time: 0.0788  last_data_time: 0.1180   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:32:49 d2.utils.events]: \u001b[0m eta: 0:19:57  iter: 7559  total_loss: 0.06422  loss_cls: 0.02079  loss_box_reg: 0.03978  loss_rpn_cls: 0.0003387  loss_rpn_loc: 0.005424    time: 0.5635  last_time: 0.5475  data_time: 0.0788  last_data_time: 0.0629   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:33:01 d2.utils.events]: \u001b[0m eta: 0:19:46  iter: 7579  total_loss: 0.06778  loss_cls: 0.01873  loss_box_reg: 0.04094  loss_rpn_cls: 0.0004079  loss_rpn_loc: 0.006468    time: 0.5636  last_time: 0.5828  data_time: 0.0833  last_data_time: 0.0967   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:33:12 d2.utils.events]: \u001b[0m eta: 0:19:34  iter: 7599  total_loss: 0.05847  loss_cls: 0.01749  loss_box_reg: 0.03467  loss_rpn_cls: 0.0001946  loss_rpn_loc: 0.005866    time: 0.5636  last_time: 0.5396  data_time: 0.0811  last_data_time: 0.0843   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:33:24 d2.utils.events]: \u001b[0m eta: 0:19:24  iter: 7619  total_loss: 0.06231  loss_cls: 0.01669  loss_box_reg: 0.03704  loss_rpn_cls: 0.0005293  loss_rpn_loc: 0.004503    time: 0.5636  last_time: 0.5748  data_time: 0.0776  last_data_time: 0.0889   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:33:35 d2.utils.events]: \u001b[0m eta: 0:19:12  iter: 7639  total_loss: 0.06725  loss_cls: 0.01843  loss_box_reg: 0.03954  loss_rpn_cls: 0.0004607  loss_rpn_loc: 0.004963    time: 0.5636  last_time: 0.5779  data_time: 0.0898  last_data_time: 0.0877   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:33:46 d2.utils.events]: \u001b[0m eta: 0:19:01  iter: 7659  total_loss: 0.06473  loss_cls: 0.01887  loss_box_reg: 0.04168  loss_rpn_cls: 0.0005966  loss_rpn_loc: 0.005746    time: 0.5637  last_time: 0.5728  data_time: 0.0806  last_data_time: 0.0840   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:33:58 d2.utils.events]: \u001b[0m eta: 0:18:50  iter: 7679  total_loss: 0.06775  loss_cls: 0.0185  loss_box_reg: 0.04235  loss_rpn_cls: 0.0006589  loss_rpn_loc: 0.006174    time: 0.5637  last_time: 0.5645  data_time: 0.0886  last_data_time: 0.0743   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:34:09 d2.utils.events]: \u001b[0m eta: 0:18:39  iter: 7699  total_loss: 0.04975  loss_cls: 0.01422  loss_box_reg: 0.02756  loss_rpn_cls: 0.0005388  loss_rpn_loc: 0.006137    time: 0.5637  last_time: 0.4925  data_time: 0.0834  last_data_time: 0.0756   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:34:21 d2.utils.events]: \u001b[0m eta: 0:18:28  iter: 7719  total_loss: 0.05675  loss_cls: 0.01709  loss_box_reg: 0.03428  loss_rpn_cls: 0.0006681  loss_rpn_loc: 0.004768    time: 0.5637  last_time: 0.6924  data_time: 0.0748  last_data_time: 0.1239   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:34:32 d2.utils.events]: \u001b[0m eta: 0:18:16  iter: 7739  total_loss: 0.06217  loss_cls: 0.01915  loss_box_reg: 0.03866  loss_rpn_cls: 0.0005216  loss_rpn_loc: 0.00511    time: 0.5637  last_time: 0.5947  data_time: 0.0791  last_data_time: 0.0995   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:34:43 d2.utils.events]: \u001b[0m eta: 0:18:05  iter: 7759  total_loss: 0.07123  loss_cls: 0.02107  loss_box_reg: 0.04183  loss_rpn_cls: 0.0004388  loss_rpn_loc: 0.005635    time: 0.5637  last_time: 0.5614  data_time: 0.0703  last_data_time: 0.0802   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:34:54 d2.utils.events]: \u001b[0m eta: 0:17:53  iter: 7779  total_loss: 0.07019  loss_cls: 0.01986  loss_box_reg: 0.04469  loss_rpn_cls: 0.0005363  loss_rpn_loc: 0.005678    time: 0.5637  last_time: 0.5625  data_time: 0.0849  last_data_time: 0.0691   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:35:06 d2.utils.events]: \u001b[0m eta: 0:17:42  iter: 7799  total_loss: 0.06095  loss_cls: 0.02005  loss_box_reg: 0.03481  loss_rpn_cls: 0.0004345  loss_rpn_loc: 0.004748    time: 0.5637  last_time: 0.5003  data_time: 0.0830  last_data_time: 0.0225   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:35:17 d2.utils.events]: \u001b[0m eta: 0:17:31  iter: 7819  total_loss: 0.05949  loss_cls: 0.01614  loss_box_reg: 0.03578  loss_rpn_cls: 0.0003259  loss_rpn_loc: 0.005364    time: 0.5637  last_time: 0.5526  data_time: 0.0789  last_data_time: 0.0676   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:35:28 d2.utils.events]: \u001b[0m eta: 0:17:19  iter: 7839  total_loss: 0.06089  loss_cls: 0.01812  loss_box_reg: 0.03624  loss_rpn_cls: 0.0005887  loss_rpn_loc: 0.005139    time: 0.5637  last_time: 0.5123  data_time: 0.0744  last_data_time: 0.0276   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:35:40 d2.utils.events]: \u001b[0m eta: 0:17:08  iter: 7859  total_loss: 0.0527  loss_cls: 0.0173  loss_box_reg: 0.03105  loss_rpn_cls: 0.0002467  loss_rpn_loc: 0.005252    time: 0.5637  last_time: 0.5489  data_time: 0.0810  last_data_time: 0.0733   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:35:51 d2.utils.events]: \u001b[0m eta: 0:16:57  iter: 7879  total_loss: 0.05662  loss_cls: 0.01778  loss_box_reg: 0.03503  loss_rpn_cls: 0.0004177  loss_rpn_loc: 0.005476    time: 0.5637  last_time: 0.5532  data_time: 0.0839  last_data_time: 0.0683   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:36:03 d2.utils.events]: \u001b[0m eta: 0:16:45  iter: 7899  total_loss: 0.06836  loss_cls: 0.01956  loss_box_reg: 0.042  loss_rpn_cls: 0.0004203  loss_rpn_loc: 0.005282    time: 0.5637  last_time: 0.6648  data_time: 0.0828  last_data_time: 0.1319   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:36:14 d2.utils.events]: \u001b[0m eta: 0:16:33  iter: 7919  total_loss: 0.07562  loss_cls: 0.02029  loss_box_reg: 0.04606  loss_rpn_cls: 0.0003577  loss_rpn_loc: 0.005246    time: 0.5637  last_time: 0.6851  data_time: 0.0796  last_data_time: 0.1753   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:36:25 d2.utils.events]: \u001b[0m eta: 0:16:22  iter: 7939  total_loss: 0.05765  loss_cls: 0.01736  loss_box_reg: 0.03195  loss_rpn_cls: 0.0004259  loss_rpn_loc: 0.005172    time: 0.5637  last_time: 0.5178  data_time: 0.0810  last_data_time: 0.0709   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:36:36 d2.utils.events]: \u001b[0m eta: 0:16:11  iter: 7959  total_loss: 0.05643  loss_cls: 0.01585  loss_box_reg: 0.03242  loss_rpn_cls: 0.0006683  loss_rpn_loc: 0.004749    time: 0.5637  last_time: 0.5111  data_time: 0.0795  last_data_time: 0.0771   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:36:48 d2.utils.events]: \u001b[0m eta: 0:15:59  iter: 7979  total_loss: 0.07666  loss_cls: 0.0234  loss_box_reg: 0.04856  loss_rpn_cls: 0.0003538  loss_rpn_loc: 0.005827    time: 0.5638  last_time: 0.5534  data_time: 0.0828  last_data_time: 0.0748   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:37:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[05/07 19:37:01 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[05/07 19:37:01 d2.data.common]: \u001b[0mSerializing 392 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/07 19:37:01 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/07 19:37:01 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "\u001b[32m[05/07 19:37:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 392 batches\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[32m[05/07 19:37:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/392. Dataloading: 0.0016 s/iter. Inference: 0.0357 s/iter. Eval: 0.0003 s/iter. Total: 0.0376 s/iter. ETA=0:00:14\n",
            "\u001b[32m[05/07 19:37:07 d2.evaluation.evaluator]: \u001b[0mInference done 111/392. Dataloading: 0.0042 s/iter. Inference: 0.0450 s/iter. Eval: 0.0003 s/iter. Total: 0.0496 s/iter. ETA=0:00:13\n",
            "\u001b[32m[05/07 19:37:12 d2.evaluation.evaluator]: \u001b[0mInference done 243/392. Dataloading: 0.0031 s/iter. Inference: 0.0397 s/iter. Eval: 0.0003 s/iter. Total: 0.0432 s/iter. ETA=0:00:06\n",
            "\u001b[32m[05/07 19:37:17 d2.evaluation.evaluator]: \u001b[0mInference done 366/392. Dataloading: 0.0030 s/iter. Inference: 0.0391 s/iter. Eval: 0.0003 s/iter. Total: 0.0425 s/iter. ETA=0:00:01\n",
            "\u001b[32m[05/07 19:37:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.917865 (0.043715 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 19:37:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.039930 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 19:37:18 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/07 19:37:18 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
            "\u001b[32m[05/07 19:37:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[05/07 19:37:18 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[05/07 19:37:18 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.06 seconds.\n",
            "\u001b[32m[05/07 19:37:18 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[05/07 19:37:18 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.489\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.774\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.518\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.291\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.502\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.477\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.576\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.589\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.381\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.602\n",
            "\u001b[32m[05/07 19:37:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 48.876 | 77.401 | 51.814 |  nan  | 29.119 | 50.211 |\n",
            "\u001b[32m[05/07 19:37:18 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[05/07 19:37:18 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| Axe        | 40.496 | Handgun    | 51.768 | Knife      | 54.364 |\n",
            "\u001b[32m[05/07 19:37:18 d2.engine.defaults]: \u001b[0mEvaluation results for intruder_valid in csv format:\n",
            "\u001b[32m[05/07 19:37:18 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/07 19:37:18 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/07 19:37:18 d2.evaluation.testing]: \u001b[0mcopypaste: 48.8760,77.4007,51.8138,nan,29.1189,50.2112\n",
            "\u001b[32m[05/07 19:37:18 d2.utils.events]: \u001b[0m eta: 0:15:48  iter: 7999  total_loss: 0.05801  loss_cls: 0.01967  loss_box_reg: 0.03523  loss_rpn_cls: 0.0002768  loss_rpn_loc: 0.004279    time: 0.5638  last_time: 0.5103  data_time: 0.0809  last_data_time: 0.0759   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:37:30 d2.utils.events]: \u001b[0m eta: 0:15:36  iter: 8019  total_loss: 0.04874  loss_cls: 0.01534  loss_box_reg: 0.03  loss_rpn_cls: 0.0002952  loss_rpn_loc: 0.00458    time: 0.5637  last_time: 0.6499  data_time: 0.0813  last_data_time: 0.1241   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:37:41 d2.utils.events]: \u001b[0m eta: 0:15:25  iter: 8039  total_loss: 0.06333  loss_cls: 0.01849  loss_box_reg: 0.0376  loss_rpn_cls: 0.0001962  loss_rpn_loc: 0.004599    time: 0.5637  last_time: 0.5436  data_time: 0.0804  last_data_time: 0.0590   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:37:52 d2.utils.events]: \u001b[0m eta: 0:15:14  iter: 8059  total_loss: 0.06751  loss_cls: 0.0205  loss_box_reg: 0.04189  loss_rpn_cls: 0.0003997  loss_rpn_loc: 0.005798    time: 0.5638  last_time: 0.5139  data_time: 0.0795  last_data_time: 0.0745   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:38:04 d2.utils.events]: \u001b[0m eta: 0:15:02  iter: 8079  total_loss: 0.05657  loss_cls: 0.01597  loss_box_reg: 0.03346  loss_rpn_cls: 0.0004771  loss_rpn_loc: 0.005708    time: 0.5638  last_time: 0.5612  data_time: 0.0821  last_data_time: 0.0744   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:38:15 d2.utils.events]: \u001b[0m eta: 0:14:51  iter: 8099  total_loss: 0.06013  loss_cls: 0.01807  loss_box_reg: 0.03795  loss_rpn_cls: 0.0004201  loss_rpn_loc: 0.005419    time: 0.5638  last_time: 0.5431  data_time: 0.0767  last_data_time: 0.0681   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:38:26 d2.utils.events]: \u001b[0m eta: 0:14:40  iter: 8119  total_loss: 0.06086  loss_cls: 0.01776  loss_box_reg: 0.03958  loss_rpn_cls: 0.0005048  loss_rpn_loc: 0.005737    time: 0.5638  last_time: 0.5112  data_time: 0.0825  last_data_time: 0.0749   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:38:38 d2.utils.events]: \u001b[0m eta: 0:14:29  iter: 8139  total_loss: 0.06278  loss_cls: 0.01865  loss_box_reg: 0.03724  loss_rpn_cls: 0.0005711  loss_rpn_loc: 0.005406    time: 0.5638  last_time: 0.5462  data_time: 0.0892  last_data_time: 0.0638   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:38:49 d2.utils.events]: \u001b[0m eta: 0:14:18  iter: 8159  total_loss: 0.06705  loss_cls: 0.01817  loss_box_reg: 0.04138  loss_rpn_cls: 0.0005274  loss_rpn_loc: 0.004919    time: 0.5638  last_time: 0.5110  data_time: 0.0846  last_data_time: 0.0583   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:39:01 d2.utils.events]: \u001b[0m eta: 0:14:06  iter: 8179  total_loss: 0.05762  loss_cls: 0.01702  loss_box_reg: 0.0351  loss_rpn_cls: 0.0002088  loss_rpn_loc: 0.005168    time: 0.5638  last_time: 0.5016  data_time: 0.0829  last_data_time: 0.0760   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:39:12 d2.utils.events]: \u001b[0m eta: 0:13:55  iter: 8199  total_loss: 0.05407  loss_cls: 0.01735  loss_box_reg: 0.03167  loss_rpn_cls: 0.0005153  loss_rpn_loc: 0.00498    time: 0.5638  last_time: 0.6169  data_time: 0.0852  last_data_time: 0.0962   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:39:23 d2.utils.events]: \u001b[0m eta: 0:13:44  iter: 8219  total_loss: 0.06216  loss_cls: 0.01839  loss_box_reg: 0.03972  loss_rpn_cls: 0.000261  loss_rpn_loc: 0.00468    time: 0.5638  last_time: 0.6451  data_time: 0.0758  last_data_time: 0.0993   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:39:34 d2.utils.events]: \u001b[0m eta: 0:13:33  iter: 8239  total_loss: 0.06121  loss_cls: 0.01838  loss_box_reg: 0.03777  loss_rpn_cls: 0.0004679  loss_rpn_loc: 0.005361    time: 0.5638  last_time: 0.5576  data_time: 0.0838  last_data_time: 0.0735   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:39:45 d2.utils.events]: \u001b[0m eta: 0:13:21  iter: 8259  total_loss: 0.05633  loss_cls: 0.01658  loss_box_reg: 0.0345  loss_rpn_cls: 0.0004208  loss_rpn_loc: 0.00496    time: 0.5638  last_time: 0.5490  data_time: 0.0805  last_data_time: 0.0681   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:39:56 d2.utils.events]: \u001b[0m eta: 0:13:10  iter: 8279  total_loss: 0.0521  loss_cls: 0.01491  loss_box_reg: 0.03247  loss_rpn_cls: 0.0006102  loss_rpn_loc: 0.004018    time: 0.5638  last_time: 0.5239  data_time: 0.0802  last_data_time: 0.0601   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:40:08 d2.utils.events]: \u001b[0m eta: 0:12:59  iter: 8299  total_loss: 0.0548  loss_cls: 0.01641  loss_box_reg: 0.03355  loss_rpn_cls: 0.0002801  loss_rpn_loc: 0.004587    time: 0.5638  last_time: 0.5624  data_time: 0.0848  last_data_time: 0.0867   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:40:19 d2.utils.events]: \u001b[0m eta: 0:12:47  iter: 8319  total_loss: 0.05662  loss_cls: 0.01694  loss_box_reg: 0.03424  loss_rpn_cls: 0.0003358  loss_rpn_loc: 0.004785    time: 0.5638  last_time: 0.5138  data_time: 0.0816  last_data_time: 0.0754   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:40:31 d2.utils.events]: \u001b[0m eta: 0:12:36  iter: 8339  total_loss: 0.06138  loss_cls: 0.01651  loss_box_reg: 0.0376  loss_rpn_cls: 0.0005472  loss_rpn_loc: 0.006343    time: 0.5638  last_time: 0.5033  data_time: 0.0792  last_data_time: 0.0626   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:40:42 d2.utils.events]: \u001b[0m eta: 0:12:25  iter: 8359  total_loss: 0.0552  loss_cls: 0.0155  loss_box_reg: 0.03234  loss_rpn_cls: 0.0003013  loss_rpn_loc: 0.00413    time: 0.5638  last_time: 0.5639  data_time: 0.0815  last_data_time: 0.0846   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:40:53 d2.utils.events]: \u001b[0m eta: 0:12:14  iter: 8379  total_loss: 0.05796  loss_cls: 0.01756  loss_box_reg: 0.03736  loss_rpn_cls: 0.0006116  loss_rpn_loc: 0.004325    time: 0.5638  last_time: 0.6262  data_time: 0.0820  last_data_time: 0.1121   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:41:04 d2.utils.events]: \u001b[0m eta: 0:12:03  iter: 8399  total_loss: 0.05856  loss_cls: 0.01794  loss_box_reg: 0.03704  loss_rpn_cls: 0.0003454  loss_rpn_loc: 0.004552    time: 0.5638  last_time: 0.6663  data_time: 0.0796  last_data_time: 0.1049   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:41:16 d2.utils.events]: \u001b[0m eta: 0:11:51  iter: 8419  total_loss: 0.06248  loss_cls: 0.01748  loss_box_reg: 0.03693  loss_rpn_cls: 0.0004402  loss_rpn_loc: 0.006597    time: 0.5638  last_time: 0.5520  data_time: 0.0781  last_data_time: 0.0670   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:41:27 d2.utils.events]: \u001b[0m eta: 0:11:40  iter: 8439  total_loss: 0.05588  loss_cls: 0.01693  loss_box_reg: 0.03251  loss_rpn_cls: 0.0004598  loss_rpn_loc: 0.005009    time: 0.5638  last_time: 0.5105  data_time: 0.0814  last_data_time: 0.0601   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:41:38 d2.utils.events]: \u001b[0m eta: 0:11:29  iter: 8459  total_loss: 0.06198  loss_cls: 0.01758  loss_box_reg: 0.03645  loss_rpn_cls: 0.0003672  loss_rpn_loc: 0.004617    time: 0.5638  last_time: 0.5266  data_time: 0.0747  last_data_time: 0.0765   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:41:49 d2.utils.events]: \u001b[0m eta: 0:11:18  iter: 8479  total_loss: 0.05925  loss_cls: 0.0167  loss_box_reg: 0.03568  loss_rpn_cls: 0.0003678  loss_rpn_loc: 0.004797    time: 0.5638  last_time: 0.5066  data_time: 0.0836  last_data_time: 0.0635   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:42:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[05/07 19:42:03 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[05/07 19:42:03 d2.data.common]: \u001b[0mSerializing 392 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/07 19:42:03 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/07 19:42:03 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "\u001b[32m[05/07 19:42:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 392 batches\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[32m[05/07 19:42:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/392. Dataloading: 0.0012 s/iter. Inference: 0.0369 s/iter. Eval: 0.0003 s/iter. Total: 0.0385 s/iter. ETA=0:00:14\n",
            "\u001b[32m[05/07 19:42:09 d2.evaluation.evaluator]: \u001b[0mInference done 117/392. Dataloading: 0.0035 s/iter. Inference: 0.0428 s/iter. Eval: 0.0004 s/iter. Total: 0.0468 s/iter. ETA=0:00:12\n",
            "\u001b[32m[05/07 19:42:14 d2.evaluation.evaluator]: \u001b[0mInference done 241/392. Dataloading: 0.0029 s/iter. Inference: 0.0402 s/iter. Eval: 0.0004 s/iter. Total: 0.0435 s/iter. ETA=0:00:06\n",
            "\u001b[32m[05/07 19:42:19 d2.evaluation.evaluator]: \u001b[0mInference done 373/392. Dataloading: 0.0026 s/iter. Inference: 0.0386 s/iter. Eval: 0.0003 s/iter. Total: 0.0415 s/iter. ETA=0:00:00\n",
            "\u001b[32m[05/07 19:42:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.085528 (0.041565 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 19:42:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.038362 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 19:42:19 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/07 19:42:19 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
            "\u001b[32m[05/07 19:42:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[05/07 19:42:19 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[05/07 19:42:20 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.07 seconds.\n",
            "\u001b[32m[05/07 19:42:20 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[05/07 19:42:20 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.477\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.769\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.497\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.279\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.490\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.469\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.564\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.579\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.368\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.591\n",
            "\u001b[32m[05/07 19:42:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 47.665 | 76.868 | 49.663 |  nan  | 27.910 | 48.960 |\n",
            "\u001b[32m[05/07 19:42:20 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[05/07 19:42:20 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| Axe        | 38.321 | Handgun    | 49.676 | Knife      | 55.000 |\n",
            "\u001b[32m[05/07 19:42:20 d2.engine.defaults]: \u001b[0mEvaluation results for intruder_valid in csv format:\n",
            "\u001b[32m[05/07 19:42:20 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/07 19:42:20 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/07 19:42:20 d2.evaluation.testing]: \u001b[0mcopypaste: 47.6654,76.8683,49.6627,nan,27.9098,48.9597\n",
            "\u001b[32m[05/07 19:42:20 d2.utils.events]: \u001b[0m eta: 0:11:06  iter: 8499  total_loss: 0.06887  loss_cls: 0.0188  loss_box_reg: 0.04104  loss_rpn_cls: 0.00031  loss_rpn_loc: 0.006309    time: 0.5638  last_time: 0.5531  data_time: 0.0825  last_data_time: 0.0671   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:42:31 d2.utils.events]: \u001b[0m eta: 0:10:55  iter: 8519  total_loss: 0.06121  loss_cls: 0.01866  loss_box_reg: 0.03804  loss_rpn_cls: 0.0005595  loss_rpn_loc: 0.005023    time: 0.5638  last_time: 0.5541  data_time: 0.0805  last_data_time: 0.0663   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:42:42 d2.utils.events]: \u001b[0m eta: 0:10:44  iter: 8539  total_loss: 0.05465  loss_cls: 0.01647  loss_box_reg: 0.03438  loss_rpn_cls: 0.000225  loss_rpn_loc: 0.004543    time: 0.5638  last_time: 0.5474  data_time: 0.0821  last_data_time: 0.0736   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:42:54 d2.utils.events]: \u001b[0m eta: 0:10:33  iter: 8559  total_loss: 0.05732  loss_cls: 0.01583  loss_box_reg: 0.03426  loss_rpn_cls: 0.0004025  loss_rpn_loc: 0.005784    time: 0.5639  last_time: 0.5766  data_time: 0.0845  last_data_time: 0.0727   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:43:05 d2.utils.events]: \u001b[0m eta: 0:10:21  iter: 8579  total_loss: 0.05546  loss_cls: 0.01686  loss_box_reg: 0.03245  loss_rpn_cls: 0.000452  loss_rpn_loc: 0.005023    time: 0.5639  last_time: 0.5036  data_time: 0.0861  last_data_time: 0.0759   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:43:16 d2.utils.events]: \u001b[0m eta: 0:10:10  iter: 8599  total_loss: 0.05267  loss_cls: 0.01509  loss_box_reg: 0.03372  loss_rpn_cls: 0.0002239  loss_rpn_loc: 0.004877    time: 0.5639  last_time: 0.5337  data_time: 0.0849  last_data_time: 0.0623   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:43:28 d2.utils.events]: \u001b[0m eta: 0:09:59  iter: 8619  total_loss: 0.06774  loss_cls: 0.01838  loss_box_reg: 0.04017  loss_rpn_cls: 0.0003825  loss_rpn_loc: 0.005719    time: 0.5639  last_time: 0.5771  data_time: 0.0869  last_data_time: 0.0883   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:43:39 d2.utils.events]: \u001b[0m eta: 0:09:48  iter: 8639  total_loss: 0.06649  loss_cls: 0.01999  loss_box_reg: 0.04003  loss_rpn_cls: 0.0001915  loss_rpn_loc: 0.005407    time: 0.5639  last_time: 0.5446  data_time: 0.0784  last_data_time: 0.0734   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:43:51 d2.utils.events]: \u001b[0m eta: 0:09:36  iter: 8659  total_loss: 0.05804  loss_cls: 0.01737  loss_box_reg: 0.03355  loss_rpn_cls: 0.0006234  loss_rpn_loc: 0.005394    time: 0.5639  last_time: 0.5588  data_time: 0.0769  last_data_time: 0.0709   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:44:02 d2.utils.events]: \u001b[0m eta: 0:09:25  iter: 8679  total_loss: 0.06573  loss_cls: 0.01769  loss_box_reg: 0.04122  loss_rpn_cls: 0.0001955  loss_rpn_loc: 0.005115    time: 0.5639  last_time: 0.6195  data_time: 0.0797  last_data_time: 0.1288   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:44:13 d2.utils.events]: \u001b[0m eta: 0:09:14  iter: 8699  total_loss: 0.05912  loss_cls: 0.01784  loss_box_reg: 0.03583  loss_rpn_cls: 0.0003939  loss_rpn_loc: 0.004684    time: 0.5639  last_time: 0.7017  data_time: 0.0876  last_data_time: 0.1602   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:44:24 d2.utils.events]: \u001b[0m eta: 0:09:03  iter: 8719  total_loss: 0.06006  loss_cls: 0.01791  loss_box_reg: 0.03769  loss_rpn_cls: 0.0002632  loss_rpn_loc: 0.005826    time: 0.5639  last_time: 0.5781  data_time: 0.0711  last_data_time: 0.0991   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:44:35 d2.utils.events]: \u001b[0m eta: 0:08:52  iter: 8739  total_loss: 0.0579  loss_cls: 0.01431  loss_box_reg: 0.03335  loss_rpn_cls: 0.0005162  loss_rpn_loc: 0.006352    time: 0.5639  last_time: 0.5446  data_time: 0.0832  last_data_time: 0.0818   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:44:47 d2.utils.events]: \u001b[0m eta: 0:08:41  iter: 8759  total_loss: 0.05277  loss_cls: 0.0137  loss_box_reg: 0.03252  loss_rpn_cls: 0.0005084  loss_rpn_loc: 0.004944    time: 0.5638  last_time: 0.5342  data_time: 0.0820  last_data_time: 0.0694   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:44:58 d2.utils.events]: \u001b[0m eta: 0:08:30  iter: 8779  total_loss: 0.04792  loss_cls: 0.01487  loss_box_reg: 0.02892  loss_rpn_cls: 0.0002706  loss_rpn_loc: 0.005016    time: 0.5638  last_time: 0.5406  data_time: 0.0842  last_data_time: 0.0737   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:45:09 d2.utils.events]: \u001b[0m eta: 0:08:18  iter: 8799  total_loss: 0.05365  loss_cls: 0.01679  loss_box_reg: 0.0335  loss_rpn_cls: 0.0001367  loss_rpn_loc: 0.004194    time: 0.5639  last_time: 0.5661  data_time: 0.0783  last_data_time: 0.0967   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:45:20 d2.utils.events]: \u001b[0m eta: 0:08:07  iter: 8819  total_loss: 0.05159  loss_cls: 0.01439  loss_box_reg: 0.0341  loss_rpn_cls: 0.0002778  loss_rpn_loc: 0.004431    time: 0.5638  last_time: 0.5615  data_time: 0.0803  last_data_time: 0.0780   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:45:32 d2.utils.events]: \u001b[0m eta: 0:07:56  iter: 8839  total_loss: 0.05292  loss_cls: 0.01475  loss_box_reg: 0.03151  loss_rpn_cls: 0.0003994  loss_rpn_loc: 0.004805    time: 0.5638  last_time: 0.5285  data_time: 0.0822  last_data_time: 0.0880   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:45:43 d2.utils.events]: \u001b[0m eta: 0:07:45  iter: 8859  total_loss: 0.049  loss_cls: 0.01382  loss_box_reg: 0.03134  loss_rpn_cls: 0.0003036  loss_rpn_loc: 0.004572    time: 0.5638  last_time: 0.4868  data_time: 0.0806  last_data_time: 0.0699   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:45:54 d2.utils.events]: \u001b[0m eta: 0:07:34  iter: 8879  total_loss: 0.06037  loss_cls: 0.01682  loss_box_reg: 0.03799  loss_rpn_cls: 0.00034  loss_rpn_loc: 0.005461    time: 0.5638  last_time: 0.5331  data_time: 0.0859  last_data_time: 0.0673   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:46:06 d2.utils.events]: \u001b[0m eta: 0:07:23  iter: 8899  total_loss: 0.06379  loss_cls: 0.01923  loss_box_reg: 0.03737  loss_rpn_cls: 0.0002653  loss_rpn_loc: 0.004714    time: 0.5639  last_time: 0.6465  data_time: 0.0842  last_data_time: 0.1252   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:46:17 d2.utils.events]: \u001b[0m eta: 0:07:12  iter: 8919  total_loss: 0.05701  loss_cls: 0.01806  loss_box_reg: 0.03546  loss_rpn_cls: 0.000266  loss_rpn_loc: 0.005904    time: 0.5638  last_time: 0.6523  data_time: 0.0786  last_data_time: 0.0392   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:46:28 d2.utils.events]: \u001b[0m eta: 0:07:01  iter: 8939  total_loss: 0.06031  loss_cls: 0.01821  loss_box_reg: 0.036  loss_rpn_cls: 0.0006222  loss_rpn_loc: 0.005278    time: 0.5638  last_time: 0.4932  data_time: 0.0720  last_data_time: 0.0621   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:46:39 d2.utils.events]: \u001b[0m eta: 0:06:49  iter: 8959  total_loss: 0.06108  loss_cls: 0.0194  loss_box_reg: 0.03685  loss_rpn_cls: 0.0004652  loss_rpn_loc: 0.005423    time: 0.5638  last_time: 0.5523  data_time: 0.0814  last_data_time: 0.0642   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:46:51 d2.utils.events]: \u001b[0m eta: 0:06:38  iter: 8979  total_loss: 0.05144  loss_cls: 0.01384  loss_box_reg: 0.03045  loss_rpn_cls: 0.0003034  loss_rpn_loc: 0.005232    time: 0.5638  last_time: 0.5469  data_time: 0.0753  last_data_time: 0.0666   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:47:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[05/07 19:47:04 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[05/07 19:47:04 d2.data.common]: \u001b[0mSerializing 392 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/07 19:47:04 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/07 19:47:04 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "\u001b[32m[05/07 19:47:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 392 batches\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[32m[05/07 19:47:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/392. Dataloading: 0.0015 s/iter. Inference: 0.0353 s/iter. Eval: 0.0003 s/iter. Total: 0.0371 s/iter. ETA=0:00:14\n",
            "\u001b[32m[05/07 19:47:10 d2.evaluation.evaluator]: \u001b[0mInference done 114/392. Dataloading: 0.0042 s/iter. Inference: 0.0434 s/iter. Eval: 0.0003 s/iter. Total: 0.0480 s/iter. ETA=0:00:13\n",
            "\u001b[32m[05/07 19:47:15 d2.evaluation.evaluator]: \u001b[0mInference done 247/392. Dataloading: 0.0030 s/iter. Inference: 0.0389 s/iter. Eval: 0.0003 s/iter. Total: 0.0423 s/iter. ETA=0:00:06\n",
            "\u001b[32m[05/07 19:47:20 d2.evaluation.evaluator]: \u001b[0mInference done 362/392. Dataloading: 0.0030 s/iter. Inference: 0.0394 s/iter. Eval: 0.0003 s/iter. Total: 0.0428 s/iter. ETA=0:00:01\n",
            "\u001b[32m[05/07 19:47:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.877662 (0.043612 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 19:47:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.039878 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 19:47:21 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/07 19:47:21 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
            "\u001b[32m[05/07 19:47:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[05/07 19:47:21 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[05/07 19:47:21 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.04 seconds.\n",
            "\u001b[32m[05/07 19:47:21 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[05/07 19:47:21 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.462\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.753\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.477\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.284\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.474\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.465\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.558\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.571\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.353\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.584\n",
            "\u001b[32m[05/07 19:47:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 46.170 | 75.331 | 47.688 |  nan  | 28.439 | 47.441 |\n",
            "\u001b[32m[05/07 19:47:21 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[05/07 19:47:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| Axe        | 35.708 | Handgun    | 48.606 | Knife      | 54.196 |\n",
            "\u001b[32m[05/07 19:47:21 d2.engine.defaults]: \u001b[0mEvaluation results for intruder_valid in csv format:\n",
            "\u001b[32m[05/07 19:47:21 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/07 19:47:21 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/07 19:47:21 d2.evaluation.testing]: \u001b[0mcopypaste: 46.1700,75.3310,47.6877,nan,28.4386,47.4407\n",
            "\u001b[32m[05/07 19:47:21 d2.utils.events]: \u001b[0m eta: 0:06:27  iter: 8999  total_loss: 0.05864  loss_cls: 0.01853  loss_box_reg: 0.03525  loss_rpn_cls: 0.0006483  loss_rpn_loc: 0.007378    time: 0.5638  last_time: 0.4592  data_time: 0.0839  last_data_time: 0.0632   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:47:33 d2.utils.events]: \u001b[0m eta: 0:06:16  iter: 9019  total_loss: 0.06717  loss_cls: 0.01828  loss_box_reg: 0.04398  loss_rpn_cls: 0.0003546  loss_rpn_loc: 0.005367    time: 0.5638  last_time: 0.6902  data_time: 0.0816  last_data_time: 0.1186   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:47:43 d2.utils.events]: \u001b[0m eta: 0:06:05  iter: 9039  total_loss: 0.05751  loss_cls: 0.01613  loss_box_reg: 0.0347  loss_rpn_cls: 0.0003872  loss_rpn_loc: 0.005221    time: 0.5638  last_time: 0.5790  data_time: 0.0781  last_data_time: 0.0804   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:47:55 d2.utils.events]: \u001b[0m eta: 0:05:54  iter: 9059  total_loss: 0.06578  loss_cls: 0.02029  loss_box_reg: 0.03842  loss_rpn_cls: 0.0003448  loss_rpn_loc: 0.005192    time: 0.5638  last_time: 0.5710  data_time: 0.0863  last_data_time: 0.0922   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:48:06 d2.utils.events]: \u001b[0m eta: 0:05:43  iter: 9079  total_loss: 0.05971  loss_cls: 0.01724  loss_box_reg: 0.03571  loss_rpn_cls: 0.0005174  loss_rpn_loc: 0.005212    time: 0.5638  last_time: 0.5479  data_time: 0.0823  last_data_time: 0.0791   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:48:17 d2.utils.events]: \u001b[0m eta: 0:05:31  iter: 9099  total_loss: 0.05358  loss_cls: 0.01513  loss_box_reg: 0.03321  loss_rpn_cls: 0.0003363  loss_rpn_loc: 0.005203    time: 0.5638  last_time: 0.5355  data_time: 0.0831  last_data_time: 0.0600   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:48:29 d2.utils.events]: \u001b[0m eta: 0:05:20  iter: 9119  total_loss: 0.06298  loss_cls: 0.01815  loss_box_reg: 0.03725  loss_rpn_cls: 0.0004073  loss_rpn_loc: 0.006189    time: 0.5638  last_time: 0.5577  data_time: 0.0797  last_data_time: 0.0751   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:48:40 d2.utils.events]: \u001b[0m eta: 0:05:09  iter: 9139  total_loss: 0.05241  loss_cls: 0.01549  loss_box_reg: 0.03177  loss_rpn_cls: 0.000269  loss_rpn_loc: 0.004645    time: 0.5638  last_time: 0.5490  data_time: 0.0813  last_data_time: 0.0720   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:48:51 d2.utils.events]: \u001b[0m eta: 0:04:58  iter: 9159  total_loss: 0.05071  loss_cls: 0.01557  loss_box_reg: 0.03033  loss_rpn_cls: 0.0004094  loss_rpn_loc: 0.0053    time: 0.5638  last_time: 0.5607  data_time: 0.0824  last_data_time: 0.0898   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:49:03 d2.utils.events]: \u001b[0m eta: 0:04:47  iter: 9179  total_loss: 0.05676  loss_cls: 0.01603  loss_box_reg: 0.03481  loss_rpn_cls: 0.0004171  loss_rpn_loc: 0.005145    time: 0.5638  last_time: 0.5630  data_time: 0.0772  last_data_time: 0.0705   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:49:14 d2.utils.events]: \u001b[0m eta: 0:04:36  iter: 9199  total_loss: 0.05155  loss_cls: 0.01495  loss_box_reg: 0.03135  loss_rpn_cls: 0.000501  loss_rpn_loc: 0.004719    time: 0.5638  last_time: 0.5573  data_time: 0.0858  last_data_time: 0.0763   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:49:25 d2.utils.events]: \u001b[0m eta: 0:04:25  iter: 9219  total_loss: 0.06686  loss_cls: 0.02054  loss_box_reg: 0.04324  loss_rpn_cls: 0.0003501  loss_rpn_loc: 0.005613    time: 0.5638  last_time: 0.5125  data_time: 0.0776  last_data_time: 0.0809   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:49:37 d2.utils.events]: \u001b[0m eta: 0:04:14  iter: 9239  total_loss: 0.05859  loss_cls: 0.016  loss_box_reg: 0.03746  loss_rpn_cls: 0.0004257  loss_rpn_loc: 0.004578    time: 0.5638  last_time: 0.6677  data_time: 0.0788  last_data_time: 0.1033   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:49:48 d2.utils.events]: \u001b[0m eta: 0:04:03  iter: 9259  total_loss: 0.05231  loss_cls: 0.01455  loss_box_reg: 0.03019  loss_rpn_cls: 0.0004065  loss_rpn_loc: 0.004366    time: 0.5638  last_time: 0.6401  data_time: 0.0804  last_data_time: 0.0901   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:49:59 d2.utils.events]: \u001b[0m eta: 0:03:52  iter: 9279  total_loss: 0.05778  loss_cls: 0.01706  loss_box_reg: 0.03495  loss_rpn_cls: 0.00066  loss_rpn_loc: 0.004918    time: 0.5638  last_time: 0.5112  data_time: 0.0785  last_data_time: 0.0678   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:50:10 d2.utils.events]: \u001b[0m eta: 0:03:41  iter: 9299  total_loss: 0.05095  loss_cls: 0.01498  loss_box_reg: 0.0294  loss_rpn_cls: 0.0002153  loss_rpn_loc: 0.004466    time: 0.5638  last_time: 0.5137  data_time: 0.0869  last_data_time: 0.0761   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:50:22 d2.utils.events]: \u001b[0m eta: 0:03:30  iter: 9319  total_loss: 0.05732  loss_cls: 0.0174  loss_box_reg: 0.03493  loss_rpn_cls: 0.0002131  loss_rpn_loc: 0.005418    time: 0.5638  last_time: 0.5141  data_time: 0.0810  last_data_time: 0.0936   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:50:33 d2.utils.events]: \u001b[0m eta: 0:03:19  iter: 9339  total_loss: 0.05533  loss_cls: 0.01551  loss_box_reg: 0.03444  loss_rpn_cls: 0.0003844  loss_rpn_loc: 0.003848    time: 0.5638  last_time: 0.5465  data_time: 0.0851  last_data_time: 0.0591   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:50:44 d2.utils.events]: \u001b[0m eta: 0:03:08  iter: 9359  total_loss: 0.05747  loss_cls: 0.01669  loss_box_reg: 0.03544  loss_rpn_cls: 0.0005496  loss_rpn_loc: 0.00475    time: 0.5638  last_time: 0.5400  data_time: 0.0848  last_data_time: 0.0685   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:50:56 d2.utils.events]: \u001b[0m eta: 0:02:57  iter: 9379  total_loss: 0.05775  loss_cls: 0.01668  loss_box_reg: 0.03463  loss_rpn_cls: 0.0002542  loss_rpn_loc: 0.005274    time: 0.5638  last_time: 0.5557  data_time: 0.0808  last_data_time: 0.0714   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:51:07 d2.utils.events]: \u001b[0m eta: 0:02:46  iter: 9399  total_loss: 0.05646  loss_cls: 0.01701  loss_box_reg: 0.03407  loss_rpn_cls: 0.0002975  loss_rpn_loc: 0.005088    time: 0.5638  last_time: 0.5127  data_time: 0.0894  last_data_time: 0.0845   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:51:18 d2.utils.events]: \u001b[0m eta: 0:02:35  iter: 9419  total_loss: 0.06317  loss_cls: 0.01853  loss_box_reg: 0.04032  loss_rpn_cls: 0.0003198  loss_rpn_loc: 0.005466    time: 0.5639  last_time: 0.5503  data_time: 0.0819  last_data_time: 0.0736   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:51:30 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 9439  total_loss: 0.05294  loss_cls: 0.01578  loss_box_reg: 0.03166  loss_rpn_cls: 0.0003571  loss_rpn_loc: 0.004645    time: 0.5639  last_time: 0.5484  data_time: 0.0829  last_data_time: 0.0688   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:51:41 d2.utils.events]: \u001b[0m eta: 0:02:12  iter: 9459  total_loss: 0.05912  loss_cls: 0.01671  loss_box_reg: 0.03589  loss_rpn_cls: 0.0003646  loss_rpn_loc: 0.004837    time: 0.5639  last_time: 0.6168  data_time: 0.0834  last_data_time: 0.1050   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:51:52 d2.utils.events]: \u001b[0m eta: 0:02:01  iter: 9479  total_loss: 0.04811  loss_cls: 0.01495  loss_box_reg: 0.02827  loss_rpn_cls: 0.0002785  loss_rpn_loc: 0.003484    time: 0.5639  last_time: 0.6080  data_time: 0.0712  last_data_time: 0.0873   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:52:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[05/07 19:52:06 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[05/07 19:52:06 d2.data.common]: \u001b[0mSerializing 392 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/07 19:52:06 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/07 19:52:06 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "\u001b[32m[05/07 19:52:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 392 batches\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[32m[05/07 19:52:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/392. Dataloading: 0.0014 s/iter. Inference: 0.0374 s/iter. Eval: 0.0003 s/iter. Total: 0.0391 s/iter. ETA=0:00:14\n",
            "\u001b[32m[05/07 19:52:12 d2.evaluation.evaluator]: \u001b[0mInference done 142/392. Dataloading: 0.0021 s/iter. Inference: 0.0358 s/iter. Eval: 0.0003 s/iter. Total: 0.0382 s/iter. ETA=0:00:09\n",
            "\u001b[32m[05/07 19:52:17 d2.evaluation.evaluator]: \u001b[0mInference done 261/392. Dataloading: 0.0023 s/iter. Inference: 0.0373 s/iter. Eval: 0.0004 s/iter. Total: 0.0400 s/iter. ETA=0:00:05\n",
            "\u001b[32m[05/07 19:52:22 d2.evaluation.evaluator]: \u001b[0mInference done 376/392. Dataloading: 0.0025 s/iter. Inference: 0.0382 s/iter. Eval: 0.0004 s/iter. Total: 0.0412 s/iter. ETA=0:00:00\n",
            "\u001b[32m[05/07 19:52:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.923083 (0.041145 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 19:52:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.038009 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 19:52:23 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/07 19:52:23 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
            "\u001b[32m[05/07 19:52:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[05/07 19:52:23 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[05/07 19:52:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.03 seconds.\n",
            "\u001b[32m[05/07 19:52:23 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[05/07 19:52:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.480\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.763\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.499\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.271\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.496\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.476\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.568\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.582\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.354\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.596\n",
            "\u001b[32m[05/07 19:52:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 48.049 | 76.289 | 49.932 |  nan  | 27.114 | 49.605 |\n",
            "\u001b[32m[05/07 19:52:23 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[05/07 19:52:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| Axe        | 38.346 | Handgun    | 50.712 | Knife      | 55.088 |\n",
            "\u001b[32m[05/07 19:52:23 d2.engine.defaults]: \u001b[0mEvaluation results for intruder_valid in csv format:\n",
            "\u001b[32m[05/07 19:52:23 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/07 19:52:23 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/07 19:52:23 d2.evaluation.testing]: \u001b[0mcopypaste: 48.0487,76.2893,49.9324,nan,27.1136,49.6050\n",
            "\u001b[32m[05/07 19:52:23 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 9499  total_loss: 0.05537  loss_cls: 0.01749  loss_box_reg: 0.03335  loss_rpn_cls: 0.000281  loss_rpn_loc: 0.004829    time: 0.5638  last_time: 0.4998  data_time: 0.0749  last_data_time: 0.0692   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:52:34 d2.utils.events]: \u001b[0m eta: 0:01:39  iter: 9519  total_loss: 0.06027  loss_cls: 0.0178  loss_box_reg: 0.03386  loss_rpn_cls: 0.0004443  loss_rpn_loc: 0.004128    time: 0.5638  last_time: 0.5800  data_time: 0.0845  last_data_time: 0.1039   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:52:45 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 9539  total_loss: 0.06357  loss_cls: 0.01773  loss_box_reg: 0.03877  loss_rpn_cls: 0.0003029  loss_rpn_loc: 0.004886    time: 0.5639  last_time: 0.5824  data_time: 0.0903  last_data_time: 0.0948   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:52:57 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 9559  total_loss: 0.05521  loss_cls: 0.01698  loss_box_reg: 0.03417  loss_rpn_cls: 0.0003407  loss_rpn_loc: 0.005102    time: 0.5639  last_time: 0.5504  data_time: 0.0876  last_data_time: 0.0750   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:53:08 d2.utils.events]: \u001b[0m eta: 0:01:06  iter: 9579  total_loss: 0.05841  loss_cls: 0.0175  loss_box_reg: 0.03381  loss_rpn_cls: 0.0003064  loss_rpn_loc: 0.005154    time: 0.5639  last_time: 0.6582  data_time: 0.0821  last_data_time: 0.1011   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:53:20 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 9599  total_loss: 0.05254  loss_cls: 0.01628  loss_box_reg: 0.03126  loss_rpn_cls: 0.0004843  loss_rpn_loc: 0.004266    time: 0.5639  last_time: 0.6480  data_time: 0.0839  last_data_time: 0.0884   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:53:31 d2.utils.events]: \u001b[0m eta: 0:00:44  iter: 9619  total_loss: 0.0586  loss_cls: 0.01832  loss_box_reg: 0.03644  loss_rpn_cls: 0.00024  loss_rpn_loc: 0.005335    time: 0.5639  last_time: 0.6143  data_time: 0.0792  last_data_time: 0.0875   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:53:42 d2.utils.events]: \u001b[0m eta: 0:00:33  iter: 9639  total_loss: 0.05412  loss_cls: 0.01609  loss_box_reg: 0.03345  loss_rpn_cls: 0.0004838  loss_rpn_loc: 0.005619    time: 0.5639  last_time: 0.5666  data_time: 0.0804  last_data_time: 0.0733   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:53:54 d2.utils.events]: \u001b[0m eta: 0:00:22  iter: 9659  total_loss: 0.06047  loss_cls: 0.01676  loss_box_reg: 0.03667  loss_rpn_cls: 0.0003113  loss_rpn_loc: 0.005012    time: 0.5639  last_time: 0.5518  data_time: 0.0833  last_data_time: 0.0671   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:54:05 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 9679  total_loss: 0.04755  loss_cls: 0.0136  loss_box_reg: 0.02974  loss_rpn_cls: 0.0002474  loss_rpn_loc: 0.004712    time: 0.5639  last_time: 0.5725  data_time: 0.0808  last_data_time: 0.0794   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:54:17 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9699  total_loss: 0.05909  loss_cls: 0.0172  loss_box_reg: 0.03646  loss_rpn_cls: 0.0003377  loss_rpn_loc: 0.00532    time: 0.5639  last_time: 0.5504  data_time: 0.0874  last_data_time: 0.0678   lr: 0.0025  max_mem: 5722M\n",
            "\u001b[32m[05/07 19:54:18 d2.engine.hooks]: \u001b[0mOverall training speed: 9698 iterations in 1:31:08 (0.5639 s / it)\n",
            "\u001b[32m[05/07 19:54:18 d2.engine.hooks]: \u001b[0mTotal training time: 1:37:25 (0:06:16 on hooks)\n",
            "\u001b[32m[05/07 19:54:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[05/07 19:54:20 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[05/07 19:54:20 d2.data.common]: \u001b[0mSerializing 392 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/07 19:54:20 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/07 19:54:20 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "\u001b[32m[05/07 19:54:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 392 batches\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[32m[05/07 19:54:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/392. Dataloading: 0.0055 s/iter. Inference: 0.0551 s/iter. Eval: 0.0003 s/iter. Total: 0.0610 s/iter. ETA=0:00:23\n",
            "\u001b[32m[05/07 19:54:26 d2.evaluation.evaluator]: \u001b[0mInference done 119/392. Dataloading: 0.0039 s/iter. Inference: 0.0430 s/iter. Eval: 0.0003 s/iter. Total: 0.0472 s/iter. ETA=0:00:12\n",
            "\u001b[32m[05/07 19:54:31 d2.evaluation.evaluator]: \u001b[0mInference done 253/392. Dataloading: 0.0028 s/iter. Inference: 0.0388 s/iter. Eval: 0.0003 s/iter. Total: 0.0419 s/iter. ETA=0:00:05\n",
            "\u001b[32m[05/07 19:54:36 d2.evaluation.evaluator]: \u001b[0mInference done 357/392. Dataloading: 0.0032 s/iter. Inference: 0.0402 s/iter. Eval: 0.0003 s/iter. Total: 0.0438 s/iter. ETA=0:00:01\n",
            "\u001b[32m[05/07 19:54:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.893295 (0.043652 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 19:54:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.039979 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/07 19:54:37 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/07 19:54:37 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
            "\u001b[32m[05/07 19:54:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[05/07 19:54:37 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[05/07 19:54:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.03 seconds.\n",
            "\u001b[32m[05/07 19:54:37 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[05/07 19:54:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.478\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.772\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.503\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.284\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.493\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.472\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.570\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.584\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.342\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.601\n",
            "\u001b[32m[05/07 19:54:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 47.798 | 77.199 | 50.272 |  nan  | 28.396 | 49.258 |\n",
            "\u001b[32m[05/07 19:54:37 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[05/07 19:54:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| Axe        | 39.350 | Handgun    | 48.979 | Knife      | 55.066 |\n",
            "\u001b[32m[05/07 19:54:37 d2.engine.defaults]: \u001b[0mEvaluation results for intruder_valid in csv format:\n",
            "\u001b[32m[05/07 19:54:37 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/07 19:54:37 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/07 19:54:37 d2.evaluation.testing]: \u001b[0mcopypaste: 47.7982,77.1991,50.2723,nan,28.3962,49.2582\n",
            "Model and config saved to:  ./output\n"
          ]
        }
      ]
    }
  ]
}